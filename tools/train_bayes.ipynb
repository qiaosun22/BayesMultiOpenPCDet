{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7a3b7-423e-48d0-aef4-3d6f53af4196",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-05-27T04:08:03.294690Z",
     "iopub.status.busy": "2023-05-27T04:08:03.294435Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 12:08:03,391   INFO  **********************Start logging**********************\n",
      "2023-05-27 12:08:03,391   INFO  **********************Start logging**********************\n",
      "2023-05-27 12:08:03,391   INFO  **********************Start logging**********************\n",
      "2023-05-27 12:08:03,391   INFO  **********************Start logging**********************\n",
      "2023-05-27 12:08:03,393   INFO  CUDA_VISIBLE_DEVICES=0\n",
      "2023-05-27 12:08:03,393   INFO  CUDA_VISIBLE_DEVICES=0\n",
      "2023-05-27 12:08:03,393   INFO  CUDA_VISIBLE_DEVICES=0\n",
      "2023-05-27 12:08:03,393   INFO  CUDA_VISIBLE_DEVICES=0\n",
      "2023-05-27 12:08:03,394   INFO  cfg_file         ./cfgs/kitti_models/pointpillar_bayes.yaml\n",
      "2023-05-27 12:08:03,394   INFO  cfg_file         ./cfgs/kitti_models/pointpillar_bayes.yaml\n",
      "2023-05-27 12:08:03,394   INFO  cfg_file         ./cfgs/kitti_models/pointpillar_bayes.yaml\n",
      "2023-05-27 12:08:03,394   INFO  cfg_file         ./cfgs/kitti_models/pointpillar_bayes.yaml\n",
      "2023-05-27 12:08:03,395   INFO  batch_size       4\n",
      "2023-05-27 12:08:03,395   INFO  batch_size       4\n",
      "2023-05-27 12:08:03,395   INFO  batch_size       4\n",
      "2023-05-27 12:08:03,395   INFO  batch_size       4\n",
      "2023-05-27 12:08:03,397   INFO  epochs           80\n",
      "2023-05-27 12:08:03,397   INFO  epochs           80\n",
      "2023-05-27 12:08:03,397   INFO  epochs           80\n",
      "2023-05-27 12:08:03,397   INFO  epochs           80\n",
      "2023-05-27 12:08:03,398   INFO  workers          32\n",
      "2023-05-27 12:08:03,398   INFO  workers          32\n",
      "2023-05-27 12:08:03,398   INFO  workers          32\n",
      "2023-05-27 12:08:03,398   INFO  workers          32\n",
      "2023-05-27 12:08:03,399   INFO  extra_tag        default\n",
      "2023-05-27 12:08:03,399   INFO  extra_tag        default\n",
      "2023-05-27 12:08:03,399   INFO  extra_tag        default\n",
      "2023-05-27 12:08:03,399   INFO  extra_tag        default\n",
      "2023-05-27 12:08:03,400   INFO  ckpt             ./checkpoint_epoch_80.pth\n",
      "2023-05-27 12:08:03,400   INFO  ckpt             ./checkpoint_epoch_80.pth\n",
      "2023-05-27 12:08:03,400   INFO  ckpt             ./checkpoint_epoch_80.pth\n",
      "2023-05-27 12:08:03,400   INFO  ckpt             ./checkpoint_epoch_80.pth\n",
      "2023-05-27 12:08:03,402   INFO  pretrained_model True\n",
      "2023-05-27 12:08:03,402   INFO  pretrained_model True\n",
      "2023-05-27 12:08:03,402   INFO  pretrained_model True\n",
      "2023-05-27 12:08:03,402   INFO  pretrained_model True\n",
      "2023-05-27 12:08:03,403   INFO  launcher         none\n",
      "2023-05-27 12:08:03,403   INFO  launcher         none\n",
      "2023-05-27 12:08:03,403   INFO  launcher         none\n",
      "2023-05-27 12:08:03,403   INFO  launcher         none\n",
      "2023-05-27 12:08:03,404   INFO  tcp_port         18888\n",
      "2023-05-27 12:08:03,404   INFO  tcp_port         18888\n",
      "2023-05-27 12:08:03,404   INFO  tcp_port         18888\n",
      "2023-05-27 12:08:03,404   INFO  tcp_port         18888\n",
      "2023-05-27 12:08:03,405   INFO  sync_bn          False\n",
      "2023-05-27 12:08:03,405   INFO  sync_bn          False\n",
      "2023-05-27 12:08:03,405   INFO  sync_bn          False\n",
      "2023-05-27 12:08:03,405   INFO  sync_bn          False\n",
      "2023-05-27 12:08:03,407   INFO  fix_random_seed  True\n",
      "2023-05-27 12:08:03,407   INFO  fix_random_seed  True\n",
      "2023-05-27 12:08:03,407   INFO  fix_random_seed  True\n",
      "2023-05-27 12:08:03,407   INFO  fix_random_seed  True\n",
      "2023-05-27 12:08:03,408   INFO  ckpt_save_interval 1\n",
      "2023-05-27 12:08:03,408   INFO  ckpt_save_interval 1\n",
      "2023-05-27 12:08:03,408   INFO  ckpt_save_interval 1\n",
      "2023-05-27 12:08:03,408   INFO  ckpt_save_interval 1\n",
      "2023-05-27 12:08:03,409   INFO  local_rank       0\n",
      "2023-05-27 12:08:03,409   INFO  local_rank       0\n",
      "2023-05-27 12:08:03,409   INFO  local_rank       0\n",
      "2023-05-27 12:08:03,409   INFO  local_rank       0\n",
      "2023-05-27 12:08:03,410   INFO  max_ckpt_save_num 81\n",
      "2023-05-27 12:08:03,410   INFO  max_ckpt_save_num 81\n",
      "2023-05-27 12:08:03,410   INFO  max_ckpt_save_num 81\n",
      "2023-05-27 12:08:03,410   INFO  max_ckpt_save_num 81\n",
      "2023-05-27 12:08:03,411   INFO  merge_all_iters_to_one_epoch False\n",
      "2023-05-27 12:08:03,411   INFO  merge_all_iters_to_one_epoch False\n",
      "2023-05-27 12:08:03,411   INFO  merge_all_iters_to_one_epoch False\n",
      "2023-05-27 12:08:03,411   INFO  merge_all_iters_to_one_epoch False\n",
      "2023-05-27 12:08:03,413   INFO  set_cfgs         None\n",
      "2023-05-27 12:08:03,413   INFO  set_cfgs         None\n",
      "2023-05-27 12:08:03,413   INFO  set_cfgs         None\n",
      "2023-05-27 12:08:03,413   INFO  set_cfgs         None\n",
      "2023-05-27 12:08:03,414   INFO  max_waiting_mins 0\n",
      "2023-05-27 12:08:03,414   INFO  max_waiting_mins 0\n",
      "2023-05-27 12:08:03,414   INFO  max_waiting_mins 0\n",
      "2023-05-27 12:08:03,414   INFO  max_waiting_mins 0\n",
      "2023-05-27 12:08:03,415   INFO  start_epoch      0\n",
      "2023-05-27 12:08:03,415   INFO  start_epoch      0\n",
      "2023-05-27 12:08:03,415   INFO  start_epoch      0\n",
      "2023-05-27 12:08:03,415   INFO  start_epoch      0\n",
      "2023-05-27 12:08:03,416   INFO  save_to_file     False\n",
      "2023-05-27 12:08:03,416   INFO  save_to_file     False\n",
      "2023-05-27 12:08:03,416   INFO  save_to_file     False\n",
      "2023-05-27 12:08:03,416   INFO  save_to_file     False\n",
      "2023-05-27 12:08:03,418   INFO  cfg.ROOT_DIR: /mnt/workspace/sunqiao/OpenPCDet\n",
      "2023-05-27 12:08:03,418   INFO  cfg.ROOT_DIR: /mnt/workspace/sunqiao/OpenPCDet\n",
      "2023-05-27 12:08:03,418   INFO  cfg.ROOT_DIR: /mnt/workspace/sunqiao/OpenPCDet\n",
      "2023-05-27 12:08:03,418   INFO  cfg.ROOT_DIR: /mnt/workspace/sunqiao/OpenPCDet\n",
      "2023-05-27 12:08:03,419   INFO  cfg.LOCAL_RANK: 0\n",
      "2023-05-27 12:08:03,419   INFO  cfg.LOCAL_RANK: 0\n",
      "2023-05-27 12:08:03,419   INFO  cfg.LOCAL_RANK: 0\n",
      "2023-05-27 12:08:03,419   INFO  cfg.LOCAL_RANK: 0\n",
      "2023-05-27 12:08:03,420   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2023-05-27 12:08:03,420   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2023-05-27 12:08:03,420   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2023-05-27 12:08:03,420   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2023-05-27 12:08:03,421   INFO  ----------- DATA_CONFIG -----------\n",
      "2023-05-27 12:08:03,421   INFO  ----------- DATA_CONFIG -----------\n",
      "2023-05-27 12:08:03,421   INFO  ----------- DATA_CONFIG -----------\n",
      "2023-05-27 12:08:03,421   INFO  ----------- DATA_CONFIG -----------\n",
      "2023-05-27 12:08:03,422   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2023-05-27 12:08:03,422   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2023-05-27 12:08:03,422   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2023-05-27 12:08:03,422   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2023-05-27 12:08:03,424   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti\n",
      "2023-05-27 12:08:03,424   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti\n",
      "2023-05-27 12:08:03,424   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti\n",
      "2023-05-27 12:08:03,424   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti\n",
      "2023-05-27 12:08:03,425   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]\n",
      "2023-05-27 12:08:03,425   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]\n",
      "2023-05-27 12:08:03,425   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]\n",
      "2023-05-27 12:08:03,425   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]\n",
      "2023-05-27 12:08:03,426   INFO  ----------- DATA_SPLIT -----------\n",
      "2023-05-27 12:08:03,426   INFO  ----------- DATA_SPLIT -----------\n",
      "2023-05-27 12:08:03,426   INFO  ----------- DATA_SPLIT -----------\n",
      "2023-05-27 12:08:03,426   INFO  ----------- DATA_SPLIT -----------\n",
      "2023-05-27 12:08:03,427   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2023-05-27 12:08:03,427   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2023-05-27 12:08:03,427   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2023-05-27 12:08:03,427   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2023-05-27 12:08:03,429   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2023-05-27 12:08:03,429   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2023-05-27 12:08:03,429   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2023-05-27 12:08:03,429   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2023-05-27 12:08:03,430   INFO  ----------- INFO_PATH -----------\n",
      "2023-05-27 12:08:03,430   INFO  ----------- INFO_PATH -----------\n",
      "2023-05-27 12:08:03,430   INFO  ----------- INFO_PATH -----------\n",
      "2023-05-27 12:08:03,430   INFO  ----------- INFO_PATH -----------\n",
      "2023-05-27 12:08:03,431   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2023-05-27 12:08:03,431   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2023-05-27 12:08:03,431   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2023-05-27 12:08:03,431   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2023-05-27 12:08:03,432   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2023-05-27 12:08:03,432   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2023-05-27 12:08:03,432   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2023-05-27 12:08:03,432   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2023-05-27 12:08:03,433   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']\n",
      "2023-05-27 12:08:03,433   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']\n",
      "2023-05-27 12:08:03,433   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']\n",
      "2023-05-27 12:08:03,433   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']\n",
      "2023-05-27 12:08:03,435   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2023-05-27 12:08:03,435   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2023-05-27 12:08:03,435   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2023-05-27 12:08:03,435   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2023-05-27 12:08:03,436   INFO  ----------- DATA_AUGMENTOR -----------\n",
      "2023-05-27 12:08:03,436   INFO  ----------- DATA_AUGMENTOR -----------\n",
      "2023-05-27 12:08:03,436   INFO  ----------- DATA_AUGMENTOR -----------\n",
      "2023-05-27 12:08:03,436   INFO  ----------- DATA_AUGMENTOR -----------\n",
      "2023-05-27 12:08:03,437   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2023-05-27 12:08:03,437   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2023-05-27 12:08:03,437   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2023-05-27 12:08:03,437   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2023-05-27 12:08:03,438   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2023-05-27 12:08:03,438   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2023-05-27 12:08:03,438   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2023-05-27 12:08:03,438   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2023-05-27 12:08:03,440   INFO  ----------- POINT_FEATURE_ENCODING -----------\n",
      "2023-05-27 12:08:03,440   INFO  ----------- POINT_FEATURE_ENCODING -----------\n",
      "2023-05-27 12:08:03,440   INFO  ----------- POINT_FEATURE_ENCODING -----------\n",
      "2023-05-27 12:08:03,440   INFO  ----------- POINT_FEATURE_ENCODING -----------\n",
      "2023-05-27 12:08:03,441   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2023-05-27 12:08:03,441   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2023-05-27 12:08:03,441   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2023-05-27 12:08:03,441   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2023-05-27 12:08:03,442   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,442   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,442   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,442   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,443   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,443   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,443   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,443   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-05-27 12:08:03,445   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]\n",
      "2023-05-27 12:08:03,445   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]\n",
      "2023-05-27 12:08:03,445   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]\n",
      "2023-05-27 12:08:03,445   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]\n",
      "2023-05-27 12:08:03,446   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml\n",
      "2023-05-27 12:08:03,446   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml\n",
      "2023-05-27 12:08:03,446   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml\n",
      "2023-05-27 12:08:03,446   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml\n",
      "2023-05-27 12:08:03,447   INFO  ----------- MODEL -----------\n",
      "2023-05-27 12:08:03,447   INFO  ----------- MODEL -----------\n",
      "2023-05-27 12:08:03,447   INFO  ----------- MODEL -----------\n",
      "2023-05-27 12:08:03,447   INFO  ----------- MODEL -----------\n",
      "2023-05-27 12:08:03,448   INFO  cfg.MODEL.NAME: PointPillar\n",
      "2023-05-27 12:08:03,448   INFO  cfg.MODEL.NAME: PointPillar\n",
      "2023-05-27 12:08:03,448   INFO  cfg.MODEL.NAME: PointPillar\n",
      "2023-05-27 12:08:03,448   INFO  cfg.MODEL.NAME: PointPillar\n",
      "2023-05-27 12:08:03,450   INFO  ----------- VFE -----------\n",
      "2023-05-27 12:08:03,450   INFO  ----------- VFE -----------\n",
      "2023-05-27 12:08:03,450   INFO  ----------- VFE -----------\n",
      "2023-05-27 12:08:03,450   INFO  ----------- VFE -----------\n",
      "2023-05-27 12:08:03,451   INFO  cfg.MODEL.VFE.NAME: PillarVFE\n",
      "2023-05-27 12:08:03,451   INFO  cfg.MODEL.VFE.NAME: PillarVFE\n",
      "2023-05-27 12:08:03,451   INFO  cfg.MODEL.VFE.NAME: PillarVFE\n",
      "2023-05-27 12:08:03,451   INFO  cfg.MODEL.VFE.NAME: PillarVFE\n",
      "2023-05-27 12:08:03,452   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False\n",
      "2023-05-27 12:08:03,452   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False\n",
      "2023-05-27 12:08:03,452   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False\n",
      "2023-05-27 12:08:03,452   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False\n",
      "2023-05-27 12:08:03,453   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True\n",
      "2023-05-27 12:08:03,453   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True\n",
      "2023-05-27 12:08:03,453   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True\n",
      "2023-05-27 12:08:03,453   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True\n",
      "2023-05-27 12:08:03,455   INFO  cfg.MODEL.VFE.USE_NORM: True\n",
      "2023-05-27 12:08:03,455   INFO  cfg.MODEL.VFE.USE_NORM: True\n",
      "2023-05-27 12:08:03,455   INFO  cfg.MODEL.VFE.USE_NORM: True\n",
      "2023-05-27 12:08:03,455   INFO  cfg.MODEL.VFE.USE_NORM: True\n",
      "2023-05-27 12:08:03,456   INFO  cfg.MODEL.VFE.USE_DO: True\n",
      "2023-05-27 12:08:03,456   INFO  cfg.MODEL.VFE.USE_DO: True\n",
      "2023-05-27 12:08:03,456   INFO  cfg.MODEL.VFE.USE_DO: True\n",
      "2023-05-27 12:08:03,456   INFO  cfg.MODEL.VFE.USE_DO: True\n",
      "2023-05-27 12:08:03,457   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]\n",
      "2023-05-27 12:08:03,457   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]\n",
      "2023-05-27 12:08:03,457   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]\n",
      "2023-05-27 12:08:03,457   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]\n",
      "2023-05-27 12:08:03,458   INFO  ----------- MAP_TO_BEV -----------\n",
      "2023-05-27 12:08:03,458   INFO  ----------- MAP_TO_BEV -----------\n",
      "2023-05-27 12:08:03,458   INFO  ----------- MAP_TO_BEV -----------\n",
      "2023-05-27 12:08:03,458   INFO  ----------- MAP_TO_BEV -----------\n",
      "2023-05-27 12:08:03,459   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter\n",
      "2023-05-27 12:08:03,459   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter\n",
      "2023-05-27 12:08:03,459   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter\n",
      "2023-05-27 12:08:03,459   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter\n",
      "2023-05-27 12:08:03,461   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64\n",
      "2023-05-27 12:08:03,461   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64\n",
      "2023-05-27 12:08:03,461   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64\n",
      "2023-05-27 12:08:03,461   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64\n",
      "2023-05-27 12:08:03,462   INFO  ----------- BACKBONE_2D -----------\n",
      "2023-05-27 12:08:03,462   INFO  ----------- BACKBONE_2D -----------\n",
      "2023-05-27 12:08:03,462   INFO  ----------- BACKBONE_2D -----------\n",
      "2023-05-27 12:08:03,462   INFO  ----------- BACKBONE_2D -----------\n",
      "2023-05-27 12:08:03,463   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone\n",
      "2023-05-27 12:08:03,463   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone\n",
      "2023-05-27 12:08:03,463   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone\n",
      "2023-05-27 12:08:03,463   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone\n",
      "2023-05-27 12:08:03,464   INFO  cfg.MODEL.BACKBONE_2D.USE_NORM: True\n",
      "2023-05-27 12:08:03,464   INFO  cfg.MODEL.BACKBONE_2D.USE_NORM: True\n",
      "2023-05-27 12:08:03,464   INFO  cfg.MODEL.BACKBONE_2D.USE_NORM: True\n",
      "2023-05-27 12:08:03,464   INFO  cfg.MODEL.BACKBONE_2D.USE_NORM: True\n",
      "2023-05-27 12:08:03,465   INFO  cfg.MODEL.BACKBONE_2D.USE_DO: True\n",
      "2023-05-27 12:08:03,465   INFO  cfg.MODEL.BACKBONE_2D.USE_DO: True\n",
      "2023-05-27 12:08:03,465   INFO  cfg.MODEL.BACKBONE_2D.USE_DO: True\n",
      "2023-05-27 12:08:03,465   INFO  cfg.MODEL.BACKBONE_2D.USE_DO: True\n",
      "2023-05-27 12:08:03,467   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]\n",
      "2023-05-27 12:08:03,467   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]\n",
      "2023-05-27 12:08:03,467   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]\n",
      "2023-05-27 12:08:03,467   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]\n",
      "2023-05-27 12:08:03,468   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]\n",
      "2023-05-27 12:08:03,468   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]\n",
      "2023-05-27 12:08:03,468   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]\n",
      "2023-05-27 12:08:03,468   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]\n",
      "2023-05-27 12:08:03,469   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]\n",
      "2023-05-27 12:08:03,469   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]\n",
      "2023-05-27 12:08:03,469   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]\n",
      "2023-05-27 12:08:03,469   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]\n",
      "2023-05-27 12:08:03,470   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]\n",
      "2023-05-27 12:08:03,470   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]\n",
      "2023-05-27 12:08:03,470   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]\n",
      "2023-05-27 12:08:03,470   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]\n",
      "2023-05-27 12:08:03,472   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]\n",
      "2023-05-27 12:08:03,472   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]\n",
      "2023-05-27 12:08:03,472   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]\n",
      "2023-05-27 12:08:03,472   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]\n",
      "2023-05-27 12:08:03,473   INFO  ----------- DENSE_HEAD -----------\n",
      "2023-05-27 12:08:03,473   INFO  ----------- DENSE_HEAD -----------\n",
      "2023-05-27 12:08:03,473   INFO  ----------- DENSE_HEAD -----------\n",
      "2023-05-27 12:08:03,473   INFO  ----------- DENSE_HEAD -----------\n",
      "2023-05-27 12:08:03,474   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle\n",
      "2023-05-27 12:08:03,474   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle\n",
      "2023-05-27 12:08:03,474   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle\n",
      "2023-05-27 12:08:03,474   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle\n",
      "2023-05-27 12:08:03,475   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False\n",
      "2023-05-27 12:08:03,475   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False\n",
      "2023-05-27 12:08:03,475   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False\n",
      "2023-05-27 12:08:03,475   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False\n",
      "2023-05-27 12:08:03,476   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True\n",
      "2023-05-27 12:08:03,476   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True\n",
      "2023-05-27 12:08:03,476   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True\n",
      "2023-05-27 12:08:03,476   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True\n",
      "2023-05-27 12:08:03,478   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539\n",
      "2023-05-27 12:08:03,478   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539\n",
      "2023-05-27 12:08:03,478   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539\n",
      "2023-05-27 12:08:03,478   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539\n",
      "2023-05-27 12:08:03,479   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0\n",
      "2023-05-27 12:08:03,479   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0\n",
      "2023-05-27 12:08:03,479   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0\n",
      "2023-05-27 12:08:03,479   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0\n",
      "2023-05-27 12:08:03,480   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2\n",
      "2023-05-27 12:08:03,480   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2\n",
      "2023-05-27 12:08:03,480   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2\n",
      "2023-05-27 12:08:03,480   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2\n",
      "2023-05-27 12:08:03,481   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]\n",
      "2023-05-27 12:08:03,481   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]\n",
      "2023-05-27 12:08:03,481   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]\n",
      "2023-05-27 12:08:03,481   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]\n",
      "2023-05-27 12:08:03,483   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------\n",
      "2023-05-27 12:08:03,483   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------\n",
      "2023-05-27 12:08:03,483   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------\n",
      "2023-05-27 12:08:03,483   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------\n",
      "2023-05-27 12:08:03,484   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner\n",
      "2023-05-27 12:08:03,484   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner\n",
      "2023-05-27 12:08:03,484   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner\n",
      "2023-05-27 12:08:03,484   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner\n",
      "2023-05-27 12:08:03,485   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0\n",
      "2023-05-27 12:08:03,485   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0\n",
      "2023-05-27 12:08:03,485   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0\n",
      "2023-05-27 12:08:03,485   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0\n",
      "2023-05-27 12:08:03,486   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512\n",
      "2023-05-27 12:08:03,486   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512\n",
      "2023-05-27 12:08:03,486   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512\n",
      "2023-05-27 12:08:03,486   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512\n",
      "2023-05-27 12:08:03,488   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False\n",
      "2023-05-27 12:08:03,488   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False\n",
      "2023-05-27 12:08:03,488   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False\n",
      "2023-05-27 12:08:03,488   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False\n",
      "2023-05-27 12:08:03,489   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False\n",
      "2023-05-27 12:08:03,489   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False\n",
      "2023-05-27 12:08:03,489   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False\n",
      "2023-05-27 12:08:03,489   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False\n",
      "2023-05-27 12:08:03,490   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder\n",
      "2023-05-27 12:08:03,490   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder\n",
      "2023-05-27 12:08:03,490   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder\n",
      "2023-05-27 12:08:03,490   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder\n",
      "2023-05-27 12:08:03,491   INFO  ----------- LOSS_CONFIG -----------\n",
      "2023-05-27 12:08:03,491   INFO  ----------- LOSS_CONFIG -----------\n",
      "2023-05-27 12:08:03,491   INFO  ----------- LOSS_CONFIG -----------\n",
      "2023-05-27 12:08:03,491   INFO  ----------- LOSS_CONFIG -----------\n",
      "2023-05-27 12:08:03,492   INFO  ----------- LOSS_WEIGHTS -----------\n",
      "2023-05-27 12:08:03,492   INFO  ----------- LOSS_WEIGHTS -----------\n",
      "2023-05-27 12:08:03,492   INFO  ----------- LOSS_WEIGHTS -----------\n",
      "2023-05-27 12:08:03,492   INFO  ----------- LOSS_WEIGHTS -----------\n",
      "2023-05-27 12:08:03,494   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0\n",
      "2023-05-27 12:08:03,494   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0\n",
      "2023-05-27 12:08:03,494   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0\n",
      "2023-05-27 12:08:03,494   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0\n",
      "2023-05-27 12:08:03,495   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0\n",
      "2023-05-27 12:08:03,495   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0\n",
      "2023-05-27 12:08:03,495   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0\n",
      "2023-05-27 12:08:03,495   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0\n",
      "2023-05-27 12:08:03,496   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2\n",
      "2023-05-27 12:08:03,496   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2\n",
      "2023-05-27 12:08:03,496   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2\n",
      "2023-05-27 12:08:03,496   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2\n",
      "2023-05-27 12:08:03,497   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-05-27 12:08:03,497   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-05-27 12:08:03,497   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-05-27 12:08:03,497   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-05-27 12:08:03,498   INFO  ----------- POST_PROCESSING -----------\n",
      "2023-05-27 12:08:03,498   INFO  ----------- POST_PROCESSING -----------\n",
      "2023-05-27 12:08:03,498   INFO  ----------- POST_PROCESSING -----------\n",
      "2023-05-27 12:08:03,498   INFO  ----------- POST_PROCESSING -----------\n",
      "2023-05-27 12:08:03,500   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2023-05-27 12:08:03,500   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2023-05-27 12:08:03,500   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2023-05-27 12:08:03,500   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2023-05-27 12:08:03,501   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2023-05-27 12:08:03,501   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2023-05-27 12:08:03,501   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2023-05-27 12:08:03,501   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2023-05-27 12:08:03,502   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2023-05-27 12:08:03,502   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2023-05-27 12:08:03,502   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2023-05-27 12:08:03,502   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2023-05-27 12:08:03,503   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2023-05-27 12:08:03,503   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2023-05-27 12:08:03,503   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2023-05-27 12:08:03,503   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2023-05-27 12:08:03,505   INFO  ----------- NMS_CONFIG -----------\n",
      "2023-05-27 12:08:03,505   INFO  ----------- NMS_CONFIG -----------\n",
      "2023-05-27 12:08:03,505   INFO  ----------- NMS_CONFIG -----------\n",
      "2023-05-27 12:08:03,505   INFO  ----------- NMS_CONFIG -----------\n",
      "2023-05-27 12:08:03,506   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2023-05-27 12:08:03,506   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2023-05-27 12:08:03,506   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2023-05-27 12:08:03,506   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2023-05-27 12:08:03,507   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2023-05-27 12:08:03,507   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2023-05-27 12:08:03,507   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2023-05-27 12:08:03,507   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2023-05-27 12:08:03,508   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01\n",
      "2023-05-27 12:08:03,508   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01\n",
      "2023-05-27 12:08:03,508   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01\n",
      "2023-05-27 12:08:03,508   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01\n",
      "2023-05-27 12:08:03,509   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2023-05-27 12:08:03,509   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2023-05-27 12:08:03,509   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2023-05-27 12:08:03,509   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2023-05-27 12:08:03,511   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2023-05-27 12:08:03,511   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2023-05-27 12:08:03,511   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2023-05-27 12:08:03,511   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2023-05-27 12:08:03,512   INFO  ----------- OPTIMIZATION -----------\n",
      "2023-05-27 12:08:03,512   INFO  ----------- OPTIMIZATION -----------\n",
      "2023-05-27 12:08:03,512   INFO  ----------- OPTIMIZATION -----------\n",
      "2023-05-27 12:08:03,512   INFO  ----------- OPTIMIZATION -----------\n",
      "2023-05-27 12:08:03,514   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4\n",
      "2023-05-27 12:08:03,514   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4\n",
      "2023-05-27 12:08:03,514   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4\n",
      "2023-05-27 12:08:03,514   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4\n",
      "2023-05-27 12:08:03,515   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2023-05-27 12:08:03,515   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2023-05-27 12:08:03,515   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2023-05-27 12:08:03,515   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2023-05-27 12:08:03,516   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2023-05-27 12:08:03,516   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2023-05-27 12:08:03,516   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2023-05-27 12:08:03,516   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2023-05-27 12:08:03,517   INFO  cfg.OPTIMIZATION.LR: 0.003\n",
      "2023-05-27 12:08:03,517   INFO  cfg.OPTIMIZATION.LR: 0.003\n",
      "2023-05-27 12:08:03,517   INFO  cfg.OPTIMIZATION.LR: 0.003\n",
      "2023-05-27 12:08:03,517   INFO  cfg.OPTIMIZATION.LR: 0.003\n",
      "2023-05-27 12:08:03,519   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2023-05-27 12:08:03,519   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2023-05-27 12:08:03,519   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2023-05-27 12:08:03,519   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2023-05-27 12:08:03,520   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2023-05-27 12:08:03,520   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2023-05-27 12:08:03,520   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2023-05-27 12:08:03,520   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2023-05-27 12:08:03,521   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2023-05-27 12:08:03,521   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2023-05-27 12:08:03,521   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2023-05-27 12:08:03,521   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2023-05-27 12:08:03,522   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2023-05-27 12:08:03,522   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2023-05-27 12:08:03,522   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2023-05-27 12:08:03,522   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2023-05-27 12:08:03,523   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2023-05-27 12:08:03,523   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2023-05-27 12:08:03,523   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2023-05-27 12:08:03,523   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2023-05-27 12:08:03,525   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2023-05-27 12:08:03,525   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2023-05-27 12:08:03,525   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2023-05-27 12:08:03,525   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2023-05-27 12:08:03,526   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2023-05-27 12:08:03,526   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2023-05-27 12:08:03,526   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2023-05-27 12:08:03,526   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2023-05-27 12:08:03,527   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2023-05-27 12:08:03,527   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2023-05-27 12:08:03,527   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2023-05-27 12:08:03,527   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2023-05-27 12:08:03,528   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2023-05-27 12:08:03,528   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2023-05-27 12:08:03,528   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2023-05-27 12:08:03,528   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2023-05-27 12:08:03,529   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2023-05-27 12:08:03,529   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2023-05-27 12:08:03,529   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2023-05-27 12:08:03,529   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2023-05-27 12:08:03,531   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2023-05-27 12:08:03,531   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2023-05-27 12:08:03,531   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2023-05-27 12:08:03,531   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2023-05-27 12:08:03,532   INFO  cfg.TAG: pointpillar_bayes\n",
      "2023-05-27 12:08:03,532   INFO  cfg.TAG: pointpillar_bayes\n",
      "2023-05-27 12:08:03,532   INFO  cfg.TAG: pointpillar_bayes\n",
      "2023-05-27 12:08:03,532   INFO  cfg.TAG: pointpillar_bayes\n",
      "2023-05-27 12:08:03,533   INFO  cfg.EXP_GROUP_PATH: cfgs/kitti_models\n",
      "2023-05-27 12:08:03,533   INFO  cfg.EXP_GROUP_PATH: cfgs/kitti_models\n",
      "2023-05-27 12:08:03,533   INFO  cfg.EXP_GROUP_PATH: cfgs/kitti_models\n",
      "2023-05-27 12:08:03,533   INFO  cfg.EXP_GROUP_PATH: cfgs/kitti_models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n",
      "=============\n",
      "0.11 0.11\n",
      "=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 12:08:03,668   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2023-05-27 12:08:03,668   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2023-05-27 12:08:03,668   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2023-05-27 12:08:03,668   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2023-05-27 12:08:03,670   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2023-05-27 12:08:03,670   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2023-05-27 12:08:03,670   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2023-05-27 12:08:03,670   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2023-05-27 12:08:03,672   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2023-05-27 12:08:03,672   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2023-05-27 12:08:03,672   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2023-05-27 12:08:03,672   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2023-05-27 12:08:03,688   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2023-05-27 12:08:03,688   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2023-05-27 12:08:03,688   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2023-05-27 12:08:03,688   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2023-05-27 12:08:03,692   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2023-05-27 12:08:03,692   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2023-05-27 12:08:03,692   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2023-05-27 12:08:03,692   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2023-05-27 12:08:03,694   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2023-05-27 12:08:03,694   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2023-05-27 12:08:03,694   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2023-05-27 12:08:03,694   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2023-05-27 12:08:03,700   INFO  Loading KITTI dataset\n",
      "2023-05-27 12:08:03,700   INFO  Loading KITTI dataset\n",
      "2023-05-27 12:08:03,700   INFO  Loading KITTI dataset\n",
      "2023-05-27 12:08:03,700   INFO  Loading KITTI dataset\n",
      "2023-05-27 12:08:03,785   INFO  Total samples for KITTI dataset: 3712\n",
      "2023-05-27 12:08:03,785   INFO  Total samples for KITTI dataset: 3712\n",
      "2023-05-27 12:08:03,785   INFO  Total samples for KITTI dataset: 3712\n",
      "2023-05-27 12:08:03,785   INFO  Total samples for KITTI dataset: 3712\n",
      "2023-05-27 12:08:03,827   INFO  ==> Loading parameters from checkpoint ./checkpoint_epoch_80.pth to CPU\n",
      "2023-05-27 12:08:03,827   INFO  ==> Loading parameters from checkpoint ./checkpoint_epoch_80.pth to CPU\n",
      "2023-05-27 12:08:03,827   INFO  ==> Loading parameters from checkpoint ./checkpoint_epoch_80.pth to CPU\n",
      "2023-05-27 12:08:03,827   INFO  ==> Loading parameters from checkpoint ./checkpoint_epoch_80.pth to CPU\n",
      "2023-05-27 12:08:03,887   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+26a1612\n",
      "2023-05-27 12:08:03,887   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+26a1612\n",
      "2023-05-27 12:08:03,887   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+26a1612\n",
      "2023-05-27 12:08:03,887   INFO  ==> Checkpoint trained from version: pcdet+0.3.0+26a1612\n",
      "2023-05-27 12:08:03,967   INFO  Not updated weight backbone_2d.blocks.0.5.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,967   INFO  Not updated weight backbone_2d.blocks.0.5.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,967   INFO  Not updated weight backbone_2d.blocks.0.5.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,967   INFO  Not updated weight backbone_2d.blocks.0.5.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,968   INFO  Not updated weight backbone_2d.blocks.0.6.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,968   INFO  Not updated weight backbone_2d.blocks.0.6.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,968   INFO  Not updated weight backbone_2d.blocks.0.6.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,968   INFO  Not updated weight backbone_2d.blocks.0.6.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,970   INFO  Not updated weight backbone_2d.blocks.0.6.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,970   INFO  Not updated weight backbone_2d.blocks.0.6.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,970   INFO  Not updated weight backbone_2d.blocks.0.6.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,970   INFO  Not updated weight backbone_2d.blocks.0.6.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,971   INFO  Not updated weight backbone_2d.blocks.0.6.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,971   INFO  Not updated weight backbone_2d.blocks.0.6.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,971   INFO  Not updated weight backbone_2d.blocks.0.6.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,971   INFO  Not updated weight backbone_2d.blocks.0.6.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,972   INFO  Not updated weight backbone_2d.blocks.0.6.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,972   INFO  Not updated weight backbone_2d.blocks.0.6.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,972   INFO  Not updated weight backbone_2d.blocks.0.6.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,972   INFO  Not updated weight backbone_2d.blocks.0.6.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,973   INFO  Not updated weight backbone_2d.blocks.0.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,973   INFO  Not updated weight backbone_2d.blocks.0.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,973   INFO  Not updated weight backbone_2d.blocks.0.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,973   INFO  Not updated weight backbone_2d.blocks.0.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,974   INFO  Not updated weight backbone_2d.blocks.0.9.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,974   INFO  Not updated weight backbone_2d.blocks.0.9.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,974   INFO  Not updated weight backbone_2d.blocks.0.9.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,974   INFO  Not updated weight backbone_2d.blocks.0.9.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,976   INFO  Not updated weight backbone_2d.blocks.0.10.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,976   INFO  Not updated weight backbone_2d.blocks.0.10.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,976   INFO  Not updated weight backbone_2d.blocks.0.10.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,976   INFO  Not updated weight backbone_2d.blocks.0.10.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,977   INFO  Not updated weight backbone_2d.blocks.0.10.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,977   INFO  Not updated weight backbone_2d.blocks.0.10.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,977   INFO  Not updated weight backbone_2d.blocks.0.10.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,977   INFO  Not updated weight backbone_2d.blocks.0.10.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,978   INFO  Not updated weight backbone_2d.blocks.0.10.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,978   INFO  Not updated weight backbone_2d.blocks.0.10.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,978   INFO  Not updated weight backbone_2d.blocks.0.10.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,978   INFO  Not updated weight backbone_2d.blocks.0.10.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,979   INFO  Not updated weight backbone_2d.blocks.0.10.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,979   INFO  Not updated weight backbone_2d.blocks.0.10.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,979   INFO  Not updated weight backbone_2d.blocks.0.10.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,979   INFO  Not updated weight backbone_2d.blocks.0.10.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,981   INFO  Not updated weight backbone_2d.blocks.0.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,981   INFO  Not updated weight backbone_2d.blocks.0.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,981   INFO  Not updated weight backbone_2d.blocks.0.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,981   INFO  Not updated weight backbone_2d.blocks.0.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,982   INFO  Not updated weight backbone_2d.blocks.0.13.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,982   INFO  Not updated weight backbone_2d.blocks.0.13.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,982   INFO  Not updated weight backbone_2d.blocks.0.13.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,982   INFO  Not updated weight backbone_2d.blocks.0.13.weight: torch.Size([64, 64, 3, 3])\n",
      "2023-05-27 12:08:03,983   INFO  Not updated weight backbone_2d.blocks.0.14.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,983   INFO  Not updated weight backbone_2d.blocks.0.14.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,983   INFO  Not updated weight backbone_2d.blocks.0.14.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,983   INFO  Not updated weight backbone_2d.blocks.0.14.weight: torch.Size([64])\n",
      "2023-05-27 12:08:03,984   INFO  Not updated weight backbone_2d.blocks.0.14.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,984   INFO  Not updated weight backbone_2d.blocks.0.14.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,984   INFO  Not updated weight backbone_2d.blocks.0.14.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,984   INFO  Not updated weight backbone_2d.blocks.0.14.bias: torch.Size([64])\n",
      "2023-05-27 12:08:03,986   INFO  Not updated weight backbone_2d.blocks.0.14.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,986   INFO  Not updated weight backbone_2d.blocks.0.14.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,986   INFO  Not updated weight backbone_2d.blocks.0.14.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,986   INFO  Not updated weight backbone_2d.blocks.0.14.running_mean: torch.Size([64])\n",
      "2023-05-27 12:08:03,987   INFO  Not updated weight backbone_2d.blocks.0.14.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,987   INFO  Not updated weight backbone_2d.blocks.0.14.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,987   INFO  Not updated weight backbone_2d.blocks.0.14.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,987   INFO  Not updated weight backbone_2d.blocks.0.14.running_var: torch.Size([64])\n",
      "2023-05-27 12:08:03,988   INFO  Not updated weight backbone_2d.blocks.0.14.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,988   INFO  Not updated weight backbone_2d.blocks.0.14.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,988   INFO  Not updated weight backbone_2d.blocks.0.14.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,988   INFO  Not updated weight backbone_2d.blocks.0.14.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,989   INFO  Not updated weight backbone_2d.blocks.1.5.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,989   INFO  Not updated weight backbone_2d.blocks.1.5.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,989   INFO  Not updated weight backbone_2d.blocks.1.5.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,989   INFO  Not updated weight backbone_2d.blocks.1.5.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,991   INFO  Not updated weight backbone_2d.blocks.1.6.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,991   INFO  Not updated weight backbone_2d.blocks.1.6.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,991   INFO  Not updated weight backbone_2d.blocks.1.6.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,991   INFO  Not updated weight backbone_2d.blocks.1.6.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,992   INFO  Not updated weight backbone_2d.blocks.1.6.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,992   INFO  Not updated weight backbone_2d.blocks.1.6.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,992   INFO  Not updated weight backbone_2d.blocks.1.6.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,992   INFO  Not updated weight backbone_2d.blocks.1.6.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,993   INFO  Not updated weight backbone_2d.blocks.1.6.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:03,993   INFO  Not updated weight backbone_2d.blocks.1.6.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:03,993   INFO  Not updated weight backbone_2d.blocks.1.6.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:03,993   INFO  Not updated weight backbone_2d.blocks.1.6.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:03,994   INFO  Not updated weight backbone_2d.blocks.1.6.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:03,994   INFO  Not updated weight backbone_2d.blocks.1.6.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:03,994   INFO  Not updated weight backbone_2d.blocks.1.6.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:03,994   INFO  Not updated weight backbone_2d.blocks.1.6.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:03,996   INFO  Not updated weight backbone_2d.blocks.1.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,996   INFO  Not updated weight backbone_2d.blocks.1.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,996   INFO  Not updated weight backbone_2d.blocks.1.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,996   INFO  Not updated weight backbone_2d.blocks.1.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:03,997   INFO  Not updated weight backbone_2d.blocks.1.9.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,997   INFO  Not updated weight backbone_2d.blocks.1.9.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,997   INFO  Not updated weight backbone_2d.blocks.1.9.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,997   INFO  Not updated weight backbone_2d.blocks.1.9.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:03,998   INFO  Not updated weight backbone_2d.blocks.1.10.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,998   INFO  Not updated weight backbone_2d.blocks.1.10.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,998   INFO  Not updated weight backbone_2d.blocks.1.10.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,998   INFO  Not updated weight backbone_2d.blocks.1.10.weight: torch.Size([128])\n",
      "2023-05-27 12:08:03,999   INFO  Not updated weight backbone_2d.blocks.1.10.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,999   INFO  Not updated weight backbone_2d.blocks.1.10.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,999   INFO  Not updated weight backbone_2d.blocks.1.10.bias: torch.Size([128])\n",
      "2023-05-27 12:08:03,999   INFO  Not updated weight backbone_2d.blocks.1.10.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,001   INFO  Not updated weight backbone_2d.blocks.1.10.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,001   INFO  Not updated weight backbone_2d.blocks.1.10.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,001   INFO  Not updated weight backbone_2d.blocks.1.10.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,001   INFO  Not updated weight backbone_2d.blocks.1.10.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,002   INFO  Not updated weight backbone_2d.blocks.1.10.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,002   INFO  Not updated weight backbone_2d.blocks.1.10.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,002   INFO  Not updated weight backbone_2d.blocks.1.10.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,002   INFO  Not updated weight backbone_2d.blocks.1.10.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,003   INFO  Not updated weight backbone_2d.blocks.1.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,003   INFO  Not updated weight backbone_2d.blocks.1.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,003   INFO  Not updated weight backbone_2d.blocks.1.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,003   INFO  Not updated weight backbone_2d.blocks.1.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,004   INFO  Not updated weight backbone_2d.blocks.1.17.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,004   INFO  Not updated weight backbone_2d.blocks.1.17.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,004   INFO  Not updated weight backbone_2d.blocks.1.17.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,004   INFO  Not updated weight backbone_2d.blocks.1.17.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,006   INFO  Not updated weight backbone_2d.blocks.1.18.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,006   INFO  Not updated weight backbone_2d.blocks.1.18.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,006   INFO  Not updated weight backbone_2d.blocks.1.18.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,006   INFO  Not updated weight backbone_2d.blocks.1.18.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,007   INFO  Not updated weight backbone_2d.blocks.1.18.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,007   INFO  Not updated weight backbone_2d.blocks.1.18.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,007   INFO  Not updated weight backbone_2d.blocks.1.18.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,007   INFO  Not updated weight backbone_2d.blocks.1.18.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,008   INFO  Not updated weight backbone_2d.blocks.1.18.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,008   INFO  Not updated weight backbone_2d.blocks.1.18.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,008   INFO  Not updated weight backbone_2d.blocks.1.18.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,008   INFO  Not updated weight backbone_2d.blocks.1.18.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,009   INFO  Not updated weight backbone_2d.blocks.1.18.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,009   INFO  Not updated weight backbone_2d.blocks.1.18.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,009   INFO  Not updated weight backbone_2d.blocks.1.18.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,009   INFO  Not updated weight backbone_2d.blocks.1.18.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,010   INFO  Not updated weight backbone_2d.blocks.1.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,010   INFO  Not updated weight backbone_2d.blocks.1.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,010   INFO  Not updated weight backbone_2d.blocks.1.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,010   INFO  Not updated weight backbone_2d.blocks.1.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,012   INFO  Not updated weight backbone_2d.blocks.1.21.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,012   INFO  Not updated weight backbone_2d.blocks.1.21.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,012   INFO  Not updated weight backbone_2d.blocks.1.21.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,012   INFO  Not updated weight backbone_2d.blocks.1.21.weight: torch.Size([128, 128, 3, 3])\n",
      "2023-05-27 12:08:04,013   INFO  Not updated weight backbone_2d.blocks.1.22.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,013   INFO  Not updated weight backbone_2d.blocks.1.22.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,013   INFO  Not updated weight backbone_2d.blocks.1.22.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,013   INFO  Not updated weight backbone_2d.blocks.1.22.weight: torch.Size([128])\n",
      "2023-05-27 12:08:04,014   INFO  Not updated weight backbone_2d.blocks.1.22.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,014   INFO  Not updated weight backbone_2d.blocks.1.22.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,014   INFO  Not updated weight backbone_2d.blocks.1.22.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,014   INFO  Not updated weight backbone_2d.blocks.1.22.bias: torch.Size([128])\n",
      "2023-05-27 12:08:04,015   INFO  Not updated weight backbone_2d.blocks.1.22.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,015   INFO  Not updated weight backbone_2d.blocks.1.22.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,015   INFO  Not updated weight backbone_2d.blocks.1.22.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,015   INFO  Not updated weight backbone_2d.blocks.1.22.running_mean: torch.Size([128])\n",
      "2023-05-27 12:08:04,017   INFO  Not updated weight backbone_2d.blocks.1.22.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,017   INFO  Not updated weight backbone_2d.blocks.1.22.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,017   INFO  Not updated weight backbone_2d.blocks.1.22.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,017   INFO  Not updated weight backbone_2d.blocks.1.22.running_var: torch.Size([128])\n",
      "2023-05-27 12:08:04,018   INFO  Not updated weight backbone_2d.blocks.1.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,018   INFO  Not updated weight backbone_2d.blocks.1.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,018   INFO  Not updated weight backbone_2d.blocks.1.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,018   INFO  Not updated weight backbone_2d.blocks.1.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,019   INFO  Not updated weight backbone_2d.blocks.2.5.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,019   INFO  Not updated weight backbone_2d.blocks.2.5.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,019   INFO  Not updated weight backbone_2d.blocks.2.5.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,019   INFO  Not updated weight backbone_2d.blocks.2.5.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,020   INFO  Not updated weight backbone_2d.blocks.2.6.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,020   INFO  Not updated weight backbone_2d.blocks.2.6.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,020   INFO  Not updated weight backbone_2d.blocks.2.6.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,020   INFO  Not updated weight backbone_2d.blocks.2.6.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,022   INFO  Not updated weight backbone_2d.blocks.2.6.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,022   INFO  Not updated weight backbone_2d.blocks.2.6.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,022   INFO  Not updated weight backbone_2d.blocks.2.6.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,022   INFO  Not updated weight backbone_2d.blocks.2.6.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,023   INFO  Not updated weight backbone_2d.blocks.2.6.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,023   INFO  Not updated weight backbone_2d.blocks.2.6.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,023   INFO  Not updated weight backbone_2d.blocks.2.6.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,023   INFO  Not updated weight backbone_2d.blocks.2.6.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,024   INFO  Not updated weight backbone_2d.blocks.2.6.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,024   INFO  Not updated weight backbone_2d.blocks.2.6.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,024   INFO  Not updated weight backbone_2d.blocks.2.6.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,024   INFO  Not updated weight backbone_2d.blocks.2.6.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,025   INFO  Not updated weight backbone_2d.blocks.2.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,025   INFO  Not updated weight backbone_2d.blocks.2.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,025   INFO  Not updated weight backbone_2d.blocks.2.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,025   INFO  Not updated weight backbone_2d.blocks.2.6.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,027   INFO  Not updated weight backbone_2d.blocks.2.9.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,027   INFO  Not updated weight backbone_2d.blocks.2.9.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,027   INFO  Not updated weight backbone_2d.blocks.2.9.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,027   INFO  Not updated weight backbone_2d.blocks.2.9.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,028   INFO  Not updated weight backbone_2d.blocks.2.10.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,028   INFO  Not updated weight backbone_2d.blocks.2.10.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,028   INFO  Not updated weight backbone_2d.blocks.2.10.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,028   INFO  Not updated weight backbone_2d.blocks.2.10.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,029   INFO  Not updated weight backbone_2d.blocks.2.10.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,029   INFO  Not updated weight backbone_2d.blocks.2.10.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,029   INFO  Not updated weight backbone_2d.blocks.2.10.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,029   INFO  Not updated weight backbone_2d.blocks.2.10.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,030   INFO  Not updated weight backbone_2d.blocks.2.10.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,030   INFO  Not updated weight backbone_2d.blocks.2.10.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,030   INFO  Not updated weight backbone_2d.blocks.2.10.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,030   INFO  Not updated weight backbone_2d.blocks.2.10.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,032   INFO  Not updated weight backbone_2d.blocks.2.10.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,032   INFO  Not updated weight backbone_2d.blocks.2.10.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,032   INFO  Not updated weight backbone_2d.blocks.2.10.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,032   INFO  Not updated weight backbone_2d.blocks.2.10.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,033   INFO  Not updated weight backbone_2d.blocks.2.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,033   INFO  Not updated weight backbone_2d.blocks.2.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,033   INFO  Not updated weight backbone_2d.blocks.2.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,033   INFO  Not updated weight backbone_2d.blocks.2.10.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,034   INFO  Not updated weight backbone_2d.blocks.2.17.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,034   INFO  Not updated weight backbone_2d.blocks.2.17.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,034   INFO  Not updated weight backbone_2d.blocks.2.17.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,034   INFO  Not updated weight backbone_2d.blocks.2.17.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,035   INFO  Not updated weight backbone_2d.blocks.2.18.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,035   INFO  Not updated weight backbone_2d.blocks.2.18.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,035   INFO  Not updated weight backbone_2d.blocks.2.18.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,035   INFO  Not updated weight backbone_2d.blocks.2.18.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,037   INFO  Not updated weight backbone_2d.blocks.2.18.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,037   INFO  Not updated weight backbone_2d.blocks.2.18.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,037   INFO  Not updated weight backbone_2d.blocks.2.18.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,037   INFO  Not updated weight backbone_2d.blocks.2.18.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,038   INFO  Not updated weight backbone_2d.blocks.2.18.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,038   INFO  Not updated weight backbone_2d.blocks.2.18.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,038   INFO  Not updated weight backbone_2d.blocks.2.18.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,038   INFO  Not updated weight backbone_2d.blocks.2.18.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,039   INFO  Not updated weight backbone_2d.blocks.2.18.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,039   INFO  Not updated weight backbone_2d.blocks.2.18.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,039   INFO  Not updated weight backbone_2d.blocks.2.18.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,039   INFO  Not updated weight backbone_2d.blocks.2.18.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,040   INFO  Not updated weight backbone_2d.blocks.2.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,040   INFO  Not updated weight backbone_2d.blocks.2.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,040   INFO  Not updated weight backbone_2d.blocks.2.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,040   INFO  Not updated weight backbone_2d.blocks.2.18.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,042   INFO  Not updated weight backbone_2d.blocks.2.21.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,042   INFO  Not updated weight backbone_2d.blocks.2.21.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,042   INFO  Not updated weight backbone_2d.blocks.2.21.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,042   INFO  Not updated weight backbone_2d.blocks.2.21.weight: torch.Size([256, 256, 3, 3])\n",
      "2023-05-27 12:08:04,043   INFO  Not updated weight backbone_2d.blocks.2.22.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,043   INFO  Not updated weight backbone_2d.blocks.2.22.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,043   INFO  Not updated weight backbone_2d.blocks.2.22.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,043   INFO  Not updated weight backbone_2d.blocks.2.22.weight: torch.Size([256])\n",
      "2023-05-27 12:08:04,044   INFO  Not updated weight backbone_2d.blocks.2.22.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,044   INFO  Not updated weight backbone_2d.blocks.2.22.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,044   INFO  Not updated weight backbone_2d.blocks.2.22.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,044   INFO  Not updated weight backbone_2d.blocks.2.22.bias: torch.Size([256])\n",
      "2023-05-27 12:08:04,045   INFO  Not updated weight backbone_2d.blocks.2.22.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,045   INFO  Not updated weight backbone_2d.blocks.2.22.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,045   INFO  Not updated weight backbone_2d.blocks.2.22.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,045   INFO  Not updated weight backbone_2d.blocks.2.22.running_mean: torch.Size([256])\n",
      "2023-05-27 12:08:04,046   INFO  Not updated weight backbone_2d.blocks.2.22.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,046   INFO  Not updated weight backbone_2d.blocks.2.22.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,046   INFO  Not updated weight backbone_2d.blocks.2.22.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,046   INFO  Not updated weight backbone_2d.blocks.2.22.running_var: torch.Size([256])\n",
      "2023-05-27 12:08:04,048   INFO  Not updated weight backbone_2d.blocks.2.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,048   INFO  Not updated weight backbone_2d.blocks.2.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,048   INFO  Not updated weight backbone_2d.blocks.2.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,048   INFO  Not updated weight backbone_2d.blocks.2.22.num_batches_tracked: torch.Size([])\n",
      "2023-05-27 12:08:04,050   INFO  ==> Done (loaded 61/127)\n",
      "2023-05-27 12:08:04,050   INFO  ==> Done (loaded 61/127)\n",
      "2023-05-27 12:08:04,050   INFO  ==> Done (loaded 61/127)\n",
      "2023-05-27 12:08:04,050   INFO  ==> Done (loaded 61/127)\n",
      "2023-05-27 12:08:04,051   INFO  PointPillar(\n",
      "  (vfe): PillarVFE(\n",
      "    (pfn_layers): ModuleList(\n",
      "      (0): PFNLayer(\n",
      "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
      "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (do): Dropout(p=0.11, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone_3d): None\n",
      "  (map_to_bev_module): PointPillarScatter()\n",
      "  (pfe): None\n",
      "  (backbone_2d): BaseBEVBackbone(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (deblocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dense_head): AnchorHeadSingle(\n",
      "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "    (reg_loss_func): WeightedSmoothL1Loss()\n",
      "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (point_head): None\n",
      "  (roi_head): None\n",
      ")\n",
      "2023-05-27 12:08:04,051   INFO  PointPillar(\n",
      "  (vfe): PillarVFE(\n",
      "    (pfn_layers): ModuleList(\n",
      "      (0): PFNLayer(\n",
      "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
      "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (do): Dropout(p=0.11, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone_3d): None\n",
      "  (map_to_bev_module): PointPillarScatter()\n",
      "  (pfe): None\n",
      "  (backbone_2d): BaseBEVBackbone(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (deblocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dense_head): AnchorHeadSingle(\n",
      "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "    (reg_loss_func): WeightedSmoothL1Loss()\n",
      "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (point_head): None\n",
      "  (roi_head): None\n",
      ")\n",
      "2023-05-27 12:08:04,051   INFO  PointPillar(\n",
      "  (vfe): PillarVFE(\n",
      "    (pfn_layers): ModuleList(\n",
      "      (0): PFNLayer(\n",
      "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
      "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (do): Dropout(p=0.11, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone_3d): None\n",
      "  (map_to_bev_module): PointPillarScatter()\n",
      "  (pfe): None\n",
      "  (backbone_2d): BaseBEVBackbone(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (deblocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dense_head): AnchorHeadSingle(\n",
      "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "    (reg_loss_func): WeightedSmoothL1Loss()\n",
      "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (point_head): None\n",
      "  (roi_head): None\n",
      ")\n",
      "2023-05-27 12:08:04,051   INFO  PointPillar(\n",
      "  (vfe): PillarVFE(\n",
      "    (pfn_layers): ModuleList(\n",
      "      (0): PFNLayer(\n",
      "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
      "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (do): Dropout(p=0.11, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone_3d): None\n",
      "  (map_to_bev_module): PointPillarScatter()\n",
      "  (pfe): None\n",
      "  (backbone_2d): BaseBEVBackbone(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ZeroPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (3): Dropout2d(p=0.11, inplace=False)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (7): Dropout2d(p=0.11, inplace=False)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (11): Dropout2d(p=0.11, inplace=False)\n",
      "        (12): ReLU()\n",
      "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (15): Dropout2d(p=0.11, inplace=False)\n",
      "        (16): ReLU()\n",
      "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (19): Dropout2d(p=0.11, inplace=False)\n",
      "        (20): ReLU()\n",
      "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (23): Dropout2d(p=0.11, inplace=False)\n",
      "        (24): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (deblocks): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Dropout2d(p=0.11, inplace=False)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dense_head): AnchorHeadSingle(\n",
      "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "    (reg_loss_func): WeightedSmoothL1Loss()\n",
      "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (point_head): None\n",
      "  (roi_head): None\n",
      ")\n",
      "2023-05-27 12:08:04,056   INFO  **********************Start training cfgs/kitti_models/pointpillar_bayes(default)**********************\n",
      "2023-05-27 12:08:04,056   INFO  **********************Start training cfgs/kitti_models/pointpillar_bayes(default)**********************\n",
      "2023-05-27 12:08:04,056   INFO  **********************Start training cfgs/kitti_models/pointpillar_bayes(default)**********************\n",
      "2023-05-27 12:08:04,056   INFO  **********************Start training cfgs/kitti_models/pointpillar_bayes(default)**********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/sunqiao/OpenPCDet/output/cfgs/kitti_models/bayes/default/ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  18%|█▊        | 14/80 [1:22:05<6:28:45, 353.41s/it]"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "from noise import add_noise_to_weights\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models_bayes import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model, model_save\n",
    "from eval_utils import eval_utils\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', \\\n",
    "                        help='specify the config for training')\n",
    "    # sunqiao/OpenPCDet/tools/cfgs/kitti_models/pointpillar_bayes.yaml\n",
    "    parser.add_argument('--batch_size', type=int, default=None, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=None, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=32, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    parser.add_argument('--ckpt', type=str, default='./checkpoint_epoch_80.pth', help='checkpoint to start from')\n",
    "    parser.add_argument('--pretrained_model', type=str, default=True, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=81, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg\n",
    "\n",
    "\n",
    "def opt_function(p1, p2):\n",
    "    \n",
    "    print(\"=============\")\n",
    "    print(p1, p2)\n",
    "    print(\"=============\")\n",
    "    \n",
    "    global best_accu\n",
    "\n",
    "    # p1 = round(p1, 2)\n",
    "    # p2 = round(p2, 2)\n",
    "\n",
    "    train_set, train_loader, train_sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=dist_train, workers=args.workers,\n",
    "        logger=logger,\n",
    "        training=True,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "        total_epochs=args.epochs\n",
    "    )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "                        p1=p1, \n",
    "                        p2=p2, \n",
    "                        dataset=train_set)\n",
    "    # print(model.state_dict())\n",
    "    # print(\"???????????\")\n",
    "    \n",
    "    if args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    # # load checkpoint if it is possible\n",
    "    start_epoch = it = 0\n",
    "    last_epoch = -1\n",
    "    if args.pretrained_model is True:\n",
    "        model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "    # if args.ckpt is not None:\n",
    "    #     it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "    #     last_epoch = start_epoch + 1\n",
    "    # else:\n",
    "    #     ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "    #     if len(ckpt_list) > 0:\n",
    "    #         ckpt_list.sort(key=os.path.getmtime)\n",
    "    #         it, start_epoch = model.load_params_with_optimizer(\n",
    "    #             ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "    #         )\n",
    "    #         last_epoch = start_epoch + 1\n",
    "\n",
    "    model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "    if dist_train:\n",
    "        model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "    logger.info(model)\n",
    "\n",
    "    lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "        optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "        last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "    )\n",
    "\n",
    "#     # -----------------------start training---------------------------\n",
    "    logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        model_func=model_fn_decorator(),\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        optim_cfg=cfg.OPTIMIZATION,\n",
    "        start_epoch=start_epoch,\n",
    "        total_epochs=args.epochs,\n",
    "        start_iter=it,\n",
    "        rank=cfg.LOCAL_RANK,\n",
    "        tb_log=tb_log,\n",
    "        ckpt_save_dir=ckpt_dir,\n",
    "        train_sampler=train_sampler,\n",
    "        lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "        ckpt_save_interval=args.ckpt_save_interval,\n",
    "        max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "    )\n",
    "\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "                                    dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                    class_names=cfg.CLASS_NAMES,\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                )\n",
    "    \n",
    "    \n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, dataset=test_set)\n",
    "    if dist_train: \n",
    "        model = model.module\n",
    "\n",
    "    if args.pretrained_model is True:\n",
    "        model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "        \n",
    "    # model.load_params_from_file(filename='./checkpoint_epoch_80.pth', logger=logger, to_cpu=dist_train)\n",
    "    model.cuda()\n",
    "\n",
    "    ckpt_pth = save_path+'bayes_model-{}-{}'.format(p1,p2)\n",
    "    ckpt_name = ckpt_pth+'.pth'\n",
    "\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "    logger.info('**********************End training**********************')\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "\n",
    "\n",
    "    # if dist_train: \n",
    "    #     model = model.module\n",
    "\n",
    "    sigma = 0.1\n",
    "    f = open(save_path+'result.txt', \"a+\")\n",
    "    # f.write('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "    f.write('----------------{}-{}----------------\\n'.format(p1,p2))\n",
    "    f.close()\n",
    "\n",
    "    logger.info('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "    # model.load_params_from_file(filename=ckpt_name, logger=logger, to_cpu=dist_train)\n",
    "    # model.cuda()\n",
    "    add_noise_to_weights(0, sigma, model)\n",
    "    global n\n",
    "    n += 1\n",
    "    \n",
    "    acc1 = eval_utils.eval_simple(sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "    print(\"----------\")\n",
    "    print(acc1)\n",
    "    print(\"----------\")\n",
    "\n",
    "\n",
    "    logger.info('**********************End evaluation**********************')\n",
    "\n",
    "        # best_accu = acc\n",
    "\n",
    "    return acc1#+acc2+acc3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    torch.cuda.set_device(1)\n",
    "    # best_accu = 0\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    if args.launcher == 'none':\n",
    "        dist_train = False\n",
    "        total_gpus = 1\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "        memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "        print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "        os.system('rm tmp')\n",
    "    else:\n",
    "        total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "            args.tcp_port, args.local_rank, backend='nccl'\n",
    "        )\n",
    "        dist_train = True\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = './save_path/bayes/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    file = open(save_path+'result.txt','w')\n",
    "    file.write('results\\n')\n",
    "    file.close()\n",
    "\n",
    "    # head = ''\n",
    "    # logging.basicConfig(filename='./baseline/pointpillar/log.txt',\n",
    "    #                     format=head)\n",
    "    # logger_result = logging.getLogger()\n",
    "    # logger_result.setLevel(logging.INFO)\n",
    "    # console = logging.StreamHandler()\n",
    "    # logging.getLogger('').addHandler(console)\n",
    "\n",
    "    # log to file\n",
    "    logger.info('**********************Start logging**********************')\n",
    "    gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "    logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "    if dist_train:\n",
    "        logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info('{:16} {}'.format(key, val))\n",
    "    log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "    tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "    # -----------------------create dataloader & network & optimizer---------------------------\n",
    "    # train_set, train_loader, train_sampler = build_dataloader(\n",
    "    #     dataset_cfg=cfg.DATA_CONFIG,\n",
    "    #     class_names=cfg.CLASS_NAMES,\n",
    "    #     batch_size=args.batch_size,\n",
    "    #     dist=dist_train, workers=args.workers,\n",
    "    #     logger=logger,\n",
    "    #     training=True,\n",
    "    #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "    #     total_epochs=args.epochs\n",
    "    # )\n",
    "\n",
    "\n",
    "    # test_set, test_loader, sampler = build_dataloader(\n",
    "    #     dataset_cfg=cfg.DATA_CONFIG,\n",
    "    #     class_names=cfg.CLASS_NAMES,\n",
    "    #     batch_size=args.batch_size,\n",
    "    #     dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "    # )\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "    # opt_function(0.11, 0.11)\n",
    "    print(\"=============\")\n",
    "    p1 = 0.11\n",
    "    p2 = 0.11\n",
    "    print(p1, p2)\n",
    "    print(\"=============\")\n",
    "    \n",
    "    # global best_accu\n",
    "\n",
    "    # p1 = round(p1, 2)\n",
    "    # p2 = round(p2, 2)\n",
    "\n",
    "    train_set, train_loader, train_sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=dist_train, workers=args.workers,\n",
    "        logger=logger,\n",
    "        training=True,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "        total_epochs=args.epochs\n",
    "    )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "                        p1=p1, \n",
    "                        p2=p2, \n",
    "                        dataset=train_set)\n",
    "    # print(model.state_dict())\n",
    "    # print(\"???????????\")\n",
    "    \n",
    "    if args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    # # load checkpoint if it is possible\n",
    "    start_epoch = it = 0\n",
    "    last_epoch = -1\n",
    "    if args.pretrained_model is True:\n",
    "        model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "    # if args.ckpt is not None:\n",
    "    #     it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "    #     last_epoch = start_epoch + 1\n",
    "    # else:\n",
    "    #     ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "    #     if len(ckpt_list) > 0:\n",
    "    #         ckpt_list.sort(key=os.path.getmtime)\n",
    "    #         it, start_epoch = model.load_params_with_optimizer(\n",
    "    #             ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "    #         )\n",
    "    #         last_epoch = start_epoch + 1\n",
    "\n",
    "    model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "    if dist_train:\n",
    "        model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "    logger.info(model)\n",
    "\n",
    "    lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "        optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "        last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "    )\n",
    "\n",
    "#     # -----------------------start training---------------------------\n",
    "    logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "    print(ckpt_dir)\n",
    "    # ckpt_dir = './save_path/ckpts'\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        model_func=model_fn_decorator(),\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        optim_cfg=cfg.OPTIMIZATION,\n",
    "        start_epoch=start_epoch,\n",
    "        total_epochs=args.epochs,\n",
    "        start_iter=it,\n",
    "        rank=cfg.LOCAL_RANK,\n",
    "        tb_log=tb_log,\n",
    "        ckpt_save_dir=ckpt_dir,\n",
    "        train_sampler=train_sampler,\n",
    "        lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "        ckpt_save_interval=args.ckpt_save_interval,\n",
    "        max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "    )\n",
    "\n",
    "    # logger.info('----------------Bayes Optimization----------------')\n",
    "    # Bounded region of parameter space\n",
    "    # pbounds = {'p1': (0.1, 0.9), 'p2': (0.1, 0.9)}\n",
    "    \n",
    "\n",
    "#     optimizer = BayesianOptimization(\n",
    "#         f=opt_function,\n",
    "#         pbounds=pbounds,\n",
    "#         verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "#         random_state=1,\n",
    "#     )\n",
    "#     optimizer.probe(\n",
    "#         params={'p1': 0.11, 'p2': 0.11},\n",
    "#         lazy=True,\n",
    "#     )\n",
    "\n",
    "#     logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "#     optimizer.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "    \n",
    "    \n",
    "#     n = 0\n",
    "#     optimizer.maximize(\n",
    "#         init_points=3,\n",
    "#         n_iter=10,\n",
    "#     )\n",
    "    print(\"=======end========\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
