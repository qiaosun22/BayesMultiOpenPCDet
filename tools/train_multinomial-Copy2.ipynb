{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262d683d-4c38-4ecc-92b0-e8fbaa386662",
   "metadata": {},
   "source": [
    "torch.load('./checkpoint_epoch_80_multinomial.pth', map_location=torch.device('cuda:0'))['model_state']\n",
    "\n",
    "找到具有正确输出的预训练模型的 loss 和 mAP 的对应关系\n",
    "\n",
    "已完成：调整学习率，降低代码复杂度\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f7a3b7-423e-48d0-aef4-3d6f53af4196",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T15:55:18.174151Z",
     "iopub.status.busy": "2023-07-22T15:55:18.174007Z",
     "iopub.status.idle": "2023-07-22T16:17:22.716985Z",
     "shell.execute_reply": "2023-07-22T16:17:22.716154Z",
     "shell.execute_reply.started": "2023-07-22T15:55:18.174136Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 23:55:24,239   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2023-07-22 23:55:24,240   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2023-07-22 23:55:24,241   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2023-07-22 23:55:24,256   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2023-07-22 23:55:24,258   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2023-07-22 23:55:24,259   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2023-07-22 23:55:24,264   INFO  Loading KITTI dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n",
      "=============\n",
      "0.23 0.77 0.68\n",
      "=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 23:55:24,343   INFO  Total samples for KITTI dataset: 3712\n",
      "/home/pai/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2023-07-22 23:55:26,144   INFO  **********************Start training cfgs/kitti_models/pointpillar_bayes(default)**********************\n",
      "epochs:   0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_epoch: 1/800, cur_it: 1/464, lr: 1e-08, loss: 4.69438\n",
      "cur_epoch: 1/800, cur_it: 2/464, lr: 1e-08, loss: 4.57229\n",
      "cur_epoch: 1/800, cur_it: 3/464, lr: 1e-08, loss: 4.98539\n",
      "cur_epoch: 1/800, cur_it: 4/464, lr: 1e-08, loss: 4.83517\n",
      "cur_epoch: 1/800, cur_it: 5/464, lr: 1e-08, loss: 4.75756\n",
      "cur_epoch: 1/800, cur_it: 6/464, lr: 1e-08, loss: 4.6181\n",
      "cur_epoch: 1/800, cur_it: 7/464, lr: 1e-08, loss: 4.54114\n",
      "cur_epoch: 1/800, cur_it: 8/464, lr: 1e-08, loss: 4.5293\n",
      "cur_epoch: 1/800, cur_it: 9/464, lr: 1e-08, loss: 4.48194\n",
      "cur_epoch: 1/800, cur_it: 10/464, lr: 1e-08, loss: 4.40207\n",
      "cur_epoch: 1/800, cur_it: 11/464, lr: 1e-08, loss: 4.41913\n",
      "cur_epoch: 1/800, cur_it: 12/464, lr: 1e-08, loss: 4.3883\n",
      "cur_epoch: 1/800, cur_it: 13/464, lr: 1e-08, loss: 4.37268\n",
      "cur_epoch: 1/800, cur_it: 14/464, lr: 1e-08, loss: 4.3427\n",
      "cur_epoch: 1/800, cur_it: 15/464, lr: 1e-08, loss: 4.31392\n",
      "cur_epoch: 1/800, cur_it: 16/464, lr: 1e-08, loss: 4.30032\n",
      "cur_epoch: 1/800, cur_it: 17/464, lr: 1e-08, loss: 4.29488\n",
      "cur_epoch: 1/800, cur_it: 18/464, lr: 1e-08, loss: 4.36231\n",
      "cur_epoch: 1/800, cur_it: 19/464, lr: 1e-08, loss: 4.32025\n",
      "cur_epoch: 1/800, cur_it: 20/464, lr: 1e-08, loss: 4.30608\n",
      "cur_epoch: 1/800, cur_it: 21/464, lr: 1e-08, loss: 4.30257\n",
      "cur_epoch: 1/800, cur_it: 22/464, lr: 1e-08, loss: 4.36057\n",
      "cur_epoch: 1/800, cur_it: 23/464, lr: 1e-08, loss: 4.36733\n",
      "cur_epoch: 1/800, cur_it: 24/464, lr: 1e-08, loss: 4.33951\n",
      "cur_epoch: 1/800, cur_it: 25/464, lr: 1e-08, loss: 4.31346\n",
      "cur_epoch: 1/800, cur_it: 26/464, lr: 1e-08, loss: 4.31154\n",
      "cur_epoch: 1/800, cur_it: 27/464, lr: 1e-08, loss: 4.29564\n",
      "cur_epoch: 1/800, cur_it: 28/464, lr: 1e-08, loss: 4.27863\n",
      "cur_epoch: 1/800, cur_it: 29/464, lr: 1e-08, loss: 4.2751\n",
      "cur_epoch: 1/800, cur_it: 30/464, lr: 1e-08, loss: 4.30008\n",
      "cur_epoch: 1/800, cur_it: 31/464, lr: 1e-08, loss: 4.28357\n",
      "cur_epoch: 1/800, cur_it: 32/464, lr: 1e-08, loss: 4.26929\n",
      "cur_epoch: 1/800, cur_it: 33/464, lr: 1e-08, loss: 4.26062\n",
      "cur_epoch: 1/800, cur_it: 34/464, lr: 1e-08, loss: 4.25082\n",
      "cur_epoch: 1/800, cur_it: 35/464, lr: 1e-08, loss: 4.26055\n",
      "cur_epoch: 1/800, cur_it: 36/464, lr: 1e-08, loss: 4.25297\n",
      "cur_epoch: 1/800, cur_it: 37/464, lr: 1e-08, loss: 4.2395\n",
      "cur_epoch: 1/800, cur_it: 38/464, lr: 1e-08, loss: 4.23415\n",
      "cur_epoch: 1/800, cur_it: 39/464, lr: 1e-08, loss: 4.24673\n",
      "cur_epoch: 1/800, cur_it: 40/464, lr: 1e-08, loss: 4.2694\n",
      "cur_epoch: 1/800, cur_it: 41/464, lr: 1e-08, loss: 4.30921\n",
      "cur_epoch: 1/800, cur_it: 42/464, lr: 1e-08, loss: 4.30279\n",
      "cur_epoch: 1/800, cur_it: 43/464, lr: 1e-08, loss: 4.34667\n",
      "cur_epoch: 1/800, cur_it: 44/464, lr: 1e-08, loss: 4.34046\n",
      "cur_epoch: 1/800, cur_it: 45/464, lr: 1e-08, loss: 4.33217\n",
      "cur_epoch: 1/800, cur_it: 46/464, lr: 1e-08, loss: 4.32108\n",
      "cur_epoch: 1/800, cur_it: 47/464, lr: 1e-08, loss: 4.31861\n",
      "cur_epoch: 1/800, cur_it: 48/464, lr: 1e-08, loss: 4.30244\n",
      "cur_epoch: 1/800, cur_it: 49/464, lr: 1e-08, loss: 4.33553\n",
      "cur_epoch: 1/800, cur_it: 50/464, lr: 1e-08, loss: 4.33788\n",
      "cur_epoch: 1/800, cur_it: 51/464, lr: 1e-08, loss: 4.32445\n",
      "cur_epoch: 1/800, cur_it: 52/464, lr: 1e-08, loss: 4.31928\n",
      "cur_epoch: 1/800, cur_it: 53/464, lr: 1e-08, loss: 4.30889\n",
      "cur_epoch: 1/800, cur_it: 54/464, lr: 1e-08, loss: 4.31322\n",
      "cur_epoch: 1/800, cur_it: 55/464, lr: 1e-08, loss: 4.30213\n",
      "cur_epoch: 1/800, cur_it: 56/464, lr: 1e-08, loss: 4.30681\n",
      "cur_epoch: 1/800, cur_it: 57/464, lr: 1e-08, loss: 4.30636\n",
      "cur_epoch: 1/800, cur_it: 58/464, lr: 1e-08, loss: 4.37682\n",
      "cur_epoch: 1/800, cur_it: 59/464, lr: 1e-08, loss: 4.37086\n",
      "cur_epoch: 1/800, cur_it: 60/464, lr: 1e-08, loss: 4.36764\n",
      "cur_epoch: 1/800, cur_it: 61/464, lr: 1e-08, loss: 4.36318\n",
      "cur_epoch: 1/800, cur_it: 62/464, lr: 1e-08, loss: 4.35935\n",
      "cur_epoch: 1/800, cur_it: 63/464, lr: 1e-08, loss: 4.3474\n",
      "cur_epoch: 1/800, cur_it: 64/464, lr: 1e-08, loss: 4.35834\n",
      "cur_epoch: 1/800, cur_it: 65/464, lr: 1e-08, loss: 4.35028\n",
      "cur_epoch: 1/800, cur_it: 66/464, lr: 1e-08, loss: 4.34038\n",
      "cur_epoch: 1/800, cur_it: 67/464, lr: 1e-08, loss: 4.34945\n",
      "cur_epoch: 1/800, cur_it: 68/464, lr: 1e-08, loss: 4.34778\n",
      "cur_epoch: 1/800, cur_it: 69/464, lr: 1e-08, loss: 4.35734\n",
      "cur_epoch: 1/800, cur_it: 70/464, lr: 1e-08, loss: 4.35297\n",
      "cur_epoch: 1/800, cur_it: 71/464, lr: 1e-08, loss: 4.36725\n",
      "cur_epoch: 1/800, cur_it: 72/464, lr: 1e-08, loss: 4.36628\n",
      "cur_epoch: 1/800, cur_it: 73/464, lr: 1e-08, loss: 4.36017\n",
      "cur_epoch: 1/800, cur_it: 74/464, lr: 1e-08, loss: 4.36687\n",
      "cur_epoch: 1/800, cur_it: 75/464, lr: 1e-08, loss: 4.36168\n",
      "cur_epoch: 1/800, cur_it: 76/464, lr: 1e-08, loss: 4.36159\n",
      "cur_epoch: 1/800, cur_it: 77/464, lr: 1e-08, loss: 4.35563\n",
      "cur_epoch: 1/800, cur_it: 78/464, lr: 1e-08, loss: 4.3532\n",
      "cur_epoch: 1/800, cur_it: 79/464, lr: 1e-08, loss: 4.34781\n",
      "cur_epoch: 1/800, cur_it: 80/464, lr: 1e-08, loss: 4.36416\n",
      "cur_epoch: 1/800, cur_it: 81/464, lr: 1e-08, loss: 4.36132\n",
      "cur_epoch: 1/800, cur_it: 82/464, lr: 1e-08, loss: 4.37034\n",
      "cur_epoch: 1/800, cur_it: 83/464, lr: 1e-08, loss: 4.37012\n",
      "cur_epoch: 1/800, cur_it: 84/464, lr: 1e-08, loss: 4.38785\n",
      "cur_epoch: 1/800, cur_it: 85/464, lr: 1e-08, loss: 4.3937\n",
      "cur_epoch: 1/800, cur_it: 86/464, lr: 1e-08, loss: 4.38676\n",
      "cur_epoch: 1/800, cur_it: 87/464, lr: 1e-08, loss: 4.37955\n",
      "cur_epoch: 1/800, cur_it: 88/464, lr: 1e-08, loss: 4.38785\n",
      "cur_epoch: 1/800, cur_it: 89/464, lr: 1e-08, loss: 4.38646\n",
      "cur_epoch: 1/800, cur_it: 90/464, lr: 1e-08, loss: 4.38187\n",
      "cur_epoch: 1/800, cur_it: 91/464, lr: 1e-08, loss: 4.37914\n",
      "cur_epoch: 1/800, cur_it: 92/464, lr: 1e-08, loss: 4.37541\n",
      "cur_epoch: 1/800, cur_it: 93/464, lr: 1e-08, loss: 4.37225\n",
      "cur_epoch: 1/800, cur_it: 94/464, lr: 1e-08, loss: 4.36828\n",
      "cur_epoch: 1/800, cur_it: 95/464, lr: 1e-08, loss: 4.37304\n",
      "cur_epoch: 1/800, cur_it: 96/464, lr: 1e-08, loss: 4.40123\n",
      "cur_epoch: 1/800, cur_it: 97/464, lr: 1e-08, loss: 4.39849\n",
      "cur_epoch: 1/800, cur_it: 98/464, lr: 1e-08, loss: 4.39734\n",
      "cur_epoch: 1/800, cur_it: 99/464, lr: 1e-08, loss: 4.40511\n",
      "cur_epoch: 1/800, cur_it: 100/464, lr: 1e-08, loss: 4.40298\n",
      "cur_epoch: 1/800, cur_it: 101/464, lr: 1e-08, loss: 4.39645\n",
      "cur_epoch: 1/800, cur_it: 102/464, lr: 1e-08, loss: 4.39419\n",
      "cur_epoch: 1/800, cur_it: 103/464, lr: 1e-08, loss: 4.39161\n",
      "cur_epoch: 1/800, cur_it: 104/464, lr: 1e-08, loss: 4.3892\n",
      "cur_epoch: 1/800, cur_it: 105/464, lr: 1e-08, loss: 4.39153\n",
      "cur_epoch: 1/800, cur_it: 106/464, lr: 1e-08, loss: 4.39604\n",
      "cur_epoch: 1/800, cur_it: 107/464, lr: 1e-08, loss: 4.39922\n",
      "cur_epoch: 1/800, cur_it: 108/464, lr: 1e-08, loss: 4.39696\n",
      "cur_epoch: 1/800, cur_it: 109/464, lr: 1e-08, loss: 4.40564\n",
      "cur_epoch: 1/800, cur_it: 110/464, lr: 1e-08, loss: 4.39808\n",
      "cur_epoch: 1/800, cur_it: 111/464, lr: 1e-08, loss: 4.39675\n",
      "cur_epoch: 1/800, cur_it: 112/464, lr: 1e-08, loss: 4.39499\n",
      "cur_epoch: 1/800, cur_it: 113/464, lr: 1e-08, loss: 4.39379\n",
      "cur_epoch: 1/800, cur_it: 114/464, lr: 1e-08, loss: 4.39512\n",
      "cur_epoch: 1/800, cur_it: 115/464, lr: 1e-08, loss: 4.39084\n",
      "cur_epoch: 1/800, cur_it: 116/464, lr: 1e-08, loss: 4.40156\n",
      "cur_epoch: 1/800, cur_it: 117/464, lr: 1e-08, loss: 4.3989\n",
      "cur_epoch: 1/800, cur_it: 118/464, lr: 1e-08, loss: 4.39584\n",
      "cur_epoch: 1/800, cur_it: 119/464, lr: 1e-08, loss: 4.39903\n",
      "cur_epoch: 1/800, cur_it: 120/464, lr: 1e-08, loss: 4.39547\n",
      "cur_epoch: 1/800, cur_it: 121/464, lr: 1e-08, loss: 4.39465\n",
      "cur_epoch: 1/800, cur_it: 122/464, lr: 1e-08, loss: 4.39441\n",
      "cur_epoch: 1/800, cur_it: 123/464, lr: 1e-08, loss: 4.41379\n",
      "cur_epoch: 1/800, cur_it: 124/464, lr: 1e-08, loss: 4.41585\n",
      "cur_epoch: 1/800, cur_it: 125/464, lr: 1e-08, loss: 4.40892\n",
      "cur_epoch: 1/800, cur_it: 126/464, lr: 1e-08, loss: 4.40532\n",
      "cur_epoch: 1/800, cur_it: 127/464, lr: 1e-08, loss: 4.41201\n",
      "cur_epoch: 1/800, cur_it: 128/464, lr: 1e-08, loss: 4.4078\n",
      "cur_epoch: 1/800, cur_it: 129/464, lr: 1e-08, loss: 4.40688\n",
      "cur_epoch: 1/800, cur_it: 130/464, lr: 1e-08, loss: 4.42143\n",
      "cur_epoch: 1/800, cur_it: 131/464, lr: 1e-08, loss: 4.42232\n",
      "cur_epoch: 1/800, cur_it: 132/464, lr: 1e-08, loss: 4.42062\n",
      "cur_epoch: 1/800, cur_it: 133/464, lr: 1e-08, loss: 4.41778\n",
      "cur_epoch: 1/800, cur_it: 134/464, lr: 1e-08, loss: 4.41616\n",
      "cur_epoch: 1/800, cur_it: 135/464, lr: 1e-08, loss: 4.41564\n",
      "cur_epoch: 1/800, cur_it: 136/464, lr: 1e-08, loss: 4.41125\n",
      "cur_epoch: 1/800, cur_it: 137/464, lr: 1e-08, loss: 4.41874\n",
      "cur_epoch: 1/800, cur_it: 138/464, lr: 1e-08, loss: 4.41968\n",
      "cur_epoch: 1/800, cur_it: 139/464, lr: 1e-08, loss: 4.4214\n",
      "cur_epoch: 1/800, cur_it: 140/464, lr: 1e-08, loss: 4.41733\n",
      "cur_epoch: 1/800, cur_it: 141/464, lr: 1e-08, loss: 4.43062\n",
      "cur_epoch: 1/800, cur_it: 142/464, lr: 1e-08, loss: 4.42908\n",
      "cur_epoch: 1/800, cur_it: 143/464, lr: 1e-08, loss: 4.43242\n",
      "cur_epoch: 1/800, cur_it: 144/464, lr: 1e-08, loss: 4.43833\n",
      "cur_epoch: 1/800, cur_it: 145/464, lr: 1e-08, loss: 4.43624\n",
      "cur_epoch: 1/800, cur_it: 146/464, lr: 1e-08, loss: 4.43239\n",
      "cur_epoch: 1/800, cur_it: 147/464, lr: 1e-08, loss: 4.54826\n",
      "cur_epoch: 1/800, cur_it: 148/464, lr: 1e-08, loss: 4.54315\n",
      "cur_epoch: 1/800, cur_it: 149/464, lr: 1e-08, loss: 4.55651\n",
      "cur_epoch: 1/800, cur_it: 150/464, lr: 1e-08, loss: 4.55342\n",
      "cur_epoch: 1/800, cur_it: 151/464, lr: 1e-08, loss: 4.559\n",
      "cur_epoch: 1/800, cur_it: 152/464, lr: 1e-08, loss: 4.55484\n",
      "cur_epoch: 1/800, cur_it: 153/464, lr: 1e-08, loss: 4.55201\n",
      "cur_epoch: 1/800, cur_it: 154/464, lr: 1e-08, loss: 4.54772\n",
      "cur_epoch: 1/800, cur_it: 155/464, lr: 1e-08, loss: 4.54554\n",
      "cur_epoch: 1/800, cur_it: 156/464, lr: 1e-08, loss: 4.54193\n",
      "cur_epoch: 1/800, cur_it: 157/464, lr: 1e-08, loss: 4.54093\n",
      "cur_epoch: 1/800, cur_it: 158/464, lr: 1e-08, loss: 4.54053\n",
      "cur_epoch: 1/800, cur_it: 159/464, lr: 1e-08, loss: 4.53741\n",
      "cur_epoch: 1/800, cur_it: 160/464, lr: 1e-08, loss: 4.53188\n",
      "cur_epoch: 1/800, cur_it: 161/464, lr: 1e-08, loss: 4.52942\n",
      "cur_epoch: 1/800, cur_it: 162/464, lr: 1e-08, loss: 4.52262\n",
      "cur_epoch: 1/800, cur_it: 163/464, lr: 1e-08, loss: 4.52415\n",
      "cur_epoch: 1/800, cur_it: 164/464, lr: 1e-08, loss: 4.51871\n",
      "cur_epoch: 1/800, cur_it: 165/464, lr: 1e-08, loss: 4.51535\n",
      "cur_epoch: 1/800, cur_it: 166/464, lr: 1e-08, loss: 4.51282\n",
      "cur_epoch: 1/800, cur_it: 167/464, lr: 1e-08, loss: 4.51054\n",
      "cur_epoch: 1/800, cur_it: 168/464, lr: 1e-08, loss: 4.50826\n",
      "cur_epoch: 1/800, cur_it: 169/464, lr: 1e-08, loss: 4.50459\n",
      "cur_epoch: 1/800, cur_it: 170/464, lr: 1e-08, loss: 4.5024\n",
      "cur_epoch: 1/800, cur_it: 171/464, lr: 1e-08, loss: 4.50105\n",
      "cur_epoch: 1/800, cur_it: 172/464, lr: 1e-08, loss: 4.49965\n",
      "cur_epoch: 1/800, cur_it: 173/464, lr: 1e-08, loss: 4.50009\n",
      "cur_epoch: 1/800, cur_it: 174/464, lr: 1e-08, loss: 4.49922\n",
      "cur_epoch: 1/800, cur_it: 175/464, lr: 1e-08, loss: 4.49409\n",
      "cur_epoch: 1/800, cur_it: 176/464, lr: 1e-08, loss: 4.49118\n",
      "cur_epoch: 1/800, cur_it: 177/464, lr: 1e-08, loss: 4.49284\n",
      "cur_epoch: 1/800, cur_it: 178/464, lr: 1e-08, loss: 4.49198\n",
      "cur_epoch: 1/800, cur_it: 179/464, lr: 1e-08, loss: 4.49591\n",
      "cur_epoch: 1/800, cur_it: 180/464, lr: 1e-08, loss: 4.49569\n",
      "cur_epoch: 1/800, cur_it: 181/464, lr: 1e-08, loss: 4.49375\n",
      "cur_epoch: 1/800, cur_it: 182/464, lr: 1e-08, loss: 4.49367\n",
      "cur_epoch: 1/800, cur_it: 183/464, lr: 1e-08, loss: 4.49343\n",
      "cur_epoch: 1/800, cur_it: 184/464, lr: 1e-08, loss: 4.49349\n",
      "cur_epoch: 1/800, cur_it: 185/464, lr: 1e-08, loss: 4.50418\n",
      "cur_epoch: 1/800, cur_it: 186/464, lr: 1e-08, loss: 4.50489\n",
      "cur_epoch: 1/800, cur_it: 187/464, lr: 1e-08, loss: 4.50056\n",
      "cur_epoch: 1/800, cur_it: 188/464, lr: 1e-08, loss: 4.50125\n",
      "cur_epoch: 1/800, cur_it: 189/464, lr: 1e-08, loss: 4.50154\n",
      "cur_epoch: 1/800, cur_it: 190/464, lr: 1e-08, loss: 4.498\n",
      "cur_epoch: 1/800, cur_it: 191/464, lr: 1e-08, loss: 4.49283\n",
      "cur_epoch: 1/800, cur_it: 192/464, lr: 1e-08, loss: 4.49183\n",
      "cur_epoch: 1/800, cur_it: 193/464, lr: 1e-08, loss: 4.54399\n",
      "cur_epoch: 1/800, cur_it: 194/464, lr: 1e-08, loss: 4.54588\n",
      "cur_epoch: 1/800, cur_it: 195/464, lr: 1e-08, loss: 4.54764\n",
      "cur_epoch: 1/800, cur_it: 196/464, lr: 1e-08, loss: 4.54897\n",
      "cur_epoch: 1/800, cur_it: 197/464, lr: 1e-08, loss: 4.54803\n",
      "cur_epoch: 1/800, cur_it: 198/464, lr: 1e-08, loss: 4.54257\n",
      "cur_epoch: 1/800, cur_it: 199/464, lr: 1e-08, loss: 4.54942\n",
      "cur_epoch: 1/800, cur_it: 200/464, lr: 1e-08, loss: 4.54484\n",
      "cur_epoch: 1/800, cur_it: 201/464, lr: 1e-08, loss: 4.5456\n",
      "cur_epoch: 1/800, cur_it: 202/464, lr: 1e-08, loss: 4.54393\n",
      "cur_epoch: 1/800, cur_it: 203/464, lr: 1e-08, loss: 4.54112\n",
      "cur_epoch: 1/800, cur_it: 204/464, lr: 1e-08, loss: 4.54242\n",
      "cur_epoch: 1/800, cur_it: 205/464, lr: 1e-08, loss: 4.54077\n",
      "cur_epoch: 1/800, cur_it: 206/464, lr: 1e-08, loss: 4.53731\n",
      "cur_epoch: 1/800, cur_it: 207/464, lr: 1e-08, loss: 4.53719\n",
      "cur_epoch: 1/800, cur_it: 208/464, lr: 1e-08, loss: 4.53548\n",
      "cur_epoch: 1/800, cur_it: 209/464, lr: 1e-08, loss: 4.53652\n",
      "cur_epoch: 1/800, cur_it: 210/464, lr: 1e-08, loss: 4.53849\n",
      "cur_epoch: 1/800, cur_it: 211/464, lr: 1e-08, loss: 4.5351\n",
      "cur_epoch: 1/800, cur_it: 212/464, lr: 1e-08, loss: 4.53994\n",
      "cur_epoch: 1/800, cur_it: 213/464, lr: 1e-08, loss: 4.53714\n",
      "cur_epoch: 1/800, cur_it: 214/464, lr: 1e-08, loss: 4.54066\n",
      "cur_epoch: 1/800, cur_it: 215/464, lr: 1e-08, loss: 4.53838\n",
      "cur_epoch: 1/800, cur_it: 216/464, lr: 1e-08, loss: 4.5344\n",
      "cur_epoch: 1/800, cur_it: 217/464, lr: 1e-08, loss: 4.53195\n",
      "cur_epoch: 1/800, cur_it: 218/464, lr: 1e-08, loss: 4.53037\n",
      "cur_epoch: 1/800, cur_it: 219/464, lr: 1e-08, loss: 4.52729\n",
      "cur_epoch: 1/800, cur_it: 220/464, lr: 1e-08, loss: 4.52557\n",
      "cur_epoch: 1/800, cur_it: 221/464, lr: 1e-08, loss: 4.54091\n",
      "cur_epoch: 1/800, cur_it: 222/464, lr: 1e-08, loss: 4.53876\n",
      "cur_epoch: 1/800, cur_it: 223/464, lr: 1e-08, loss: 4.53675\n",
      "cur_epoch: 1/800, cur_it: 224/464, lr: 1e-08, loss: 4.53781\n",
      "cur_epoch: 1/800, cur_it: 225/464, lr: 1e-08, loss: 4.53694\n",
      "cur_epoch: 1/800, cur_it: 226/464, lr: 1e-08, loss: 4.53885\n",
      "cur_epoch: 1/800, cur_it: 227/464, lr: 1e-08, loss: 4.53522\n",
      "cur_epoch: 1/800, cur_it: 228/464, lr: 1e-08, loss: 4.5333\n",
      "cur_epoch: 1/800, cur_it: 229/464, lr: 1e-08, loss: 4.53108\n",
      "cur_epoch: 1/800, cur_it: 230/464, lr: 1e-08, loss: 4.53218\n",
      "cur_epoch: 1/800, cur_it: 231/464, lr: 1e-08, loss: 4.52926\n",
      "cur_epoch: 1/800, cur_it: 232/464, lr: 1e-08, loss: 4.52743\n",
      "cur_epoch: 1/800, cur_it: 233/464, lr: 1e-08, loss: 4.52634\n",
      "cur_epoch: 1/800, cur_it: 234/464, lr: 1e-08, loss: 4.5476\n",
      "cur_epoch: 1/800, cur_it: 235/464, lr: 1e-08, loss: 4.54819\n",
      "cur_epoch: 1/800, cur_it: 236/464, lr: 1e-08, loss: 4.55172\n",
      "cur_epoch: 1/800, cur_it: 237/464, lr: 1e-08, loss: 4.54971\n",
      "cur_epoch: 1/800, cur_it: 238/464, lr: 1e-08, loss: 4.54797\n",
      "cur_epoch: 1/800, cur_it: 239/464, lr: 1e-08, loss: 4.54618\n",
      "cur_epoch: 1/800, cur_it: 240/464, lr: 1e-08, loss: 4.55016\n",
      "cur_epoch: 1/800, cur_it: 241/464, lr: 1e-08, loss: 4.54772\n",
      "cur_epoch: 1/800, cur_it: 242/464, lr: 1e-08, loss: 4.56314\n",
      "cur_epoch: 1/800, cur_it: 243/464, lr: 1e-08, loss: 4.56212\n",
      "cur_epoch: 1/800, cur_it: 244/464, lr: 1e-08, loss: 4.55913\n",
      "cur_epoch: 1/800, cur_it: 245/464, lr: 1e-08, loss: 4.55557\n",
      "cur_epoch: 1/800, cur_it: 246/464, lr: 1e-08, loss: 4.5537\n",
      "cur_epoch: 1/800, cur_it: 247/464, lr: 1e-08, loss: 4.55011\n",
      "cur_epoch: 1/800, cur_it: 248/464, lr: 1e-08, loss: 4.5518\n",
      "cur_epoch: 1/800, cur_it: 249/464, lr: 1e-08, loss: 4.55198\n",
      "cur_epoch: 1/800, cur_it: 250/464, lr: 1e-08, loss: 4.5502\n",
      "cur_epoch: 1/800, cur_it: 251/464, lr: 1e-08, loss: 4.55561\n",
      "cur_epoch: 1/800, cur_it: 252/464, lr: 1e-08, loss: 4.55641\n",
      "cur_epoch: 1/800, cur_it: 253/464, lr: 1e-08, loss: 4.5598\n",
      "cur_epoch: 1/800, cur_it: 254/464, lr: 1e-08, loss: 4.55739\n",
      "cur_epoch: 1/800, cur_it: 255/464, lr: 1e-08, loss: 4.55444\n",
      "cur_epoch: 1/800, cur_it: 256/464, lr: 1e-08, loss: 4.5529\n",
      "cur_epoch: 1/800, cur_it: 257/464, lr: 1e-08, loss: 4.55049\n",
      "cur_epoch: 1/800, cur_it: 258/464, lr: 1e-08, loss: 4.54844\n",
      "cur_epoch: 1/800, cur_it: 259/464, lr: 1e-08, loss: 4.54557\n",
      "cur_epoch: 1/800, cur_it: 260/464, lr: 1e-08, loss: 4.55019\n",
      "cur_epoch: 1/800, cur_it: 261/464, lr: 1e-08, loss: 4.54563\n",
      "cur_epoch: 1/800, cur_it: 262/464, lr: 1e-08, loss: 4.54349\n",
      "cur_epoch: 1/800, cur_it: 263/464, lr: 1e-08, loss: 4.54349\n",
      "cur_epoch: 1/800, cur_it: 264/464, lr: 1e-08, loss: 4.55084\n",
      "cur_epoch: 1/800, cur_it: 265/464, lr: 1e-08, loss: 4.5479\n",
      "cur_epoch: 1/800, cur_it: 266/464, lr: 1e-08, loss: 4.54994\n",
      "cur_epoch: 1/800, cur_it: 267/464, lr: 1e-08, loss: 4.55202\n",
      "cur_epoch: 1/800, cur_it: 268/464, lr: 1e-08, loss: 4.55153\n",
      "cur_epoch: 1/800, cur_it: 269/464, lr: 1e-08, loss: 4.55282\n",
      "cur_epoch: 1/800, cur_it: 270/464, lr: 1e-08, loss: 4.55108\n",
      "cur_epoch: 1/800, cur_it: 271/464, lr: 1e-08, loss: 4.54911\n",
      "cur_epoch: 1/800, cur_it: 272/464, lr: 1e-08, loss: 4.54809\n",
      "cur_epoch: 1/800, cur_it: 273/464, lr: 1e-08, loss: 4.54608\n",
      "cur_epoch: 1/800, cur_it: 274/464, lr: 1e-08, loss: 4.54379\n",
      "cur_epoch: 1/800, cur_it: 275/464, lr: 1e-08, loss: 4.54178\n",
      "cur_epoch: 1/800, cur_it: 276/464, lr: 1e-08, loss: 4.54105\n",
      "cur_epoch: 1/800, cur_it: 277/464, lr: 1e-08, loss: 4.53868\n",
      "cur_epoch: 1/800, cur_it: 278/464, lr: 1e-08, loss: 4.53654\n",
      "cur_epoch: 1/800, cur_it: 279/464, lr: 1e-08, loss: 4.53511\n",
      "cur_epoch: 1/800, cur_it: 280/464, lr: 1e-08, loss: 4.53549\n",
      "cur_epoch: 1/800, cur_it: 281/464, lr: 1e-08, loss: 4.53502\n",
      "cur_epoch: 1/800, cur_it: 282/464, lr: 1e-08, loss: 4.58687\n",
      "cur_epoch: 1/800, cur_it: 283/464, lr: 1e-08, loss: 4.58352\n",
      "cur_epoch: 1/800, cur_it: 284/464, lr: 1e-08, loss: 4.58251\n",
      "cur_epoch: 1/800, cur_it: 285/464, lr: 1e-08, loss: 4.58112\n",
      "cur_epoch: 1/800, cur_it: 286/464, lr: 1e-08, loss: 4.57898\n",
      "cur_epoch: 1/800, cur_it: 287/464, lr: 1e-08, loss: 4.57835\n",
      "cur_epoch: 1/800, cur_it: 288/464, lr: 1e-08, loss: 4.57807\n",
      "cur_epoch: 1/800, cur_it: 289/464, lr: 1e-08, loss: 4.57643\n",
      "cur_epoch: 1/800, cur_it: 290/464, lr: 1e-08, loss: 4.57602\n",
      "cur_epoch: 1/800, cur_it: 291/464, lr: 1e-08, loss: 4.57512\n",
      "cur_epoch: 1/800, cur_it: 292/464, lr: 1e-08, loss: 4.5798\n",
      "cur_epoch: 1/800, cur_it: 293/464, lr: 1e-08, loss: 4.57679\n",
      "cur_epoch: 1/800, cur_it: 294/464, lr: 1e-08, loss: 4.57557\n",
      "cur_epoch: 1/800, cur_it: 295/464, lr: 1e-08, loss: 4.57601\n",
      "cur_epoch: 1/800, cur_it: 296/464, lr: 1e-08, loss: 4.57552\n",
      "cur_epoch: 1/800, cur_it: 297/464, lr: 1e-08, loss: 4.57202\n",
      "cur_epoch: 1/800, cur_it: 298/464, lr: 1e-08, loss: 4.57016\n",
      "cur_epoch: 1/800, cur_it: 299/464, lr: 1e-08, loss: 4.56781\n",
      "cur_epoch: 1/800, cur_it: 300/464, lr: 1e-08, loss: 4.56609\n",
      "cur_epoch: 1/800, cur_it: 301/464, lr: 1e-08, loss: 4.59485\n",
      "cur_epoch: 1/800, cur_it: 302/464, lr: 1e-08, loss: 4.59244\n",
      "cur_epoch: 1/800, cur_it: 303/464, lr: 1e-08, loss: 4.5905\n",
      "cur_epoch: 1/800, cur_it: 304/464, lr: 1e-08, loss: 4.58766\n",
      "cur_epoch: 1/800, cur_it: 305/464, lr: 1e-08, loss: 4.58618\n",
      "cur_epoch: 1/800, cur_it: 306/464, lr: 1e-08, loss: 4.58532\n",
      "cur_epoch: 1/800, cur_it: 307/464, lr: 1e-08, loss: 4.59364\n",
      "cur_epoch: 1/800, cur_it: 308/464, lr: 1e-08, loss: 4.59319\n",
      "cur_epoch: 1/800, cur_it: 309/464, lr: 1e-08, loss: 4.5913\n",
      "cur_epoch: 1/800, cur_it: 310/464, lr: 1e-08, loss: 4.58982\n",
      "cur_epoch: 1/800, cur_it: 311/464, lr: 1e-08, loss: 4.58824\n",
      "cur_epoch: 1/800, cur_it: 312/464, lr: 1e-08, loss: 4.58877\n",
      "cur_epoch: 1/800, cur_it: 313/464, lr: 1e-08, loss: 4.58607\n",
      "cur_epoch: 1/800, cur_it: 314/464, lr: 1e-08, loss: 4.58373\n",
      "cur_epoch: 1/800, cur_it: 315/464, lr: 1e-08, loss: 4.58226\n",
      "cur_epoch: 1/800, cur_it: 316/464, lr: 1e-08, loss: 4.58178\n",
      "cur_epoch: 1/800, cur_it: 317/464, lr: 1e-08, loss: 4.58285\n",
      "cur_epoch: 1/800, cur_it: 318/464, lr: 1e-08, loss: 4.58167\n",
      "cur_epoch: 1/800, cur_it: 319/464, lr: 1e-08, loss: 4.58067\n",
      "cur_epoch: 1/800, cur_it: 320/464, lr: 1e-08, loss: 4.57907\n",
      "cur_epoch: 1/800, cur_it: 321/464, lr: 1e-08, loss: 4.57721\n",
      "cur_epoch: 1/800, cur_it: 322/464, lr: 1e-08, loss: 4.57637\n",
      "cur_epoch: 1/800, cur_it: 323/464, lr: 1e-08, loss: 4.57326\n",
      "cur_epoch: 1/800, cur_it: 324/464, lr: 1e-08, loss: 4.57451\n",
      "cur_epoch: 1/800, cur_it: 325/464, lr: 1e-08, loss: 4.57496\n",
      "cur_epoch: 1/800, cur_it: 326/464, lr: 1e-08, loss: 4.57306\n",
      "cur_epoch: 1/800, cur_it: 327/464, lr: 1e-08, loss: 4.57274\n",
      "cur_epoch: 1/800, cur_it: 328/464, lr: 1e-08, loss: 4.57149\n",
      "cur_epoch: 1/800, cur_it: 329/464, lr: 1e-08, loss: 4.56966\n",
      "cur_epoch: 1/800, cur_it: 330/464, lr: 1e-08, loss: 4.56849\n",
      "cur_epoch: 1/800, cur_it: 331/464, lr: 1e-08, loss: 4.56631\n",
      "cur_epoch: 1/800, cur_it: 332/464, lr: 1e-08, loss: 4.56464\n",
      "cur_epoch: 1/800, cur_it: 333/464, lr: 1e-08, loss: 4.56415\n",
      "cur_epoch: 1/800, cur_it: 334/464, lr: 1e-08, loss: 4.562\n",
      "cur_epoch: 1/800, cur_it: 335/464, lr: 1e-08, loss: 4.56135\n",
      "cur_epoch: 1/800, cur_it: 336/464, lr: 1e-08, loss: 4.55857\n",
      "cur_epoch: 1/800, cur_it: 337/464, lr: 1e-08, loss: 4.5565\n",
      "cur_epoch: 1/800, cur_it: 338/464, lr: 1e-08, loss: 4.55412\n",
      "cur_epoch: 1/800, cur_it: 339/464, lr: 1e-08, loss: 4.55348\n",
      "cur_epoch: 1/800, cur_it: 340/464, lr: 1e-08, loss: 4.55876\n",
      "cur_epoch: 1/800, cur_it: 341/464, lr: 1e-08, loss: 4.55679\n",
      "cur_epoch: 1/800, cur_it: 342/464, lr: 1e-08, loss: 4.55436\n",
      "cur_epoch: 1/800, cur_it: 343/464, lr: 1e-08, loss: 4.55455\n",
      "cur_epoch: 1/800, cur_it: 344/464, lr: 1e-08, loss: 4.55475\n",
      "cur_epoch: 1/800, cur_it: 345/464, lr: 1e-08, loss: 4.55382\n",
      "cur_epoch: 1/800, cur_it: 346/464, lr: 1e-08, loss: 4.55428\n",
      "cur_epoch: 1/800, cur_it: 347/464, lr: 1e-08, loss: 4.55456\n",
      "cur_epoch: 1/800, cur_it: 348/464, lr: 1e-08, loss: 4.55339\n",
      "cur_epoch: 1/800, cur_it: 349/464, lr: 1e-08, loss: 4.55109\n",
      "cur_epoch: 1/800, cur_it: 350/464, lr: 1e-08, loss: 4.5521\n",
      "cur_epoch: 1/800, cur_it: 351/464, lr: 1e-08, loss: 4.55167\n",
      "cur_epoch: 1/800, cur_it: 352/464, lr: 1e-08, loss: 4.55246\n",
      "cur_epoch: 1/800, cur_it: 353/464, lr: 1e-08, loss: 4.55047\n",
      "cur_epoch: 1/800, cur_it: 354/464, lr: 1e-08, loss: 4.54972\n",
      "cur_epoch: 1/800, cur_it: 355/464, lr: 1e-08, loss: 4.54941\n",
      "cur_epoch: 1/800, cur_it: 356/464, lr: 1e-08, loss: 4.54829\n",
      "cur_epoch: 1/800, cur_it: 357/464, lr: 1e-08, loss: 4.5466\n",
      "cur_epoch: 1/800, cur_it: 358/464, lr: 1e-08, loss: 4.54532\n",
      "cur_epoch: 1/800, cur_it: 359/464, lr: 1e-08, loss: 4.54425\n",
      "cur_epoch: 1/800, cur_it: 360/464, lr: 1e-08, loss: 4.54247\n",
      "cur_epoch: 1/800, cur_it: 361/464, lr: 1e-08, loss: 4.54585\n",
      "cur_epoch: 1/800, cur_it: 362/464, lr: 1e-08, loss: 4.54418\n",
      "cur_epoch: 1/800, cur_it: 363/464, lr: 1e-08, loss: 4.54267\n",
      "cur_epoch: 1/800, cur_it: 364/464, lr: 1e-08, loss: 4.55521\n",
      "cur_epoch: 1/800, cur_it: 365/464, lr: 1e-08, loss: 4.55532\n",
      "cur_epoch: 1/800, cur_it: 366/464, lr: 1e-08, loss: 4.55531\n",
      "cur_epoch: 1/800, cur_it: 367/464, lr: 1e-08, loss: 4.55504\n",
      "cur_epoch: 1/800, cur_it: 368/464, lr: 1e-08, loss: 4.55437\n",
      "cur_epoch: 1/800, cur_it: 369/464, lr: 1e-08, loss: 4.55359\n",
      "cur_epoch: 1/800, cur_it: 370/464, lr: 1e-08, loss: 4.55224\n",
      "cur_epoch: 1/800, cur_it: 371/464, lr: 1e-08, loss: 4.55043\n",
      "cur_epoch: 1/800, cur_it: 372/464, lr: 1e-08, loss: 4.54979\n",
      "cur_epoch: 1/800, cur_it: 373/464, lr: 1e-08, loss: 4.54845\n",
      "cur_epoch: 1/800, cur_it: 374/464, lr: 1e-08, loss: 4.56563\n",
      "cur_epoch: 1/800, cur_it: 375/464, lr: 1e-08, loss: 4.56513\n",
      "cur_epoch: 1/800, cur_it: 376/464, lr: 1e-08, loss: 4.56673\n",
      "cur_epoch: 1/800, cur_it: 377/464, lr: 1e-08, loss: 4.56484\n",
      "cur_epoch: 1/800, cur_it: 378/464, lr: 1e-08, loss: 4.56445\n",
      "cur_epoch: 1/800, cur_it: 379/464, lr: 1e-08, loss: 4.56335\n",
      "cur_epoch: 1/800, cur_it: 380/464, lr: 1e-08, loss: 4.56273\n",
      "cur_epoch: 1/800, cur_it: 381/464, lr: 1e-08, loss: 4.56027\n",
      "cur_epoch: 1/800, cur_it: 382/464, lr: 1e-08, loss: 4.56265\n",
      "cur_epoch: 1/800, cur_it: 383/464, lr: 1e-08, loss: 4.5607\n",
      "cur_epoch: 1/800, cur_it: 384/464, lr: 1e-08, loss: 4.55997\n",
      "cur_epoch: 1/800, cur_it: 385/464, lr: 1e-08, loss: 4.55863\n",
      "cur_epoch: 1/800, cur_it: 386/464, lr: 1e-08, loss: 4.56027\n",
      "cur_epoch: 1/800, cur_it: 387/464, lr: 1e-08, loss: 4.55867\n",
      "cur_epoch: 1/800, cur_it: 388/464, lr: 1e-08, loss: 4.55671\n",
      "cur_epoch: 1/800, cur_it: 389/464, lr: 1e-08, loss: 4.5553\n",
      "cur_epoch: 1/800, cur_it: 390/464, lr: 1e-08, loss: 4.55617\n",
      "cur_epoch: 1/800, cur_it: 391/464, lr: 1e-08, loss: 4.56696\n",
      "cur_epoch: 1/800, cur_it: 392/464, lr: 1e-08, loss: 4.5674\n",
      "cur_epoch: 1/800, cur_it: 393/464, lr: 1e-08, loss: 4.56562\n",
      "cur_epoch: 1/800, cur_it: 394/464, lr: 1e-08, loss: 4.56357\n",
      "cur_epoch: 1/800, cur_it: 395/464, lr: 1e-08, loss: 4.56168\n",
      "cur_epoch: 1/800, cur_it: 396/464, lr: 1e-08, loss: 4.56004\n",
      "cur_epoch: 1/800, cur_it: 397/464, lr: 1e-08, loss: 4.55911\n",
      "cur_epoch: 1/800, cur_it: 398/464, lr: 1e-08, loss: 4.55849\n",
      "cur_epoch: 1/800, cur_it: 399/464, lr: 1e-08, loss: 4.5611\n",
      "cur_epoch: 1/800, cur_it: 400/464, lr: 1e-08, loss: 4.56519\n",
      "cur_epoch: 1/800, cur_it: 401/464, lr: 1e-08, loss: 4.56553\n",
      "cur_epoch: 1/800, cur_it: 402/464, lr: 1e-08, loss: 4.5688\n",
      "cur_epoch: 1/800, cur_it: 403/464, lr: 1e-08, loss: 4.56723\n",
      "cur_epoch: 1/800, cur_it: 404/464, lr: 1e-08, loss: 4.56917\n",
      "cur_epoch: 1/800, cur_it: 405/464, lr: 1e-08, loss: 4.56695\n",
      "cur_epoch: 1/800, cur_it: 406/464, lr: 1e-08, loss: 4.56662\n",
      "cur_epoch: 1/800, cur_it: 407/464, lr: 1e-08, loss: 4.56465\n",
      "cur_epoch: 1/800, cur_it: 408/464, lr: 1e-08, loss: 4.56507\n",
      "cur_epoch: 1/800, cur_it: 409/464, lr: 1e-08, loss: 4.56379\n",
      "cur_epoch: 1/800, cur_it: 410/464, lr: 1e-08, loss: 4.56393\n",
      "cur_epoch: 1/800, cur_it: 411/464, lr: 1e-08, loss: 4.56257\n",
      "cur_epoch: 1/800, cur_it: 412/464, lr: 1e-08, loss: 4.56492\n",
      "cur_epoch: 1/800, cur_it: 413/464, lr: 1e-08, loss: 4.56569\n",
      "cur_epoch: 1/800, cur_it: 414/464, lr: 1e-08, loss: 4.57153\n",
      "cur_epoch: 1/800, cur_it: 415/464, lr: 1e-08, loss: 4.57131\n",
      "cur_epoch: 1/800, cur_it: 416/464, lr: 1e-08, loss: 4.56878\n",
      "cur_epoch: 1/800, cur_it: 417/464, lr: 1e-08, loss: 4.56779\n",
      "cur_epoch: 1/800, cur_it: 418/464, lr: 1e-08, loss: 4.56632\n",
      "cur_epoch: 1/800, cur_it: 419/464, lr: 1e-08, loss: 4.57336\n",
      "cur_epoch: 1/800, cur_it: 420/464, lr: 1e-08, loss: 4.57191\n",
      "cur_epoch: 1/800, cur_it: 421/464, lr: 1e-08, loss: 4.57041\n",
      "cur_epoch: 1/800, cur_it: 422/464, lr: 1e-08, loss: 4.57124\n",
      "cur_epoch: 1/800, cur_it: 423/464, lr: 1e-08, loss: 4.57275\n",
      "cur_epoch: 1/800, cur_it: 424/464, lr: 1e-08, loss: 4.57063\n",
      "cur_epoch: 1/800, cur_it: 425/464, lr: 1e-08, loss: 4.57462\n",
      "cur_epoch: 1/800, cur_it: 426/464, lr: 1e-08, loss: 4.57463\n",
      "cur_epoch: 1/800, cur_it: 427/464, lr: 1e-08, loss: 4.57277\n",
      "cur_epoch: 1/800, cur_it: 428/464, lr: 1e-08, loss: 4.57086\n",
      "cur_epoch: 1/800, cur_it: 429/464, lr: 1e-08, loss: 4.56962\n",
      "cur_epoch: 1/800, cur_it: 430/464, lr: 1e-08, loss: 4.56765\n",
      "cur_epoch: 1/800, cur_it: 431/464, lr: 1e-08, loss: 4.56584\n",
      "cur_epoch: 1/800, cur_it: 432/464, lr: 1e-08, loss: 4.56382\n",
      "cur_epoch: 1/800, cur_it: 433/464, lr: 1e-08, loss: 4.56242\n",
      "cur_epoch: 1/800, cur_it: 434/464, lr: 1e-08, loss: 4.5612\n",
      "cur_epoch: 1/800, cur_it: 435/464, lr: 1e-08, loss: 4.56079\n",
      "cur_epoch: 1/800, cur_it: 436/464, lr: 1e-08, loss: 4.5609\n",
      "cur_epoch: 1/800, cur_it: 437/464, lr: 1e-08, loss: 4.55918\n",
      "cur_epoch: 1/800, cur_it: 438/464, lr: 1e-08, loss: 4.5581\n",
      "cur_epoch: 1/800, cur_it: 439/464, lr: 1e-08, loss: 4.55738\n",
      "cur_epoch: 1/800, cur_it: 440/464, lr: 1e-08, loss: 4.55496\n",
      "cur_epoch: 1/800, cur_it: 441/464, lr: 1e-08, loss: 4.55527\n",
      "cur_epoch: 1/800, cur_it: 442/464, lr: 1e-08, loss: 4.55474\n",
      "cur_epoch: 1/800, cur_it: 443/464, lr: 1e-08, loss: 4.55808\n",
      "cur_epoch: 1/800, cur_it: 444/464, lr: 1e-08, loss: 4.55835\n",
      "cur_epoch: 1/800, cur_it: 445/464, lr: 1e-08, loss: 4.55711\n",
      "cur_epoch: 1/800, cur_it: 446/464, lr: 1e-08, loss: 4.55498\n",
      "cur_epoch: 1/800, cur_it: 447/464, lr: 1e-08, loss: 4.55328\n",
      "cur_epoch: 1/800, cur_it: 448/464, lr: 1e-08, loss: 4.55178\n",
      "cur_epoch: 1/800, cur_it: 449/464, lr: 1e-08, loss: 4.55058\n",
      "cur_epoch: 1/800, cur_it: 450/464, lr: 1e-08, loss: 4.54902\n",
      "cur_epoch: 1/800, cur_it: 451/464, lr: 1e-08, loss: 4.54808\n",
      "cur_epoch: 1/800, cur_it: 452/464, lr: 1e-08, loss: 4.548\n",
      "cur_epoch: 1/800, cur_it: 453/464, lr: 1e-08, loss: 4.54692\n",
      "cur_epoch: 1/800, cur_it: 454/464, lr: 1e-08, loss: 4.54581\n",
      "cur_epoch: 1/800, cur_it: 455/464, lr: 1e-08, loss: 4.54528\n",
      "cur_epoch: 1/800, cur_it: 456/464, lr: 1e-08, loss: 4.54448\n",
      "cur_epoch: 1/800, cur_it: 457/464, lr: 1e-08, loss: 4.54428\n",
      "cur_epoch: 1/800, cur_it: 458/464, lr: 1e-08, loss: 4.54386\n",
      "cur_epoch: 1/800, cur_it: 459/464, lr: 1e-08, loss: 4.54197\n",
      "cur_epoch: 1/800, cur_it: 460/464, lr: 1e-08, loss: 4.54223\n",
      "cur_epoch: 1/800, cur_it: 461/464, lr: 1e-08, loss: 4.54171\n",
      "cur_epoch: 1/800, cur_it: 462/464, lr: 1e-08, loss: 4.54068\n",
      "cur_epoch: 1/800, cur_it: 463/464, lr: 1e-08, loss: 4.54479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 00:01:09,648   INFO  **********************Start testing**********************\n",
      "2023-07-23 00:01:09,650   INFO  Loading KITTI dataset\n",
      "2023-07-23 00:01:09,744   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_epoch: 1/800, cur_it: 464/464, lr: 1e-08, loss: 4.54344\n",
      "Average predicted number of objects(3769 samples): 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/lib/python3.9/site-packages/numba/core/typed_passes.py:329: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.readthedocs.io/en/stable/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../pcdet/datasets/kitti/kitti_object_eval_python/eval.py\", line 122:\u001b[0m\n",
      "\u001b[1m@numba.jit(nopython=True, parallel=True)\n",
      "\u001b[1mdef d3_box_overlap_kernel(boxes, qboxes, rinc, criterion=-1):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaPerformanceWarning(msg,\n",
      "epochs:   0%|          | 1/800 [08:59<119:48:07, 539.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 {'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_3d/easy_R40': 0.0, 'Car_3d/moderate_R40': 0.0, 'Car_3d/hard_R40': 0.0, 'Car_bev/easy_R40': 0.0, 'Car_bev/moderate_R40': 0.0, 'Car_bev/hard_R40': 0.0, 'Car_image/easy_R40': 0.0, 'Car_image/moderate_R40': 0.0, 'Car_image/hard_R40': 0.0, 'Pedestrian_3d/easy_R40': 0.0, 'Pedestrian_3d/moderate_R40': 0.0, 'Pedestrian_3d/hard_R40': 0.0, 'Pedestrian_bev/easy_R40': 0.0, 'Pedestrian_bev/moderate_R40': 0.0, 'Pedestrian_bev/hard_R40': 0.0, 'Pedestrian_image/easy_R40': 0.0, 'Pedestrian_image/moderate_R40': 0.0, 'Pedestrian_image/hard_R40': 0.0, 'Cyclist_3d/easy_R40': 0.0, 'Cyclist_3d/moderate_R40': 0.0, 'Cyclist_3d/hard_R40': 0.0, 'Cyclist_bev/easy_R40': 0.0, 'Cyclist_bev/moderate_R40': 0.0, 'Cyclist_bev/hard_R40': 0.0, 'Cyclist_image/easy_R40': 0.0, 'Cyclist_image/moderate_R40': 0.0, 'Cyclist_image/hard_R40': 0.0}\n",
      "cur_epoch: 2/800, cur_it: 1/464, lr: 1e-08, loss: 4.11907\n",
      "cur_epoch: 2/800, cur_it: 2/464, lr: 1e-08, loss: 4.75478\n",
      "cur_epoch: 2/800, cur_it: 3/464, lr: 1e-08, loss: 4.41949\n",
      "cur_epoch: 2/800, cur_it: 4/464, lr: 1e-08, loss: 4.27216\n",
      "cur_epoch: 2/800, cur_it: 5/464, lr: 1e-08, loss: 4.2133\n",
      "cur_epoch: 2/800, cur_it: 6/464, lr: 1e-08, loss: 4.11376\n",
      "cur_epoch: 2/800, cur_it: 7/464, lr: 1e-08, loss: 4.36885\n",
      "cur_epoch: 2/800, cur_it: 8/464, lr: 1e-08, loss: 4.40434\n",
      "cur_epoch: 2/800, cur_it: 9/464, lr: 1e-08, loss: 4.37359\n",
      "cur_epoch: 2/800, cur_it: 10/464, lr: 1e-08, loss: 4.34016\n",
      "cur_epoch: 2/800, cur_it: 11/464, lr: 1e-08, loss: 4.35576\n",
      "cur_epoch: 2/800, cur_it: 12/464, lr: 1e-08, loss: 4.3301\n",
      "cur_epoch: 2/800, cur_it: 13/464, lr: 1e-08, loss: 4.27261\n",
      "cur_epoch: 2/800, cur_it: 14/464, lr: 1e-08, loss: 4.24698\n",
      "cur_epoch: 2/800, cur_it: 15/464, lr: 1e-08, loss: 4.26279\n",
      "cur_epoch: 2/800, cur_it: 16/464, lr: 1e-08, loss: 4.23805\n",
      "cur_epoch: 2/800, cur_it: 17/464, lr: 1e-08, loss: 4.25196\n",
      "cur_epoch: 2/800, cur_it: 18/464, lr: 1e-08, loss: 4.2162\n",
      "cur_epoch: 2/800, cur_it: 19/464, lr: 1e-08, loss: 4.21842\n",
      "cur_epoch: 2/800, cur_it: 20/464, lr: 1e-08, loss: 4.39029\n",
      "cur_epoch: 2/800, cur_it: 21/464, lr: 1e-08, loss: 4.35533\n",
      "cur_epoch: 2/800, cur_it: 22/464, lr: 1e-08, loss: 4.37731\n",
      "cur_epoch: 2/800, cur_it: 23/464, lr: 1e-08, loss: 4.34694\n",
      "cur_epoch: 2/800, cur_it: 24/464, lr: 1e-08, loss: 4.47227\n",
      "cur_epoch: 2/800, cur_it: 25/464, lr: 1e-08, loss: 4.4642\n",
      "cur_epoch: 2/800, cur_it: 26/464, lr: 1e-08, loss: 4.4547\n",
      "cur_epoch: 2/800, cur_it: 27/464, lr: 1e-08, loss: 4.43827\n",
      "cur_epoch: 2/800, cur_it: 28/464, lr: 1e-08, loss: 4.51317\n",
      "cur_epoch: 2/800, cur_it: 29/464, lr: 1e-08, loss: 4.54759\n",
      "cur_epoch: 2/800, cur_it: 30/464, lr: 1e-08, loss: 4.52066\n",
      "cur_epoch: 2/800, cur_it: 31/464, lr: 1e-08, loss: 4.50072\n",
      "cur_epoch: 2/800, cur_it: 32/464, lr: 1e-08, loss: 4.49652\n",
      "cur_epoch: 2/800, cur_it: 33/464, lr: 1e-08, loss: 4.48021\n",
      "cur_epoch: 2/800, cur_it: 34/464, lr: 1e-08, loss: 4.46222\n",
      "cur_epoch: 2/800, cur_it: 35/464, lr: 1e-08, loss: 4.45882\n",
      "cur_epoch: 2/800, cur_it: 36/464, lr: 1e-08, loss: 4.45412\n",
      "cur_epoch: 2/800, cur_it: 37/464, lr: 1e-08, loss: 4.4689\n",
      "cur_epoch: 2/800, cur_it: 38/464, lr: 1e-08, loss: 4.4527\n",
      "cur_epoch: 2/800, cur_it: 39/464, lr: 1e-08, loss: 4.43569\n",
      "cur_epoch: 2/800, cur_it: 40/464, lr: 1e-08, loss: 4.54248\n",
      "cur_epoch: 2/800, cur_it: 41/464, lr: 1e-08, loss: 4.55878\n",
      "cur_epoch: 2/800, cur_it: 42/464, lr: 1e-08, loss: 4.59418\n",
      "cur_epoch: 2/800, cur_it: 43/464, lr: 1e-08, loss: 4.59328\n",
      "cur_epoch: 2/800, cur_it: 44/464, lr: 1e-08, loss: 4.57004\n",
      "cur_epoch: 2/800, cur_it: 45/464, lr: 1e-08, loss: 4.56729\n",
      "cur_epoch: 2/800, cur_it: 46/464, lr: 1e-08, loss: 4.55574\n",
      "cur_epoch: 2/800, cur_it: 47/464, lr: 1e-08, loss: 4.55061\n",
      "cur_epoch: 2/800, cur_it: 48/464, lr: 1e-08, loss: 4.5575\n",
      "cur_epoch: 2/800, cur_it: 49/464, lr: 1e-08, loss: 4.5508\n",
      "cur_epoch: 2/800, cur_it: 50/464, lr: 1e-08, loss: 4.53856\n",
      "cur_epoch: 2/800, cur_it: 51/464, lr: 1e-08, loss: 4.54404\n",
      "cur_epoch: 2/800, cur_it: 52/464, lr: 1e-08, loss: 4.54031\n",
      "cur_epoch: 2/800, cur_it: 53/464, lr: 1e-08, loss: 4.52732\n",
      "cur_epoch: 2/800, cur_it: 54/464, lr: 1e-08, loss: 4.51454\n",
      "cur_epoch: 2/800, cur_it: 55/464, lr: 1e-08, loss: 4.56106\n",
      "cur_epoch: 2/800, cur_it: 56/464, lr: 1e-08, loss: 4.54046\n",
      "cur_epoch: 2/800, cur_it: 57/464, lr: 1e-08, loss: 4.53086\n",
      "cur_epoch: 2/800, cur_it: 58/464, lr: 1e-08, loss: 4.53278\n",
      "cur_epoch: 2/800, cur_it: 59/464, lr: 1e-08, loss: 4.53998\n",
      "cur_epoch: 2/800, cur_it: 60/464, lr: 1e-08, loss: 4.54021\n",
      "cur_epoch: 2/800, cur_it: 61/464, lr: 1e-08, loss: 4.52771\n",
      "cur_epoch: 2/800, cur_it: 62/464, lr: 1e-08, loss: 4.51566\n",
      "cur_epoch: 2/800, cur_it: 63/464, lr: 1e-08, loss: 4.51812\n",
      "cur_epoch: 2/800, cur_it: 64/464, lr: 1e-08, loss: 4.52138\n",
      "cur_epoch: 2/800, cur_it: 65/464, lr: 1e-08, loss: 4.51603\n",
      "cur_epoch: 2/800, cur_it: 66/464, lr: 1e-08, loss: 4.51354\n",
      "cur_epoch: 2/800, cur_it: 67/464, lr: 1e-08, loss: 4.52551\n",
      "cur_epoch: 2/800, cur_it: 68/464, lr: 1e-08, loss: 4.52709\n",
      "cur_epoch: 2/800, cur_it: 69/464, lr: 1e-08, loss: 4.53125\n",
      "cur_epoch: 2/800, cur_it: 70/464, lr: 1e-08, loss: 4.5284\n",
      "cur_epoch: 2/800, cur_it: 71/464, lr: 1e-08, loss: 4.53253\n",
      "cur_epoch: 2/800, cur_it: 72/464, lr: 1e-08, loss: 4.52052\n",
      "cur_epoch: 2/800, cur_it: 73/464, lr: 1e-08, loss: 4.65412\n",
      "cur_epoch: 2/800, cur_it: 74/464, lr: 1e-08, loss: 4.65447\n",
      "cur_epoch: 2/800, cur_it: 75/464, lr: 1e-08, loss: 4.65369\n",
      "cur_epoch: 2/800, cur_it: 76/464, lr: 1e-08, loss: 4.65016\n",
      "cur_epoch: 2/800, cur_it: 77/464, lr: 1e-08, loss: 4.6453\n",
      "cur_epoch: 2/800, cur_it: 78/464, lr: 1e-08, loss: 4.64139\n",
      "cur_epoch: 2/800, cur_it: 79/464, lr: 1e-08, loss: 4.63497\n",
      "cur_epoch: 2/800, cur_it: 80/464, lr: 1e-08, loss: 4.62515\n",
      "cur_epoch: 2/800, cur_it: 81/464, lr: 1e-08, loss: 4.62779\n",
      "cur_epoch: 2/800, cur_it: 82/464, lr: 1e-08, loss: 4.6185\n",
      "cur_epoch: 2/800, cur_it: 83/464, lr: 1e-08, loss: 4.6293\n",
      "cur_epoch: 2/800, cur_it: 84/464, lr: 1e-08, loss: 4.64917\n",
      "cur_epoch: 2/800, cur_it: 85/464, lr: 1e-08, loss: 4.65384\n",
      "cur_epoch: 2/800, cur_it: 86/464, lr: 1e-08, loss: 4.65988\n",
      "cur_epoch: 2/800, cur_it: 87/464, lr: 1e-08, loss: 4.66164\n",
      "cur_epoch: 2/800, cur_it: 88/464, lr: 1e-08, loss: 4.6536\n",
      "cur_epoch: 2/800, cur_it: 89/464, lr: 1e-08, loss: 4.65158\n",
      "cur_epoch: 2/800, cur_it: 90/464, lr: 1e-08, loss: 4.65289\n",
      "cur_epoch: 2/800, cur_it: 91/464, lr: 1e-08, loss: 4.64814\n",
      "cur_epoch: 2/800, cur_it: 92/464, lr: 1e-08, loss: 4.64979\n",
      "cur_epoch: 2/800, cur_it: 93/464, lr: 1e-08, loss: 4.64906\n",
      "cur_epoch: 2/800, cur_it: 94/464, lr: 1e-08, loss: 4.65474\n",
      "cur_epoch: 2/800, cur_it: 95/464, lr: 1e-08, loss: 4.64817\n",
      "cur_epoch: 2/800, cur_it: 96/464, lr: 1e-08, loss: 4.64807\n",
      "cur_epoch: 2/800, cur_it: 97/464, lr: 1e-08, loss: 4.63825\n",
      "cur_epoch: 2/800, cur_it: 98/464, lr: 1e-08, loss: 4.6292\n",
      "cur_epoch: 2/800, cur_it: 99/464, lr: 1e-08, loss: 4.62111\n",
      "cur_epoch: 2/800, cur_it: 100/464, lr: 1e-08, loss: 4.61489\n",
      "cur_epoch: 2/800, cur_it: 101/464, lr: 1e-08, loss: 4.61345\n",
      "cur_epoch: 2/800, cur_it: 102/464, lr: 1e-08, loss: 4.60843\n",
      "cur_epoch: 2/800, cur_it: 103/464, lr: 1e-08, loss: 4.60213\n",
      "cur_epoch: 2/800, cur_it: 104/464, lr: 1e-08, loss: 4.59741\n",
      "cur_epoch: 2/800, cur_it: 105/464, lr: 1e-08, loss: 4.58893\n",
      "cur_epoch: 2/800, cur_it: 106/464, lr: 1e-08, loss: 4.58799\n",
      "cur_epoch: 2/800, cur_it: 107/464, lr: 1e-08, loss: 4.58834\n",
      "cur_epoch: 2/800, cur_it: 108/464, lr: 1e-08, loss: 4.5876\n",
      "cur_epoch: 2/800, cur_it: 109/464, lr: 1e-08, loss: 4.58132\n",
      "cur_epoch: 2/800, cur_it: 110/464, lr: 1e-08, loss: 4.57641\n",
      "cur_epoch: 2/800, cur_it: 111/464, lr: 1e-08, loss: 4.5769\n",
      "cur_epoch: 2/800, cur_it: 112/464, lr: 1e-08, loss: 4.58\n",
      "cur_epoch: 2/800, cur_it: 113/464, lr: 1e-08, loss: 4.59491\n",
      "cur_epoch: 2/800, cur_it: 114/464, lr: 1e-08, loss: 4.5929\n",
      "cur_epoch: 2/800, cur_it: 115/464, lr: 1e-08, loss: 4.5924\n",
      "cur_epoch: 2/800, cur_it: 116/464, lr: 1e-08, loss: 4.58616\n",
      "cur_epoch: 2/800, cur_it: 117/464, lr: 1e-08, loss: 4.58344\n",
      "cur_epoch: 2/800, cur_it: 118/464, lr: 1e-08, loss: 4.58692\n",
      "cur_epoch: 2/800, cur_it: 119/464, lr: 1e-08, loss: 4.57763\n",
      "cur_epoch: 2/800, cur_it: 120/464, lr: 1e-08, loss: 4.57386\n",
      "cur_epoch: 2/800, cur_it: 121/464, lr: 1e-08, loss: 4.56879\n",
      "cur_epoch: 2/800, cur_it: 122/464, lr: 1e-08, loss: 4.56367\n",
      "cur_epoch: 2/800, cur_it: 123/464, lr: 1e-08, loss: 4.55731\n",
      "cur_epoch: 2/800, cur_it: 124/464, lr: 1e-08, loss: 4.55213\n",
      "cur_epoch: 2/800, cur_it: 125/464, lr: 1e-08, loss: 4.55042\n",
      "cur_epoch: 2/800, cur_it: 126/464, lr: 1e-08, loss: 4.55323\n",
      "cur_epoch: 2/800, cur_it: 127/464, lr: 1e-08, loss: 4.5566\n",
      "cur_epoch: 2/800, cur_it: 128/464, lr: 1e-08, loss: 4.55321\n",
      "cur_epoch: 2/800, cur_it: 129/464, lr: 1e-08, loss: 4.55173\n",
      "cur_epoch: 2/800, cur_it: 130/464, lr: 1e-08, loss: 4.56289\n",
      "cur_epoch: 2/800, cur_it: 131/464, lr: 1e-08, loss: 4.55835\n",
      "cur_epoch: 2/800, cur_it: 132/464, lr: 1e-08, loss: 4.55649\n",
      "cur_epoch: 2/800, cur_it: 133/464, lr: 1e-08, loss: 4.55206\n",
      "cur_epoch: 2/800, cur_it: 134/464, lr: 1e-08, loss: 4.55042\n",
      "cur_epoch: 2/800, cur_it: 135/464, lr: 1e-08, loss: 4.546\n",
      "cur_epoch: 2/800, cur_it: 136/464, lr: 1e-08, loss: 4.54232\n",
      "cur_epoch: 2/800, cur_it: 137/464, lr: 1e-08, loss: 4.54044\n",
      "cur_epoch: 2/800, cur_it: 138/464, lr: 1e-08, loss: 4.53791\n",
      "cur_epoch: 2/800, cur_it: 139/464, lr: 1e-08, loss: 4.54055\n",
      "cur_epoch: 2/800, cur_it: 140/464, lr: 1e-08, loss: 4.54049\n",
      "cur_epoch: 2/800, cur_it: 141/464, lr: 1e-08, loss: 4.54229\n",
      "cur_epoch: 2/800, cur_it: 142/464, lr: 1e-08, loss: 4.53776\n",
      "cur_epoch: 2/800, cur_it: 143/464, lr: 1e-08, loss: 4.54861\n",
      "cur_epoch: 2/800, cur_it: 144/464, lr: 1e-08, loss: 4.54477\n",
      "cur_epoch: 2/800, cur_it: 145/464, lr: 1e-08, loss: 4.53903\n",
      "cur_epoch: 2/800, cur_it: 146/464, lr: 1e-08, loss: 4.53299\n",
      "cur_epoch: 2/800, cur_it: 147/464, lr: 1e-08, loss: 4.54724\n",
      "cur_epoch: 2/800, cur_it: 148/464, lr: 1e-08, loss: 4.54465\n",
      "cur_epoch: 2/800, cur_it: 149/464, lr: 1e-08, loss: 4.54177\n",
      "cur_epoch: 2/800, cur_it: 150/464, lr: 1e-08, loss: 4.54045\n",
      "cur_epoch: 2/800, cur_it: 151/464, lr: 1e-08, loss: 4.53745\n",
      "cur_epoch: 2/800, cur_it: 152/464, lr: 1e-08, loss: 4.53369\n",
      "cur_epoch: 2/800, cur_it: 153/464, lr: 1e-08, loss: 4.54008\n",
      "cur_epoch: 2/800, cur_it: 154/464, lr: 1e-08, loss: 4.53536\n",
      "cur_epoch: 2/800, cur_it: 155/464, lr: 1e-08, loss: 4.53014\n",
      "cur_epoch: 2/800, cur_it: 156/464, lr: 1e-08, loss: 4.524\n",
      "cur_epoch: 2/800, cur_it: 157/464, lr: 1e-08, loss: 4.52926\n",
      "cur_epoch: 2/800, cur_it: 158/464, lr: 1e-08, loss: 4.5263\n",
      "cur_epoch: 2/800, cur_it: 159/464, lr: 1e-08, loss: 4.52291\n",
      "cur_epoch: 2/800, cur_it: 160/464, lr: 1e-08, loss: 4.5358\n",
      "cur_epoch: 2/800, cur_it: 161/464, lr: 1e-08, loss: 4.53212\n",
      "cur_epoch: 2/800, cur_it: 162/464, lr: 1e-08, loss: 4.52718\n",
      "cur_epoch: 2/800, cur_it: 163/464, lr: 1e-08, loss: 4.53483\n",
      "cur_epoch: 2/800, cur_it: 164/464, lr: 1e-08, loss: 4.53337\n",
      "cur_epoch: 2/800, cur_it: 165/464, lr: 1e-08, loss: 4.60648\n",
      "cur_epoch: 2/800, cur_it: 166/464, lr: 1e-08, loss: 4.60218\n",
      "cur_epoch: 2/800, cur_it: 167/464, lr: 1e-08, loss: 4.59944\n",
      "cur_epoch: 2/800, cur_it: 168/464, lr: 1e-08, loss: 4.59876\n",
      "cur_epoch: 2/800, cur_it: 169/464, lr: 1e-08, loss: 4.59867\n",
      "cur_epoch: 2/800, cur_it: 170/464, lr: 1e-08, loss: 4.59516\n",
      "cur_epoch: 2/800, cur_it: 171/464, lr: 1e-08, loss: 4.59207\n",
      "cur_epoch: 2/800, cur_it: 172/464, lr: 1e-08, loss: 4.58931\n",
      "cur_epoch: 2/800, cur_it: 173/464, lr: 1e-08, loss: 4.58765\n",
      "cur_epoch: 2/800, cur_it: 174/464, lr: 1e-08, loss: 4.59283\n",
      "cur_epoch: 2/800, cur_it: 175/464, lr: 1e-08, loss: 4.59034\n",
      "cur_epoch: 2/800, cur_it: 176/464, lr: 1e-08, loss: 4.58652\n",
      "cur_epoch: 2/800, cur_it: 177/464, lr: 1e-08, loss: 4.58579\n",
      "cur_epoch: 2/800, cur_it: 178/464, lr: 1e-08, loss: 4.5862\n",
      "cur_epoch: 2/800, cur_it: 179/464, lr: 1e-08, loss: 4.58506\n",
      "cur_epoch: 2/800, cur_it: 180/464, lr: 1e-08, loss: 4.58458\n",
      "cur_epoch: 2/800, cur_it: 181/464, lr: 1e-08, loss: 4.58207\n",
      "cur_epoch: 2/800, cur_it: 182/464, lr: 1e-08, loss: 4.58068\n",
      "cur_epoch: 2/800, cur_it: 183/464, lr: 1e-08, loss: 4.58391\n",
      "cur_epoch: 2/800, cur_it: 184/464, lr: 1e-08, loss: 4.58019\n",
      "cur_epoch: 2/800, cur_it: 185/464, lr: 1e-08, loss: 4.57848\n",
      "cur_epoch: 2/800, cur_it: 186/464, lr: 1e-08, loss: 4.57422\n",
      "cur_epoch: 2/800, cur_it: 187/464, lr: 1e-08, loss: 4.57249\n",
      "cur_epoch: 2/800, cur_it: 188/464, lr: 1e-08, loss: 4.56788\n",
      "cur_epoch: 2/800, cur_it: 189/464, lr: 1e-08, loss: 4.56581\n",
      "cur_epoch: 2/800, cur_it: 190/464, lr: 1e-08, loss: 4.56419\n",
      "cur_epoch: 2/800, cur_it: 191/464, lr: 1e-08, loss: 4.56071\n",
      "cur_epoch: 2/800, cur_it: 192/464, lr: 1e-08, loss: 4.56007\n",
      "cur_epoch: 2/800, cur_it: 193/464, lr: 1e-08, loss: 4.55786\n",
      "cur_epoch: 2/800, cur_it: 194/464, lr: 1e-08, loss: 4.56213\n",
      "cur_epoch: 2/800, cur_it: 195/464, lr: 1e-08, loss: 4.56005\n",
      "cur_epoch: 2/800, cur_it: 196/464, lr: 1e-08, loss: 4.55879\n",
      "cur_epoch: 2/800, cur_it: 197/464, lr: 1e-08, loss: 4.55677\n",
      "cur_epoch: 2/800, cur_it: 198/464, lr: 1e-08, loss: 4.55317\n",
      "cur_epoch: 2/800, cur_it: 199/464, lr: 1e-08, loss: 4.54984\n",
      "cur_epoch: 2/800, cur_it: 200/464, lr: 1e-08, loss: 4.54829\n",
      "cur_epoch: 2/800, cur_it: 201/464, lr: 1e-08, loss: 4.55849\n",
      "cur_epoch: 2/800, cur_it: 202/464, lr: 1e-08, loss: 4.55698\n",
      "cur_epoch: 2/800, cur_it: 203/464, lr: 1e-08, loss: 4.55405\n",
      "cur_epoch: 2/800, cur_it: 204/464, lr: 1e-08, loss: 4.55106\n",
      "cur_epoch: 2/800, cur_it: 205/464, lr: 1e-08, loss: 4.54892\n",
      "cur_epoch: 2/800, cur_it: 206/464, lr: 1e-08, loss: 4.54505\n",
      "cur_epoch: 2/800, cur_it: 207/464, lr: 1e-08, loss: 4.54391\n",
      "cur_epoch: 2/800, cur_it: 208/464, lr: 1e-08, loss: 4.54109\n",
      "cur_epoch: 2/800, cur_it: 209/464, lr: 1e-08, loss: 4.54039\n",
      "cur_epoch: 2/800, cur_it: 210/464, lr: 1e-08, loss: 4.54071\n",
      "cur_epoch: 2/800, cur_it: 211/464, lr: 1e-08, loss: 4.55388\n",
      "cur_epoch: 2/800, cur_it: 212/464, lr: 1e-08, loss: 4.55831\n",
      "cur_epoch: 2/800, cur_it: 213/464, lr: 1e-08, loss: 4.55613\n",
      "cur_epoch: 2/800, cur_it: 214/464, lr: 1e-08, loss: 4.55474\n",
      "cur_epoch: 2/800, cur_it: 215/464, lr: 1e-08, loss: 4.55236\n",
      "cur_epoch: 2/800, cur_it: 216/464, lr: 1e-08, loss: 4.54839\n",
      "cur_epoch: 2/800, cur_it: 217/464, lr: 1e-08, loss: 4.54718\n",
      "cur_epoch: 2/800, cur_it: 218/464, lr: 1e-08, loss: 4.54697\n",
      "cur_epoch: 2/800, cur_it: 219/464, lr: 1e-08, loss: 4.54652\n",
      "cur_epoch: 2/800, cur_it: 220/464, lr: 1e-08, loss: 4.55421\n",
      "cur_epoch: 2/800, cur_it: 221/464, lr: 1e-08, loss: 4.55027\n",
      "cur_epoch: 2/800, cur_it: 222/464, lr: 1e-08, loss: 4.54672\n",
      "cur_epoch: 2/800, cur_it: 223/464, lr: 1e-08, loss: 4.55695\n",
      "cur_epoch: 2/800, cur_it: 224/464, lr: 1e-08, loss: 4.55545\n",
      "cur_epoch: 2/800, cur_it: 225/464, lr: 1e-08, loss: 4.55559\n",
      "cur_epoch: 2/800, cur_it: 226/464, lr: 1e-08, loss: 4.55205\n",
      "cur_epoch: 2/800, cur_it: 227/464, lr: 1e-08, loss: 4.55236\n",
      "cur_epoch: 2/800, cur_it: 228/464, lr: 1e-08, loss: 4.55034\n",
      "cur_epoch: 2/800, cur_it: 229/464, lr: 1e-08, loss: 4.54928\n",
      "cur_epoch: 2/800, cur_it: 230/464, lr: 1e-08, loss: 4.54972\n",
      "cur_epoch: 2/800, cur_it: 231/464, lr: 1e-08, loss: 4.55292\n",
      "cur_epoch: 2/800, cur_it: 232/464, lr: 1e-08, loss: 4.55372\n",
      "cur_epoch: 2/800, cur_it: 233/464, lr: 1e-08, loss: 4.55828\n",
      "cur_epoch: 2/800, cur_it: 234/464, lr: 1e-08, loss: 4.55892\n",
      "cur_epoch: 2/800, cur_it: 235/464, lr: 1e-08, loss: 4.56714\n",
      "cur_epoch: 2/800, cur_it: 236/464, lr: 1e-08, loss: 4.565\n",
      "cur_epoch: 2/800, cur_it: 237/464, lr: 1e-08, loss: 4.56324\n",
      "cur_epoch: 2/800, cur_it: 238/464, lr: 1e-08, loss: 4.56023\n",
      "cur_epoch: 2/800, cur_it: 239/464, lr: 1e-08, loss: 4.55638\n",
      "cur_epoch: 2/800, cur_it: 240/464, lr: 1e-08, loss: 4.55436\n",
      "cur_epoch: 2/800, cur_it: 241/464, lr: 1e-08, loss: 4.55306\n",
      "cur_epoch: 2/800, cur_it: 242/464, lr: 1e-08, loss: 4.5505\n",
      "cur_epoch: 2/800, cur_it: 243/464, lr: 1e-08, loss: 4.54798\n",
      "cur_epoch: 2/800, cur_it: 244/464, lr: 1e-08, loss: 4.55282\n",
      "cur_epoch: 2/800, cur_it: 245/464, lr: 1e-08, loss: 4.55044\n",
      "cur_epoch: 2/800, cur_it: 246/464, lr: 1e-08, loss: 4.54908\n",
      "cur_epoch: 2/800, cur_it: 247/464, lr: 1e-08, loss: 4.54693\n",
      "cur_epoch: 2/800, cur_it: 248/464, lr: 1e-08, loss: 4.54501\n",
      "cur_epoch: 2/800, cur_it: 249/464, lr: 1e-08, loss: 4.54233\n",
      "cur_epoch: 2/800, cur_it: 250/464, lr: 1e-08, loss: 4.5411\n",
      "cur_epoch: 2/800, cur_it: 251/464, lr: 1e-08, loss: 4.53896\n",
      "cur_epoch: 2/800, cur_it: 252/464, lr: 1e-08, loss: 4.53898\n",
      "cur_epoch: 2/800, cur_it: 253/464, lr: 1e-08, loss: 4.53562\n",
      "cur_epoch: 2/800, cur_it: 254/464, lr: 1e-08, loss: 4.53525\n",
      "cur_epoch: 2/800, cur_it: 255/464, lr: 1e-08, loss: 4.53761\n",
      "cur_epoch: 2/800, cur_it: 256/464, lr: 1e-08, loss: 4.53695\n",
      "cur_epoch: 2/800, cur_it: 257/464, lr: 1e-08, loss: 4.53437\n",
      "cur_epoch: 2/800, cur_it: 258/464, lr: 1e-08, loss: 4.53616\n",
      "cur_epoch: 2/800, cur_it: 259/464, lr: 1e-08, loss: 4.53735\n",
      "cur_epoch: 2/800, cur_it: 260/464, lr: 1e-08, loss: 4.53387\n",
      "cur_epoch: 2/800, cur_it: 261/464, lr: 1e-08, loss: 4.53412\n",
      "cur_epoch: 2/800, cur_it: 262/464, lr: 1e-08, loss: 4.53983\n",
      "cur_epoch: 2/800, cur_it: 263/464, lr: 1e-08, loss: 4.53828\n",
      "cur_epoch: 2/800, cur_it: 264/464, lr: 1e-08, loss: 4.5349\n",
      "cur_epoch: 2/800, cur_it: 265/464, lr: 1e-08, loss: 4.53297\n",
      "cur_epoch: 2/800, cur_it: 266/464, lr: 1e-08, loss: 4.53359\n",
      "cur_epoch: 2/800, cur_it: 267/464, lr: 1e-08, loss: 4.53241\n",
      "cur_epoch: 2/800, cur_it: 268/464, lr: 1e-08, loss: 4.53554\n",
      "cur_epoch: 2/800, cur_it: 269/464, lr: 1e-08, loss: 4.53511\n",
      "cur_epoch: 2/800, cur_it: 270/464, lr: 1e-08, loss: 4.53326\n",
      "cur_epoch: 2/800, cur_it: 271/464, lr: 1e-08, loss: 4.53415\n",
      "cur_epoch: 2/800, cur_it: 272/464, lr: 1e-08, loss: 4.53169\n",
      "cur_epoch: 2/800, cur_it: 273/464, lr: 1e-08, loss: 4.53546\n",
      "cur_epoch: 2/800, cur_it: 274/464, lr: 1e-08, loss: 4.53308\n",
      "cur_epoch: 2/800, cur_it: 275/464, lr: 1e-08, loss: 4.53425\n",
      "cur_epoch: 2/800, cur_it: 276/464, lr: 1e-08, loss: 4.5326\n",
      "cur_epoch: 2/800, cur_it: 277/464, lr: 1e-08, loss: 4.53109\n",
      "cur_epoch: 2/800, cur_it: 278/464, lr: 1e-08, loss: 4.52986\n",
      "cur_epoch: 2/800, cur_it: 279/464, lr: 1e-08, loss: 4.52896\n",
      "cur_epoch: 2/800, cur_it: 280/464, lr: 1e-08, loss: 4.52627\n",
      "cur_epoch: 2/800, cur_it: 281/464, lr: 1e-08, loss: 4.52338\n",
      "cur_epoch: 2/800, cur_it: 282/464, lr: 1e-08, loss: 4.52073\n",
      "cur_epoch: 2/800, cur_it: 283/464, lr: 1e-08, loss: 4.5207\n",
      "cur_epoch: 2/800, cur_it: 284/464, lr: 1e-08, loss: 4.51968\n",
      "cur_epoch: 2/800, cur_it: 285/464, lr: 1e-08, loss: 4.51877\n",
      "cur_epoch: 2/800, cur_it: 286/464, lr: 1e-08, loss: 4.51815\n",
      "cur_epoch: 2/800, cur_it: 287/464, lr: 1e-08, loss: 4.52\n",
      "cur_epoch: 2/800, cur_it: 288/464, lr: 1e-08, loss: 4.51835\n",
      "cur_epoch: 2/800, cur_it: 289/464, lr: 1e-08, loss: 4.51655\n",
      "cur_epoch: 2/800, cur_it: 290/464, lr: 1e-08, loss: 4.51421\n",
      "cur_epoch: 2/800, cur_it: 291/464, lr: 1e-08, loss: 4.52111\n",
      "cur_epoch: 2/800, cur_it: 292/464, lr: 1e-08, loss: 4.52015\n",
      "cur_epoch: 2/800, cur_it: 293/464, lr: 1e-08, loss: 4.5182\n",
      "cur_epoch: 2/800, cur_it: 294/464, lr: 1e-08, loss: 4.51556\n",
      "cur_epoch: 2/800, cur_it: 295/464, lr: 1e-08, loss: 4.51444\n",
      "cur_epoch: 2/800, cur_it: 296/464, lr: 1e-08, loss: 4.51161\n",
      "cur_epoch: 2/800, cur_it: 297/464, lr: 1e-08, loss: 4.51439\n",
      "cur_epoch: 2/800, cur_it: 298/464, lr: 1e-08, loss: 4.51667\n",
      "cur_epoch: 2/800, cur_it: 299/464, lr: 1e-08, loss: 4.51753\n",
      "cur_epoch: 2/800, cur_it: 300/464, lr: 1e-08, loss: 4.51597\n",
      "cur_epoch: 2/800, cur_it: 301/464, lr: 1e-08, loss: 4.5185\n",
      "cur_epoch: 2/800, cur_it: 302/464, lr: 1e-08, loss: 4.51785\n",
      "cur_epoch: 2/800, cur_it: 303/464, lr: 1e-08, loss: 4.51544\n",
      "cur_epoch: 2/800, cur_it: 304/464, lr: 1e-08, loss: 4.51573\n",
      "cur_epoch: 2/800, cur_it: 305/464, lr: 1e-08, loss: 4.51542\n",
      "cur_epoch: 2/800, cur_it: 306/464, lr: 1e-08, loss: 4.51315\n",
      "cur_epoch: 2/800, cur_it: 307/464, lr: 1e-08, loss: 4.51368\n",
      "cur_epoch: 2/800, cur_it: 308/464, lr: 1e-08, loss: 4.5169\n",
      "cur_epoch: 2/800, cur_it: 309/464, lr: 1e-08, loss: 4.52093\n",
      "cur_epoch: 2/800, cur_it: 310/464, lr: 1e-08, loss: 4.65161\n",
      "cur_epoch: 2/800, cur_it: 311/464, lr: 1e-08, loss: 4.65115\n",
      "cur_epoch: 2/800, cur_it: 312/464, lr: 1e-08, loss: 4.64968\n",
      "cur_epoch: 2/800, cur_it: 313/464, lr: 1e-08, loss: 4.65325\n",
      "cur_epoch: 2/800, cur_it: 314/464, lr: 1e-08, loss: 4.65387\n",
      "cur_epoch: 2/800, cur_it: 315/464, lr: 1e-08, loss: 4.653\n",
      "cur_epoch: 2/800, cur_it: 316/464, lr: 1e-08, loss: 4.65183\n",
      "cur_epoch: 2/800, cur_it: 317/464, lr: 1e-08, loss: 4.64957\n",
      "cur_epoch: 2/800, cur_it: 318/464, lr: 1e-08, loss: 4.64664\n",
      "cur_epoch: 2/800, cur_it: 319/464, lr: 1e-08, loss: 4.64548\n",
      "cur_epoch: 2/800, cur_it: 320/464, lr: 1e-08, loss: 4.64255\n",
      "cur_epoch: 2/800, cur_it: 321/464, lr: 1e-08, loss: 4.64113\n",
      "cur_epoch: 2/800, cur_it: 322/464, lr: 1e-08, loss: 4.63943\n",
      "cur_epoch: 2/800, cur_it: 323/464, lr: 1e-08, loss: 4.6365\n",
      "cur_epoch: 2/800, cur_it: 324/464, lr: 1e-08, loss: 4.6352\n",
      "cur_epoch: 2/800, cur_it: 325/464, lr: 1e-08, loss: 4.6327\n",
      "cur_epoch: 2/800, cur_it: 326/464, lr: 1e-08, loss: 4.63185\n",
      "cur_epoch: 2/800, cur_it: 327/464, lr: 1e-08, loss: 4.62864\n",
      "cur_epoch: 2/800, cur_it: 328/464, lr: 1e-08, loss: 4.62825\n",
      "cur_epoch: 2/800, cur_it: 329/464, lr: 1e-08, loss: 4.62823\n",
      "cur_epoch: 2/800, cur_it: 330/464, lr: 1e-08, loss: 4.62955\n",
      "cur_epoch: 2/800, cur_it: 331/464, lr: 1e-08, loss: 4.62912\n",
      "cur_epoch: 2/800, cur_it: 332/464, lr: 1e-08, loss: 4.62725\n",
      "cur_epoch: 2/800, cur_it: 333/464, lr: 1e-08, loss: 4.62895\n",
      "cur_epoch: 2/800, cur_it: 334/464, lr: 1e-08, loss: 4.62819\n",
      "cur_epoch: 2/800, cur_it: 335/464, lr: 1e-08, loss: 4.63054\n",
      "cur_epoch: 2/800, cur_it: 336/464, lr: 1e-08, loss: 4.62785\n",
      "cur_epoch: 2/800, cur_it: 337/464, lr: 1e-08, loss: 4.62507\n",
      "cur_epoch: 2/800, cur_it: 338/464, lr: 1e-08, loss: 4.63608\n",
      "cur_epoch: 2/800, cur_it: 339/464, lr: 1e-08, loss: 4.63481\n",
      "cur_epoch: 2/800, cur_it: 340/464, lr: 1e-08, loss: 4.68095\n",
      "cur_epoch: 2/800, cur_it: 341/464, lr: 1e-08, loss: 4.68102\n",
      "cur_epoch: 2/800, cur_it: 342/464, lr: 1e-08, loss: 4.68447\n",
      "cur_epoch: 2/800, cur_it: 343/464, lr: 1e-08, loss: 4.6825\n",
      "cur_epoch: 2/800, cur_it: 344/464, lr: 1e-08, loss: 4.67977\n",
      "cur_epoch: 2/800, cur_it: 345/464, lr: 1e-08, loss: 4.6792\n",
      "cur_epoch: 2/800, cur_it: 346/464, lr: 1e-08, loss: 4.67867\n",
      "cur_epoch: 2/800, cur_it: 347/464, lr: 1e-08, loss: 4.67617\n",
      "cur_epoch: 2/800, cur_it: 348/464, lr: 1e-08, loss: 4.67296\n",
      "cur_epoch: 2/800, cur_it: 349/464, lr: 1e-08, loss: 4.67199\n",
      "cur_epoch: 2/800, cur_it: 350/464, lr: 1e-08, loss: 4.67161\n",
      "cur_epoch: 2/800, cur_it: 351/464, lr: 1e-08, loss: 4.67586\n",
      "cur_epoch: 2/800, cur_it: 352/464, lr: 1e-08, loss: 4.67305\n",
      "cur_epoch: 2/800, cur_it: 353/464, lr: 1e-08, loss: 4.6709\n",
      "cur_epoch: 2/800, cur_it: 354/464, lr: 1e-08, loss: 4.67128\n",
      "cur_epoch: 2/800, cur_it: 355/464, lr: 1e-08, loss: 4.67015\n",
      "cur_epoch: 2/800, cur_it: 356/464, lr: 1e-08, loss: 4.66759\n",
      "cur_epoch: 2/800, cur_it: 357/464, lr: 1e-08, loss: 4.66761\n",
      "cur_epoch: 2/800, cur_it: 358/464, lr: 1e-08, loss: 4.66684\n",
      "cur_epoch: 2/800, cur_it: 359/464, lr: 1e-08, loss: 4.66669\n",
      "cur_epoch: 2/800, cur_it: 360/464, lr: 1e-08, loss: 4.66598\n",
      "cur_epoch: 2/800, cur_it: 361/464, lr: 1e-08, loss: 4.66431\n",
      "cur_epoch: 2/800, cur_it: 362/464, lr: 1e-08, loss: 4.66235\n",
      "cur_epoch: 2/800, cur_it: 363/464, lr: 1e-08, loss: 4.66414\n",
      "cur_epoch: 2/800, cur_it: 364/464, lr: 1e-08, loss: 4.66355\n",
      "cur_epoch: 2/800, cur_it: 365/464, lr: 1e-08, loss: 4.66446\n",
      "cur_epoch: 2/800, cur_it: 366/464, lr: 1e-08, loss: 4.66382\n",
      "cur_epoch: 2/800, cur_it: 367/464, lr: 1e-08, loss: 4.66226\n",
      "cur_epoch: 2/800, cur_it: 368/464, lr: 1e-08, loss: 4.66\n",
      "cur_epoch: 2/800, cur_it: 369/464, lr: 1e-08, loss: 4.66008\n",
      "cur_epoch: 2/800, cur_it: 370/464, lr: 1e-08, loss: 4.65807\n",
      "cur_epoch: 2/800, cur_it: 371/464, lr: 1e-08, loss: 4.6575\n",
      "cur_epoch: 2/800, cur_it: 372/464, lr: 1e-08, loss: 4.65588\n",
      "cur_epoch: 2/800, cur_it: 373/464, lr: 1e-08, loss: 4.65343\n",
      "cur_epoch: 2/800, cur_it: 374/464, lr: 1e-08, loss: 4.65483\n",
      "cur_epoch: 2/800, cur_it: 375/464, lr: 1e-08, loss: 4.65424\n",
      "cur_epoch: 2/800, cur_it: 376/464, lr: 1e-08, loss: 4.65391\n",
      "cur_epoch: 2/800, cur_it: 377/464, lr: 1e-08, loss: 4.65131\n",
      "cur_epoch: 2/800, cur_it: 378/464, lr: 1e-08, loss: 4.65004\n",
      "cur_epoch: 2/800, cur_it: 379/464, lr: 1e-08, loss: 4.64809\n",
      "cur_epoch: 2/800, cur_it: 380/464, lr: 1e-08, loss: 4.64989\n",
      "cur_epoch: 2/800, cur_it: 381/464, lr: 1e-08, loss: 4.64853\n",
      "cur_epoch: 2/800, cur_it: 382/464, lr: 1e-08, loss: 4.64654\n",
      "cur_epoch: 2/800, cur_it: 383/464, lr: 1e-08, loss: 4.64712\n",
      "cur_epoch: 2/800, cur_it: 384/464, lr: 1e-08, loss: 4.64533\n",
      "cur_epoch: 2/800, cur_it: 385/464, lr: 1e-08, loss: 4.64379\n",
      "cur_epoch: 2/800, cur_it: 386/464, lr: 1e-08, loss: 4.64233\n",
      "cur_epoch: 2/800, cur_it: 387/464, lr: 1e-08, loss: 4.64017\n",
      "cur_epoch: 2/800, cur_it: 388/464, lr: 1e-08, loss: 4.63896\n",
      "cur_epoch: 2/800, cur_it: 389/464, lr: 1e-08, loss: 4.64182\n",
      "cur_epoch: 2/800, cur_it: 390/464, lr: 1e-08, loss: 4.63938\n",
      "cur_epoch: 2/800, cur_it: 391/464, lr: 1e-08, loss: 4.66535\n",
      "cur_epoch: 2/800, cur_it: 392/464, lr: 1e-08, loss: 4.66535\n",
      "cur_epoch: 2/800, cur_it: 393/464, lr: 1e-08, loss: 4.66623\n",
      "cur_epoch: 2/800, cur_it: 394/464, lr: 1e-08, loss: 4.66466\n",
      "cur_epoch: 2/800, cur_it: 395/464, lr: 1e-08, loss: 4.66254\n",
      "cur_epoch: 2/800, cur_it: 396/464, lr: 1e-08, loss: 4.66133\n",
      "cur_epoch: 2/800, cur_it: 397/464, lr: 1e-08, loss: 4.6612\n",
      "cur_epoch: 2/800, cur_it: 398/464, lr: 1e-08, loss: 4.6603\n",
      "cur_epoch: 2/800, cur_it: 399/464, lr: 1e-08, loss: 4.65793\n",
      "cur_epoch: 2/800, cur_it: 400/464, lr: 1e-08, loss: 4.65747\n",
      "cur_epoch: 2/800, cur_it: 401/464, lr: 1e-08, loss: 4.65805\n",
      "cur_epoch: 2/800, cur_it: 402/464, lr: 1e-08, loss: 4.65687\n",
      "cur_epoch: 2/800, cur_it: 403/464, lr: 1e-08, loss: 4.65522\n",
      "cur_epoch: 2/800, cur_it: 404/464, lr: 1e-08, loss: 4.65427\n",
      "cur_epoch: 2/800, cur_it: 405/464, lr: 1e-08, loss: 4.65651\n",
      "cur_epoch: 2/800, cur_it: 406/464, lr: 1e-08, loss: 4.65494\n",
      "cur_epoch: 2/800, cur_it: 407/464, lr: 1e-08, loss: 4.65407\n",
      "cur_epoch: 2/800, cur_it: 408/464, lr: 1e-08, loss: 4.65378\n",
      "cur_epoch: 2/800, cur_it: 409/464, lr: 1e-08, loss: 4.65189\n",
      "cur_epoch: 2/800, cur_it: 410/464, lr: 1e-08, loss: 4.64961\n",
      "cur_epoch: 2/800, cur_it: 411/464, lr: 1e-08, loss: 4.65206\n",
      "cur_epoch: 2/800, cur_it: 412/464, lr: 1e-08, loss: 4.65105\n",
      "cur_epoch: 2/800, cur_it: 413/464, lr: 1e-08, loss: 4.64848\n",
      "cur_epoch: 2/800, cur_it: 414/464, lr: 1e-08, loss: 4.64876\n",
      "cur_epoch: 2/800, cur_it: 415/464, lr: 1e-08, loss: 4.64977\n",
      "cur_epoch: 2/800, cur_it: 416/464, lr: 1e-08, loss: 4.66069\n",
      "cur_epoch: 2/800, cur_it: 417/464, lr: 1e-08, loss: 4.66\n",
      "cur_epoch: 2/800, cur_it: 418/464, lr: 1e-08, loss: 4.6602\n",
      "cur_epoch: 2/800, cur_it: 419/464, lr: 1e-08, loss: 4.65882\n",
      "cur_epoch: 2/800, cur_it: 420/464, lr: 1e-08, loss: 4.65845\n",
      "cur_epoch: 2/800, cur_it: 421/464, lr: 1e-08, loss: 4.65845\n",
      "cur_epoch: 2/800, cur_it: 422/464, lr: 1e-08, loss: 4.65739\n",
      "cur_epoch: 2/800, cur_it: 423/464, lr: 1e-08, loss: 4.65506\n",
      "cur_epoch: 2/800, cur_it: 424/464, lr: 1e-08, loss: 4.6539\n",
      "cur_epoch: 2/800, cur_it: 425/464, lr: 1e-08, loss: 4.65262\n",
      "cur_epoch: 2/800, cur_it: 426/464, lr: 1e-08, loss: 4.65724\n",
      "cur_epoch: 2/800, cur_it: 427/464, lr: 1e-08, loss: 4.65539\n",
      "cur_epoch: 2/800, cur_it: 428/464, lr: 1e-08, loss: 4.65403\n",
      "cur_epoch: 2/800, cur_it: 429/464, lr: 1e-08, loss: 4.65583\n",
      "cur_epoch: 2/800, cur_it: 430/464, lr: 1e-08, loss: 4.65473\n",
      "cur_epoch: 2/800, cur_it: 431/464, lr: 1e-08, loss: 4.65622\n",
      "cur_epoch: 2/800, cur_it: 432/464, lr: 1e-08, loss: 4.65814\n",
      "cur_epoch: 2/800, cur_it: 433/464, lr: 1e-08, loss: 4.65686\n",
      "cur_epoch: 2/800, cur_it: 434/464, lr: 1e-08, loss: 4.65508\n",
      "cur_epoch: 2/800, cur_it: 435/464, lr: 1e-08, loss: 4.65373\n",
      "cur_epoch: 2/800, cur_it: 436/464, lr: 1e-08, loss: 4.65265\n",
      "cur_epoch: 2/800, cur_it: 437/464, lr: 1e-08, loss: 4.65153\n",
      "cur_epoch: 2/800, cur_it: 438/464, lr: 1e-08, loss: 4.65143\n",
      "cur_epoch: 2/800, cur_it: 439/464, lr: 1e-08, loss: 4.65138\n",
      "cur_epoch: 2/800, cur_it: 440/464, lr: 1e-08, loss: 4.6496\n",
      "cur_epoch: 2/800, cur_it: 441/464, lr: 1e-08, loss: 4.64813\n",
      "cur_epoch: 2/800, cur_it: 442/464, lr: 1e-08, loss: 4.64753\n",
      "cur_epoch: 2/800, cur_it: 443/464, lr: 1e-08, loss: 4.64724\n",
      "cur_epoch: 2/800, cur_it: 444/464, lr: 1e-08, loss: 4.64636\n",
      "cur_epoch: 2/800, cur_it: 445/464, lr: 1e-08, loss: 4.64426\n",
      "cur_epoch: 2/800, cur_it: 446/464, lr: 1e-08, loss: 4.64351\n",
      "cur_epoch: 2/800, cur_it: 447/464, lr: 1e-08, loss: 4.64278\n",
      "cur_epoch: 2/800, cur_it: 448/464, lr: 1e-08, loss: 4.64132\n",
      "cur_epoch: 2/800, cur_it: 449/464, lr: 1e-08, loss: 4.64119\n",
      "cur_epoch: 2/800, cur_it: 450/464, lr: 1e-08, loss: 4.64023\n",
      "cur_epoch: 2/800, cur_it: 451/464, lr: 1e-08, loss: 4.63879\n",
      "cur_epoch: 2/800, cur_it: 452/464, lr: 1e-08, loss: 4.63702\n",
      "cur_epoch: 2/800, cur_it: 453/464, lr: 1e-08, loss: 4.63791\n",
      "cur_epoch: 2/800, cur_it: 454/464, lr: 1e-08, loss: 4.63928\n",
      "cur_epoch: 2/800, cur_it: 455/464, lr: 1e-08, loss: 4.63821\n",
      "cur_epoch: 2/800, cur_it: 456/464, lr: 1e-08, loss: 4.63784\n",
      "cur_epoch: 2/800, cur_it: 457/464, lr: 1e-08, loss: 4.63729\n",
      "cur_epoch: 2/800, cur_it: 458/464, lr: 1e-08, loss: 4.63913\n",
      "cur_epoch: 2/800, cur_it: 459/464, lr: 1e-08, loss: 4.64192\n",
      "cur_epoch: 2/800, cur_it: 460/464, lr: 1e-08, loss: 4.64282\n",
      "cur_epoch: 2/800, cur_it: 461/464, lr: 1e-08, loss: 4.64163\n",
      "cur_epoch: 2/800, cur_it: 462/464, lr: 1e-08, loss: 4.64197\n",
      "cur_epoch: 2/800, cur_it: 463/464, lr: 1e-08, loss: 4.64055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 00:10:05,674   INFO  **********************Start testing**********************\n",
      "2023-07-23 00:10:05,676   INFO  Loading KITTI dataset\n",
      "2023-07-23 00:10:05,773   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_epoch: 2/800, cur_it: 464/464, lr: 1e-08, loss: 4.63953\n",
      "Average predicted number of objects(3769 samples): 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/800 [17:52<118:39:55, 535.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 {'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_3d/easy_R40': 0.0, 'Car_3d/moderate_R40': 0.0, 'Car_3d/hard_R40': 0.0, 'Car_bev/easy_R40': 0.0, 'Car_bev/moderate_R40': 0.0, 'Car_bev/hard_R40': 0.0, 'Car_image/easy_R40': 0.0, 'Car_image/moderate_R40': 0.0, 'Car_image/hard_R40': 0.0, 'Pedestrian_3d/easy_R40': 0.0, 'Pedestrian_3d/moderate_R40': 0.0, 'Pedestrian_3d/hard_R40': 0.0, 'Pedestrian_bev/easy_R40': 0.0, 'Pedestrian_bev/moderate_R40': 0.0, 'Pedestrian_bev/hard_R40': 0.0, 'Pedestrian_image/easy_R40': 0.0, 'Pedestrian_image/moderate_R40': 0.0, 'Pedestrian_image/hard_R40': 0.0, 'Cyclist_3d/easy_R40': 0.0, 'Cyclist_3d/moderate_R40': 0.0, 'Cyclist_3d/hard_R40': 0.0, 'Cyclist_bev/easy_R40': 0.0, 'Cyclist_bev/moderate_R40': 0.0, 'Cyclist_bev/hard_R40': 0.0, 'Cyclist_image/easy_R40': 0.0, 'Cyclist_image/moderate_R40': 0.0, 'Cyclist_image/hard_R40': 0.0}\n",
      "cur_epoch: 3/800, cur_it: 1/464, lr: 1e-08, loss: 3.98731\n",
      "cur_epoch: 3/800, cur_it: 2/464, lr: 1e-08, loss: 4.16373\n",
      "cur_epoch: 3/800, cur_it: 3/464, lr: 1e-08, loss: 4.21043\n",
      "cur_epoch: 3/800, cur_it: 4/464, lr: 1e-08, loss: 4.17014\n",
      "cur_epoch: 3/800, cur_it: 5/464, lr: 1e-08, loss: 4.50997\n",
      "cur_epoch: 3/800, cur_it: 6/464, lr: 1e-08, loss: 4.46653\n",
      "cur_epoch: 3/800, cur_it: 7/464, lr: 1e-08, loss: 4.42552\n",
      "cur_epoch: 3/800, cur_it: 8/464, lr: 1e-08, loss: 4.44597\n",
      "cur_epoch: 3/800, cur_it: 9/464, lr: 1e-08, loss: 4.44211\n",
      "cur_epoch: 3/800, cur_it: 10/464, lr: 1e-08, loss: 4.83435\n",
      "cur_epoch: 3/800, cur_it: 11/464, lr: 1e-08, loss: 4.76999\n",
      "cur_epoch: 3/800, cur_it: 12/464, lr: 1e-08, loss: 4.69484\n",
      "cur_epoch: 3/800, cur_it: 13/464, lr: 1e-08, loss: 4.65385\n",
      "cur_epoch: 3/800, cur_it: 14/464, lr: 1e-08, loss: 4.62414\n",
      "cur_epoch: 3/800, cur_it: 15/464, lr: 1e-08, loss: 4.59128\n",
      "cur_epoch: 3/800, cur_it: 16/464, lr: 1e-08, loss: 4.59561\n",
      "cur_epoch: 3/800, cur_it: 17/464, lr: 1e-08, loss: 4.56553\n",
      "cur_epoch: 3/800, cur_it: 18/464, lr: 1e-08, loss: 4.50709\n",
      "cur_epoch: 3/800, cur_it: 19/464, lr: 1e-08, loss: 4.51952\n",
      "cur_epoch: 3/800, cur_it: 20/464, lr: 1e-08, loss: 4.4851\n",
      "cur_epoch: 3/800, cur_it: 21/464, lr: 1e-08, loss: 4.47905\n",
      "cur_epoch: 3/800, cur_it: 22/464, lr: 1e-08, loss: 4.48165\n",
      "cur_epoch: 3/800, cur_it: 23/464, lr: 1e-08, loss: 4.5046\n",
      "cur_epoch: 3/800, cur_it: 24/464, lr: 1e-08, loss: 4.46992\n",
      "cur_epoch: 3/800, cur_it: 25/464, lr: 1e-08, loss: 4.4514\n",
      "cur_epoch: 3/800, cur_it: 26/464, lr: 1e-08, loss: 4.44687\n",
      "cur_epoch: 3/800, cur_it: 27/464, lr: 1e-08, loss: 4.41115\n",
      "cur_epoch: 3/800, cur_it: 28/464, lr: 1e-08, loss: 4.47846\n",
      "cur_epoch: 3/800, cur_it: 29/464, lr: 1e-08, loss: 4.45484\n",
      "cur_epoch: 3/800, cur_it: 30/464, lr: 1e-08, loss: 4.44691\n",
      "cur_epoch: 3/800, cur_it: 31/464, lr: 1e-08, loss: 4.42566\n",
      "cur_epoch: 3/800, cur_it: 32/464, lr: 1e-08, loss: 4.40209\n",
      "cur_epoch: 3/800, cur_it: 33/464, lr: 1e-08, loss: 4.39304\n",
      "cur_epoch: 3/800, cur_it: 34/464, lr: 1e-08, loss: 4.44791\n",
      "cur_epoch: 3/800, cur_it: 35/464, lr: 1e-08, loss: 4.49293\n",
      "cur_epoch: 3/800, cur_it: 36/464, lr: 1e-08, loss: 4.49972\n",
      "cur_epoch: 3/800, cur_it: 37/464, lr: 1e-08, loss: 4.47969\n",
      "cur_epoch: 3/800, cur_it: 38/464, lr: 1e-08, loss: 4.58367\n",
      "cur_epoch: 3/800, cur_it: 39/464, lr: 1e-08, loss: 4.57927\n",
      "cur_epoch: 3/800, cur_it: 40/464, lr: 1e-08, loss: 4.57992\n",
      "cur_epoch: 3/800, cur_it: 41/464, lr: 1e-08, loss: 4.56613\n",
      "cur_epoch: 3/800, cur_it: 42/464, lr: 1e-08, loss: 4.55131\n",
      "cur_epoch: 3/800, cur_it: 43/464, lr: 1e-08, loss: 4.54407\n",
      "cur_epoch: 3/800, cur_it: 44/464, lr: 1e-08, loss: 4.52624\n",
      "cur_epoch: 3/800, cur_it: 45/464, lr: 1e-08, loss: 4.52213\n",
      "cur_epoch: 3/800, cur_it: 46/464, lr: 1e-08, loss: 4.51078\n",
      "cur_epoch: 3/800, cur_it: 47/464, lr: 1e-08, loss: 4.51431\n",
      "cur_epoch: 3/800, cur_it: 48/464, lr: 1e-08, loss: 4.54047\n",
      "cur_epoch: 3/800, cur_it: 49/464, lr: 1e-08, loss: 4.53742\n",
      "cur_epoch: 3/800, cur_it: 50/464, lr: 1e-08, loss: 4.54667\n",
      "cur_epoch: 3/800, cur_it: 51/464, lr: 1e-08, loss: 4.92567\n",
      "cur_epoch: 3/800, cur_it: 52/464, lr: 1e-08, loss: 4.91401\n",
      "cur_epoch: 3/800, cur_it: 53/464, lr: 1e-08, loss: 4.91471\n",
      "cur_epoch: 3/800, cur_it: 54/464, lr: 1e-08, loss: 4.90107\n",
      "cur_epoch: 3/800, cur_it: 55/464, lr: 1e-08, loss: 4.89116\n",
      "cur_epoch: 3/800, cur_it: 56/464, lr: 1e-08, loss: 4.87718\n",
      "cur_epoch: 3/800, cur_it: 57/464, lr: 1e-08, loss: 4.86176\n",
      "cur_epoch: 3/800, cur_it: 58/464, lr: 1e-08, loss: 4.85041\n",
      "cur_epoch: 3/800, cur_it: 59/464, lr: 1e-08, loss: 4.84926\n",
      "cur_epoch: 3/800, cur_it: 60/464, lr: 1e-08, loss: 4.84848\n",
      "cur_epoch: 3/800, cur_it: 61/464, lr: 1e-08, loss: 4.84399\n",
      "cur_epoch: 3/800, cur_it: 62/464, lr: 1e-08, loss: 4.82938\n",
      "cur_epoch: 3/800, cur_it: 63/464, lr: 1e-08, loss: 4.81861\n",
      "cur_epoch: 3/800, cur_it: 64/464, lr: 1e-08, loss: 4.93097\n",
      "cur_epoch: 3/800, cur_it: 65/464, lr: 1e-08, loss: 4.92253\n",
      "cur_epoch: 3/800, cur_it: 66/464, lr: 1e-08, loss: 4.92138\n",
      "cur_epoch: 3/800, cur_it: 67/464, lr: 1e-08, loss: 4.90841\n",
      "cur_epoch: 3/800, cur_it: 68/464, lr: 1e-08, loss: 4.89742\n",
      "cur_epoch: 3/800, cur_it: 69/464, lr: 1e-08, loss: 4.88726\n",
      "cur_epoch: 3/800, cur_it: 70/464, lr: 1e-08, loss: 4.86965\n",
      "cur_epoch: 3/800, cur_it: 71/464, lr: 1e-08, loss: 4.85967\n",
      "cur_epoch: 3/800, cur_it: 72/464, lr: 1e-08, loss: 4.85814\n",
      "cur_epoch: 3/800, cur_it: 73/464, lr: 1e-08, loss: 4.84603\n",
      "cur_epoch: 3/800, cur_it: 74/464, lr: 1e-08, loss: 4.83575\n",
      "cur_epoch: 3/800, cur_it: 75/464, lr: 1e-08, loss: 4.841\n",
      "cur_epoch: 3/800, cur_it: 76/464, lr: 1e-08, loss: 4.8266\n",
      "cur_epoch: 3/800, cur_it: 77/464, lr: 1e-08, loss: 4.81442\n",
      "cur_epoch: 3/800, cur_it: 78/464, lr: 1e-08, loss: 4.80497\n",
      "cur_epoch: 3/800, cur_it: 79/464, lr: 1e-08, loss: 4.79502\n",
      "cur_epoch: 3/800, cur_it: 80/464, lr: 1e-08, loss: 4.78912\n",
      "cur_epoch: 3/800, cur_it: 81/464, lr: 1e-08, loss: 4.79012\n",
      "cur_epoch: 3/800, cur_it: 82/464, lr: 1e-08, loss: 4.78234\n",
      "cur_epoch: 3/800, cur_it: 83/464, lr: 1e-08, loss: 4.7782\n",
      "cur_epoch: 3/800, cur_it: 84/464, lr: 1e-08, loss: 4.76449\n",
      "cur_epoch: 3/800, cur_it: 85/464, lr: 1e-08, loss: 4.76924\n",
      "cur_epoch: 3/800, cur_it: 86/464, lr: 1e-08, loss: 4.76003\n",
      "cur_epoch: 3/800, cur_it: 87/464, lr: 1e-08, loss: 4.75806\n",
      "cur_epoch: 3/800, cur_it: 88/464, lr: 1e-08, loss: 4.75293\n",
      "cur_epoch: 3/800, cur_it: 89/464, lr: 1e-08, loss: 4.74115\n",
      "cur_epoch: 3/800, cur_it: 90/464, lr: 1e-08, loss: 4.72932\n",
      "cur_epoch: 3/800, cur_it: 91/464, lr: 1e-08, loss: 4.72065\n",
      "cur_epoch: 3/800, cur_it: 92/464, lr: 1e-08, loss: 4.71386\n",
      "cur_epoch: 3/800, cur_it: 93/464, lr: 1e-08, loss: 4.70443\n",
      "cur_epoch: 3/800, cur_it: 94/464, lr: 1e-08, loss: 4.69779\n",
      "cur_epoch: 3/800, cur_it: 95/464, lr: 1e-08, loss: 4.70307\n",
      "cur_epoch: 3/800, cur_it: 96/464, lr: 1e-08, loss: 4.69537\n",
      "cur_epoch: 3/800, cur_it: 97/464, lr: 1e-08, loss: 4.68772\n",
      "cur_epoch: 3/800, cur_it: 98/464, lr: 1e-08, loss: 4.68638\n",
      "cur_epoch: 3/800, cur_it: 99/464, lr: 1e-08, loss: 4.69875\n",
      "cur_epoch: 3/800, cur_it: 100/464, lr: 1e-08, loss: 4.69142\n",
      "cur_epoch: 3/800, cur_it: 101/464, lr: 1e-08, loss: 4.69011\n",
      "cur_epoch: 3/800, cur_it: 102/464, lr: 1e-08, loss: 4.68863\n",
      "cur_epoch: 3/800, cur_it: 103/464, lr: 1e-08, loss: 4.68472\n",
      "cur_epoch: 3/800, cur_it: 104/464, lr: 1e-08, loss: 4.68086\n",
      "cur_epoch: 3/800, cur_it: 105/464, lr: 1e-08, loss: 4.67252\n",
      "cur_epoch: 3/800, cur_it: 106/464, lr: 1e-08, loss: 4.66484\n",
      "cur_epoch: 3/800, cur_it: 107/464, lr: 1e-08, loss: 4.82422\n",
      "cur_epoch: 3/800, cur_it: 108/464, lr: 1e-08, loss: 4.8171\n",
      "cur_epoch: 3/800, cur_it: 109/464, lr: 1e-08, loss: 4.81242\n",
      "cur_epoch: 3/800, cur_it: 110/464, lr: 1e-08, loss: 4.80459\n",
      "cur_epoch: 3/800, cur_it: 111/464, lr: 1e-08, loss: 4.80109\n",
      "cur_epoch: 3/800, cur_it: 112/464, lr: 1e-08, loss: 4.80768\n",
      "cur_epoch: 3/800, cur_it: 113/464, lr: 1e-08, loss: 4.80529\n",
      "cur_epoch: 3/800, cur_it: 114/464, lr: 1e-08, loss: 4.79829\n",
      "cur_epoch: 3/800, cur_it: 115/464, lr: 1e-08, loss: 4.791\n",
      "cur_epoch: 3/800, cur_it: 116/464, lr: 1e-08, loss: 4.78415\n",
      "cur_epoch: 3/800, cur_it: 117/464, lr: 1e-08, loss: 4.77634\n",
      "cur_epoch: 3/800, cur_it: 118/464, lr: 1e-08, loss: 4.76974\n",
      "cur_epoch: 3/800, cur_it: 119/464, lr: 1e-08, loss: 4.76862\n",
      "cur_epoch: 3/800, cur_it: 120/464, lr: 1e-08, loss: 4.76475\n",
      "cur_epoch: 3/800, cur_it: 121/464, lr: 1e-08, loss: 4.75599\n",
      "cur_epoch: 3/800, cur_it: 122/464, lr: 1e-08, loss: 4.75583\n",
      "cur_epoch: 3/800, cur_it: 123/464, lr: 1e-08, loss: 4.74404\n",
      "cur_epoch: 3/800, cur_it: 124/464, lr: 1e-08, loss: 4.73883\n",
      "cur_epoch: 3/800, cur_it: 125/464, lr: 1e-08, loss: 4.73462\n",
      "cur_epoch: 3/800, cur_it: 126/464, lr: 1e-08, loss: 4.73781\n",
      "cur_epoch: 3/800, cur_it: 127/464, lr: 1e-08, loss: 4.73176\n",
      "cur_epoch: 3/800, cur_it: 128/464, lr: 1e-08, loss: 4.73382\n",
      "cur_epoch: 3/800, cur_it: 129/464, lr: 1e-08, loss: 4.72607\n",
      "cur_epoch: 3/800, cur_it: 130/464, lr: 1e-08, loss: 4.72119\n",
      "cur_epoch: 3/800, cur_it: 131/464, lr: 1e-08, loss: 4.7176\n",
      "cur_epoch: 3/800, cur_it: 132/464, lr: 1e-08, loss: 4.71098\n",
      "cur_epoch: 3/800, cur_it: 133/464, lr: 1e-08, loss: 4.70467\n",
      "cur_epoch: 3/800, cur_it: 134/464, lr: 1e-08, loss: 4.69961\n",
      "cur_epoch: 3/800, cur_it: 135/464, lr: 1e-08, loss: 4.69521\n",
      "cur_epoch: 3/800, cur_it: 136/464, lr: 1e-08, loss: 4.69288\n",
      "cur_epoch: 3/800, cur_it: 137/464, lr: 1e-08, loss: 4.68861\n",
      "cur_epoch: 3/800, cur_it: 138/464, lr: 1e-08, loss: 4.68613\n",
      "cur_epoch: 3/800, cur_it: 139/464, lr: 1e-08, loss: 4.68205\n",
      "cur_epoch: 3/800, cur_it: 140/464, lr: 1e-08, loss: 4.68556\n",
      "cur_epoch: 3/800, cur_it: 141/464, lr: 1e-08, loss: 4.67952\n",
      "cur_epoch: 3/800, cur_it: 142/464, lr: 1e-08, loss: 4.67701\n",
      "cur_epoch: 3/800, cur_it: 143/464, lr: 1e-08, loss: 4.67364\n",
      "cur_epoch: 3/800, cur_it: 144/464, lr: 1e-08, loss: 4.66766\n",
      "cur_epoch: 3/800, cur_it: 145/464, lr: 1e-08, loss: 4.67809\n",
      "cur_epoch: 3/800, cur_it: 146/464, lr: 1e-08, loss: 4.67413\n",
      "cur_epoch: 3/800, cur_it: 147/464, lr: 1e-08, loss: 4.67025\n",
      "cur_epoch: 3/800, cur_it: 148/464, lr: 1e-08, loss: 4.66404\n",
      "cur_epoch: 3/800, cur_it: 149/464, lr: 1e-08, loss: 4.65918\n",
      "cur_epoch: 3/800, cur_it: 150/464, lr: 1e-08, loss: 4.65474\n",
      "cur_epoch: 3/800, cur_it: 151/464, lr: 1e-08, loss: 4.64963\n",
      "cur_epoch: 3/800, cur_it: 152/464, lr: 1e-08, loss: 4.65278\n",
      "cur_epoch: 3/800, cur_it: 153/464, lr: 1e-08, loss: 4.65271\n",
      "cur_epoch: 3/800, cur_it: 154/464, lr: 1e-08, loss: 4.65198\n",
      "cur_epoch: 3/800, cur_it: 155/464, lr: 1e-08, loss: 4.65179\n",
      "cur_epoch: 3/800, cur_it: 156/464, lr: 1e-08, loss: 4.64829\n",
      "cur_epoch: 3/800, cur_it: 157/464, lr: 1e-08, loss: 4.64161\n",
      "cur_epoch: 3/800, cur_it: 158/464, lr: 1e-08, loss: 4.63986\n",
      "cur_epoch: 3/800, cur_it: 159/464, lr: 1e-08, loss: 4.63684\n",
      "cur_epoch: 3/800, cur_it: 160/464, lr: 1e-08, loss: 4.64027\n",
      "cur_epoch: 3/800, cur_it: 161/464, lr: 1e-08, loss: 4.63681\n",
      "cur_epoch: 3/800, cur_it: 162/464, lr: 1e-08, loss: 4.63362\n",
      "cur_epoch: 3/800, cur_it: 163/464, lr: 1e-08, loss: 4.63231\n",
      "cur_epoch: 3/800, cur_it: 164/464, lr: 1e-08, loss: 4.62719\n",
      "cur_epoch: 3/800, cur_it: 165/464, lr: 1e-08, loss: 4.6215\n",
      "cur_epoch: 3/800, cur_it: 166/464, lr: 1e-08, loss: 4.61834\n",
      "cur_epoch: 3/800, cur_it: 167/464, lr: 1e-08, loss: 4.61543\n",
      "cur_epoch: 3/800, cur_it: 168/464, lr: 1e-08, loss: 4.60817\n",
      "cur_epoch: 3/800, cur_it: 169/464, lr: 1e-08, loss: 4.60716\n",
      "cur_epoch: 3/800, cur_it: 170/464, lr: 1e-08, loss: 4.60303\n",
      "cur_epoch: 3/800, cur_it: 171/464, lr: 1e-08, loss: 4.60087\n",
      "cur_epoch: 3/800, cur_it: 172/464, lr: 1e-08, loss: 4.59539\n",
      "cur_epoch: 3/800, cur_it: 173/464, lr: 1e-08, loss: 4.59235\n",
      "cur_epoch: 3/800, cur_it: 174/464, lr: 1e-08, loss: 4.58757\n",
      "cur_epoch: 3/800, cur_it: 175/464, lr: 1e-08, loss: 4.58321\n",
      "cur_epoch: 3/800, cur_it: 176/464, lr: 1e-08, loss: 4.58124\n",
      "cur_epoch: 3/800, cur_it: 177/464, lr: 1e-08, loss: 4.57849\n",
      "cur_epoch: 3/800, cur_it: 178/464, lr: 1e-08, loss: 4.57833\n",
      "cur_epoch: 3/800, cur_it: 179/464, lr: 1e-08, loss: 4.5784\n",
      "cur_epoch: 3/800, cur_it: 180/464, lr: 1e-08, loss: 4.60626\n",
      "cur_epoch: 3/800, cur_it: 181/464, lr: 1e-08, loss: 4.60351\n",
      "cur_epoch: 3/800, cur_it: 182/464, lr: 1e-08, loss: 4.6035\n",
      "cur_epoch: 3/800, cur_it: 183/464, lr: 1e-08, loss: 4.60106\n",
      "cur_epoch: 3/800, cur_it: 184/464, lr: 1e-08, loss: 4.59731\n",
      "cur_epoch: 3/800, cur_it: 185/464, lr: 1e-08, loss: 4.59463\n",
      "cur_epoch: 3/800, cur_it: 186/464, lr: 1e-08, loss: 4.59259\n",
      "cur_epoch: 3/800, cur_it: 187/464, lr: 1e-08, loss: 4.58986\n",
      "cur_epoch: 3/800, cur_it: 188/464, lr: 1e-08, loss: 4.58639\n",
      "cur_epoch: 3/800, cur_it: 189/464, lr: 1e-08, loss: 4.58502\n",
      "cur_epoch: 3/800, cur_it: 190/464, lr: 1e-08, loss: 4.5846\n",
      "cur_epoch: 3/800, cur_it: 191/464, lr: 1e-08, loss: 4.57772\n",
      "cur_epoch: 3/800, cur_it: 192/464, lr: 1e-08, loss: 4.57465\n",
      "cur_epoch: 3/800, cur_it: 193/464, lr: 1e-08, loss: 4.57125\n",
      "cur_epoch: 3/800, cur_it: 194/464, lr: 1e-08, loss: 4.56737\n",
      "cur_epoch: 3/800, cur_it: 195/464, lr: 1e-08, loss: 4.56551\n",
      "cur_epoch: 3/800, cur_it: 196/464, lr: 1e-08, loss: 4.5624\n",
      "cur_epoch: 3/800, cur_it: 197/464, lr: 1e-08, loss: 4.56161\n",
      "cur_epoch: 3/800, cur_it: 198/464, lr: 1e-08, loss: 4.55663\n",
      "cur_epoch: 3/800, cur_it: 199/464, lr: 1e-08, loss: 4.56276\n",
      "cur_epoch: 3/800, cur_it: 200/464, lr: 1e-08, loss: 4.55922\n",
      "cur_epoch: 3/800, cur_it: 201/464, lr: 1e-08, loss: 4.55572\n",
      "cur_epoch: 3/800, cur_it: 202/464, lr: 1e-08, loss: 4.55246\n",
      "cur_epoch: 3/800, cur_it: 203/464, lr: 1e-08, loss: 4.55077\n",
      "cur_epoch: 3/800, cur_it: 204/464, lr: 1e-08, loss: 4.54949\n",
      "cur_epoch: 3/800, cur_it: 205/464, lr: 1e-08, loss: 4.54685\n",
      "cur_epoch: 3/800, cur_it: 206/464, lr: 1e-08, loss: 4.55562\n",
      "cur_epoch: 3/800, cur_it: 207/464, lr: 1e-08, loss: 4.5527\n",
      "cur_epoch: 3/800, cur_it: 208/464, lr: 1e-08, loss: 4.54883\n",
      "cur_epoch: 3/800, cur_it: 209/464, lr: 1e-08, loss: 4.56483\n",
      "cur_epoch: 3/800, cur_it: 210/464, lr: 1e-08, loss: 4.56116\n",
      "cur_epoch: 3/800, cur_it: 211/464, lr: 1e-08, loss: 4.55954\n",
      "cur_epoch: 3/800, cur_it: 212/464, lr: 1e-08, loss: 4.55827\n",
      "cur_epoch: 3/800, cur_it: 213/464, lr: 1e-08, loss: 4.55477\n",
      "cur_epoch: 3/800, cur_it: 214/464, lr: 1e-08, loss: 4.55805\n",
      "cur_epoch: 3/800, cur_it: 215/464, lr: 1e-08, loss: 4.55661\n",
      "cur_epoch: 3/800, cur_it: 216/464, lr: 1e-08, loss: 4.55751\n",
      "cur_epoch: 3/800, cur_it: 217/464, lr: 1e-08, loss: 4.55827\n",
      "cur_epoch: 3/800, cur_it: 218/464, lr: 1e-08, loss: 4.55612\n",
      "cur_epoch: 3/800, cur_it: 219/464, lr: 1e-08, loss: 4.55414\n",
      "cur_epoch: 3/800, cur_it: 220/464, lr: 1e-08, loss: 4.55348\n",
      "cur_epoch: 3/800, cur_it: 221/464, lr: 1e-08, loss: 4.55171\n",
      "cur_epoch: 3/800, cur_it: 222/464, lr: 1e-08, loss: 4.55199\n",
      "cur_epoch: 3/800, cur_it: 223/464, lr: 1e-08, loss: 4.54815\n",
      "cur_epoch: 3/800, cur_it: 224/464, lr: 1e-08, loss: 4.54742\n",
      "cur_epoch: 3/800, cur_it: 225/464, lr: 1e-08, loss: 4.54398\n",
      "cur_epoch: 3/800, cur_it: 226/464, lr: 1e-08, loss: 4.53947\n",
      "cur_epoch: 3/800, cur_it: 227/464, lr: 1e-08, loss: 4.56649\n",
      "cur_epoch: 3/800, cur_it: 228/464, lr: 1e-08, loss: 4.56914\n",
      "cur_epoch: 3/800, cur_it: 229/464, lr: 1e-08, loss: 4.57051\n",
      "cur_epoch: 3/800, cur_it: 230/464, lr: 1e-08, loss: 4.56806\n",
      "cur_epoch: 3/800, cur_it: 231/464, lr: 1e-08, loss: 4.56714\n",
      "cur_epoch: 3/800, cur_it: 232/464, lr: 1e-08, loss: 4.5695\n",
      "cur_epoch: 3/800, cur_it: 233/464, lr: 1e-08, loss: 4.56746\n",
      "cur_epoch: 3/800, cur_it: 234/464, lr: 1e-08, loss: 4.57548\n",
      "cur_epoch: 3/800, cur_it: 235/464, lr: 1e-08, loss: 4.57171\n",
      "cur_epoch: 3/800, cur_it: 236/464, lr: 1e-08, loss: 4.56895\n",
      "cur_epoch: 3/800, cur_it: 237/464, lr: 1e-08, loss: 4.56462\n",
      "cur_epoch: 3/800, cur_it: 238/464, lr: 1e-08, loss: 4.56442\n",
      "cur_epoch: 3/800, cur_it: 239/464, lr: 1e-08, loss: 4.56349\n",
      "cur_epoch: 3/800, cur_it: 240/464, lr: 1e-08, loss: 4.57204\n",
      "cur_epoch: 3/800, cur_it: 241/464, lr: 1e-08, loss: 4.57822\n",
      "cur_epoch: 3/800, cur_it: 242/464, lr: 1e-08, loss: 4.57589\n",
      "cur_epoch: 3/800, cur_it: 243/464, lr: 1e-08, loss: 4.57821\n",
      "cur_epoch: 3/800, cur_it: 244/464, lr: 1e-08, loss: 4.57409\n",
      "cur_epoch: 3/800, cur_it: 245/464, lr: 1e-08, loss: 4.57153\n",
      "cur_epoch: 3/800, cur_it: 246/464, lr: 1e-08, loss: 4.57079\n",
      "cur_epoch: 3/800, cur_it: 247/464, lr: 1e-08, loss: 4.56795\n",
      "cur_epoch: 3/800, cur_it: 248/464, lr: 1e-08, loss: 4.56663\n",
      "cur_epoch: 3/800, cur_it: 249/464, lr: 1e-08, loss: 4.56496\n",
      "cur_epoch: 3/800, cur_it: 250/464, lr: 1e-08, loss: 4.56334\n",
      "cur_epoch: 3/800, cur_it: 251/464, lr: 1e-08, loss: 4.55966\n",
      "cur_epoch: 3/800, cur_it: 252/464, lr: 1e-08, loss: 4.56381\n",
      "cur_epoch: 3/800, cur_it: 253/464, lr: 1e-08, loss: 4.56129\n",
      "cur_epoch: 3/800, cur_it: 254/464, lr: 1e-08, loss: 4.55795\n",
      "cur_epoch: 3/800, cur_it: 255/464, lr: 1e-08, loss: 4.55653\n",
      "cur_epoch: 3/800, cur_it: 256/464, lr: 1e-08, loss: 4.55378\n",
      "cur_epoch: 3/800, cur_it: 257/464, lr: 1e-08, loss: 4.55233\n",
      "cur_epoch: 3/800, cur_it: 258/464, lr: 1e-08, loss: 4.551\n",
      "cur_epoch: 3/800, cur_it: 259/464, lr: 1e-08, loss: 4.54947\n",
      "cur_epoch: 3/800, cur_it: 260/464, lr: 1e-08, loss: 4.54628\n",
      "cur_epoch: 3/800, cur_it: 261/464, lr: 1e-08, loss: 4.54442\n",
      "cur_epoch: 3/800, cur_it: 262/464, lr: 1e-08, loss: 4.54169\n",
      "cur_epoch: 3/800, cur_it: 263/464, lr: 1e-08, loss: 4.53891\n",
      "cur_epoch: 3/800, cur_it: 264/464, lr: 1e-08, loss: 4.53629\n",
      "cur_epoch: 3/800, cur_it: 265/464, lr: 1e-08, loss: 4.53272\n",
      "cur_epoch: 3/800, cur_it: 266/464, lr: 1e-08, loss: 4.53054\n",
      "cur_epoch: 3/800, cur_it: 267/464, lr: 1e-08, loss: 4.52923\n",
      "cur_epoch: 3/800, cur_it: 268/464, lr: 1e-08, loss: 4.53053\n",
      "cur_epoch: 3/800, cur_it: 269/464, lr: 1e-08, loss: 4.52795\n",
      "cur_epoch: 3/800, cur_it: 270/464, lr: 1e-08, loss: 4.5266\n",
      "cur_epoch: 3/800, cur_it: 271/464, lr: 1e-08, loss: 4.52779\n",
      "cur_epoch: 3/800, cur_it: 272/464, lr: 1e-08, loss: 4.52673\n",
      "cur_epoch: 3/800, cur_it: 273/464, lr: 1e-08, loss: 4.52561\n",
      "cur_epoch: 3/800, cur_it: 274/464, lr: 1e-08, loss: 4.52275\n",
      "cur_epoch: 3/800, cur_it: 275/464, lr: 1e-08, loss: 4.52195\n",
      "cur_epoch: 3/800, cur_it: 276/464, lr: 1e-08, loss: 4.52066\n",
      "cur_epoch: 3/800, cur_it: 277/464, lr: 1e-08, loss: 4.51769\n",
      "cur_epoch: 3/800, cur_it: 278/464, lr: 1e-08, loss: 4.51956\n",
      "cur_epoch: 3/800, cur_it: 279/464, lr: 1e-08, loss: 4.51773\n",
      "cur_epoch: 3/800, cur_it: 280/464, lr: 1e-08, loss: 4.51529\n",
      "cur_epoch: 3/800, cur_it: 281/464, lr: 1e-08, loss: 4.51379\n",
      "cur_epoch: 3/800, cur_it: 282/464, lr: 1e-08, loss: 4.51199\n",
      "cur_epoch: 3/800, cur_it: 283/464, lr: 1e-08, loss: 4.50862\n",
      "cur_epoch: 3/800, cur_it: 284/464, lr: 1e-08, loss: 4.50696\n",
      "cur_epoch: 3/800, cur_it: 285/464, lr: 1e-08, loss: 4.50599\n",
      "cur_epoch: 3/800, cur_it: 286/464, lr: 1e-08, loss: 4.50358\n",
      "cur_epoch: 3/800, cur_it: 287/464, lr: 1e-08, loss: 4.50618\n",
      "cur_epoch: 3/800, cur_it: 288/464, lr: 1e-08, loss: 4.50508\n",
      "cur_epoch: 3/800, cur_it: 289/464, lr: 1e-08, loss: 4.50206\n",
      "cur_epoch: 3/800, cur_it: 290/464, lr: 1e-08, loss: 4.50136\n",
      "cur_epoch: 3/800, cur_it: 291/464, lr: 1e-08, loss: 4.53858\n",
      "cur_epoch: 3/800, cur_it: 292/464, lr: 1e-08, loss: 4.54044\n",
      "cur_epoch: 3/800, cur_it: 293/464, lr: 1e-08, loss: 4.5423\n",
      "cur_epoch: 3/800, cur_it: 294/464, lr: 1e-08, loss: 4.54148\n",
      "cur_epoch: 3/800, cur_it: 295/464, lr: 1e-08, loss: 4.54017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 2/800 [21:55<145:50:44, 657.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 191\u001b[0m\n\u001b[1;32m    188\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    190\u001b[0m load_data_to_gpu(batch)\n\u001b[0;32m--> 191\u001b[0m ret_dict, tb_dict, disp_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m loss \u001b[38;5;241m=\u001b[39m ret_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    195\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models_multinomial_half/detectors/pointpillar.py:413\u001b[0m, in \u001b[0;36mPointPillar.forward\u001b[0;34m(self, batch_dict)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_dict):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cur_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_list:\n\u001b[0;32m--> 413\u001b[0m         batch_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcur_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    416\u001b[0m         loss, tb_dict, disp_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_training_loss()\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models_multinomial_half/dense_heads/anchor_head_single.py:61\u001b[0m, in \u001b[0;36mAnchorHeadSingle.forward\u001b[0;34m(self, data_dict)\u001b[0m\n\u001b[1;32m     58\u001b[0m     dir_cls_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m---> 61\u001b[0m     targets_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgt_boxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgt_boxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_ret_dict\u001b[38;5;241m.\u001b[39mupdate(targets_dict)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_boxes_when_training:\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models_multinomial_half/dense_heads/anchor_head_template.py:96\u001b[0m, in \u001b[0;36mAnchorHeadTemplate.assign_targets\u001b[0;34m(self, gt_boxes)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massign_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, gt_boxes):\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m        gt_boxes: (B, M, 8)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     targets_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_assigner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_boxes\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targets_dict\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models_multinomial_half/dense_heads/target_assigner/axis_aligned_target_assigner.py:83\u001b[0m, in \u001b[0;36mAxisAlignedTargetAssigner.assign_targets\u001b[0;34m(self, all_anchors, gt_boxes_with_classes)\u001b[0m\n\u001b[1;32m     80\u001b[0m         anchors \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, anchors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     81\u001b[0m         selected_classes \u001b[38;5;241m=\u001b[39m cur_gt_classes[mask]\n\u001b[0;32m---> 83\u001b[0m     single_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_targets_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcur_gt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgt_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatched_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatched_thresholds\u001b[49m\u001b[43m[\u001b[49m\u001b[43manchor_class_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43munmatched_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munmatched_thresholds\u001b[49m\u001b[43m[\u001b[49m\u001b[43manchor_class_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     target_list\u001b[38;5;241m.\u001b[39mappend(single_target)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_multihead:\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models_multinomial_half/dense_heads/target_assigner/axis_aligned_target_assigner.py:200\u001b[0m, in \u001b[0;36mAxisAlignedTargetAssigner.assign_targets_single\u001b[0;34m(self, anchors, gt_boxes, gt_classes, matched_threshold, unmatched_threshold)\u001b[0m\n\u001b[1;32m    198\u001b[0m     num_examples \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    199\u001b[0m     num_examples \u001b[38;5;241m=\u001b[39m num_examples \u001b[38;5;28;01mif\u001b[39;00m num_examples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m--> 200\u001b[0m     reg_weights[labels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     reg_weights[labels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/_tensor.py:32\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/_tensor.py:643\u001b[0m, in \u001b[0;36mTensor.__rdiv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rdiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreciprocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from pcdet.models_multinomial_half.detectors.pointpillar import PointPillar\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "from noise import add_noise_to_weights\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models_multinomial_half import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "# from train_utils.train_utils import train_model\n",
    "# from eval_utils import eval_utils_multinomial\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from eval_utils import eval_utils_multinomial_finalv_half as eval_utils\n",
    "\n",
    "\n",
    "\n",
    "def load_data_to_gpu(batch_dict):\n",
    "    for key, val in batch_dict.items():\n",
    "        if not isinstance(val, np.ndarray):\n",
    "            continue\n",
    "        elif key in ['frame_id', 'metadata', 'calib']:\n",
    "            continue\n",
    "        elif key in ['images']:\n",
    "            batch_dict[key] = image_to_tensor(val).float().cuda().contiguous()\n",
    "        elif key in ['image_shape']:\n",
    "            batch_dict[key] = torch.from_numpy(val).int().cuda()\n",
    "        else:\n",
    "            batch_dict[key] = torch.from_numpy(val).float().cuda()\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', help='specify the config for training')\n",
    "    parser.add_argument('--batch_size', type=int, default=8, required=False, help='batch size for training')\n",
    "    parser.add_argument('--workers', type=int, default=32, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    parser.add_argument('--pretrained_model', type=str, default=True, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=80, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=81, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER, help='set extra config keys if needed')\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--epochs', type=int, default=800, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--ckpt', type=str, default='checkpoint_epoch_80_multinomial.pth', help='checkpoint to start from')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1: -1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    dist_train = False\n",
    "    total_gpus = 1\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "    os.system('rm tmp')\n",
    "\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "    \n",
    "    common_utils.set_random_seed(666)\n",
    "    save_path = './save_path/logger/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "    \n",
    "    print(\"=============\")\n",
    "    p1 = 0.23\n",
    "    p2 = 0.77\n",
    "    p3 = 0.68\n",
    "    print(p1, p2, p3)\n",
    "    print(\"=============\")\n",
    "    \n",
    "\n",
    "    train_set, train_loader, train_sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=dist_train, workers=args.workers,\n",
    "        logger=logger,\n",
    "        training=True,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "        total_epochs=args.epochs\n",
    "    )\n",
    "\n",
    "    model = PointPillar(\n",
    "        model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=p1, p2=p2, p3=p3, dataset=train_set\n",
    "    )\n",
    "    \n",
    "    pth = torch.load('./checkpoint_epoch_80_multinomial.pth', map_location=torch.device('cuda:0'))['model_state']\n",
    "    model.load_state_dict(pth)#['model_state']\n",
    "    # torch.load('./checkpoint_epoch_33_multinomial.pth')['model_state']\n",
    "    # model.cuda()\n",
    "\n",
    "    optim_cfg = cfg.OPTIMIZATION\n",
    "    optim_cfg.LR = 0.00000001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=optim_cfg.LR, weight_decay=optim_cfg.WEIGHT_DECAY)\n",
    "\n",
    "    start_epoch = it = 0\n",
    "    last_epoch = -1\n",
    "\n",
    "    # model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "    # for m in model.modules():\n",
    "    #     if isinstance(m, nn.BatchNorm2d):\n",
    "    #         m.eval()\n",
    "    def fix_bn(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('BatchNorm') != -1:\n",
    "            m.eval()\n",
    "\n",
    "    # model = models.resnet50(pretrained=True)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    model.apply(fix_bn)  # fix batchnorm\n",
    "\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 20, eta_min=0, last_epoch=-1)\n",
    "    \n",
    "\n",
    "#     # -----------------------start training---------------------------\n",
    "    logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "    \n",
    "    optim_cfg=cfg.OPTIMIZATION\n",
    "    total_epochs=args.epochs\n",
    "    rank=cfg.LOCAL_RANK\n",
    "    \n",
    "    with tqdm.trange(start_epoch, total_epochs, desc='epochs', dynamic_ncols=True, leave=(rank==0)) as tbar:\n",
    "        total_it_each_epoch = len(train_loader)\n",
    "        for cur_epoch in tbar:\n",
    "            dataloader_iter = iter(train_loader)\n",
    "            loss_list = []\n",
    "\n",
    "            for cur_it in range(total_it_each_epoch):\n",
    "                batch = next(dataloader_iter)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                load_data_to_gpu(batch)\n",
    "                ret_dict, tb_dict, disp_dict = model(batch)\n",
    "\n",
    "                loss = ret_dict['loss'].mean()\n",
    "        \n",
    "                loss_list.append(loss)\n",
    "                loss_avg = sum(loss_list) / len(loss_list)\n",
    "\n",
    "                loss.backward()\n",
    "                # clip_grad_norm_(model.parameters(), optim_cfg.GRAD_NORM_CLIP)\n",
    "                \n",
    "                optimizer.step()\n",
    "                # lr_scheduler.step()\n",
    "\n",
    "                print('cur_epoch: {}/{}, cur_it: {}/{}, lr: {:.6}, loss: {:.6}'.format(cur_epoch+1, total_epochs, cur_it+1, total_it_each_epoch, optim_cfg.LR, loss_avg))\n",
    "            \n",
    "            logger.info('**********************Start testing**********************')\n",
    "            test_set, test_loader, sampler = build_dataloader(\n",
    "                                            dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                            class_names=cfg.CLASS_NAMES,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                        )\n",
    "\n",
    "            acc1, acc2, ret = eval_utils.eval_(cfg, model, test_loader)\n",
    "            print(acc1, acc2, ret)\n",
    "\n",
    "            filename = './save_path/0722/ckpt_epoch{}.pth'.format(cur_epoch+1)\n",
    "            last_filename = filename\n",
    "            torch.save(model.state_dict(), filename)\n",
    "        \n",
    "        \n",
    "    # filename = './save_path/0722/ckpt_epoch{}.pth'.format(0+1)\n",
    "    # torch.save(model.state_dict(), filename)        \n",
    "    \n",
    "#     logger.info('**********************Start testing %s/%s(%s)**********************'\n",
    "#                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "#     test_set, test_loader, sampler = build_dataloader(\n",
    "#                                     dataset_cfg=cfg.DATA_CONFIG,\n",
    "#                                     class_names=cfg.CLASS_NAMES,\n",
    "#                                     batch_size=args.batch_size,\n",
    "#                                     dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "#                                 )\n",
    "\n",
    "#     acc1, acc2, ret = eval_utils.eval_(cfg, model, test_loader)\n",
    "#     print(acc1, ac2, ret)\n",
    "\n",
    "    # logger.info('----------------Bayes Optimization----------------')\n",
    "    # Bounded region of parameter space\n",
    "    # pbounds = {'p1': (0.1, 0.9), 'p2': (0.1, 0.9)}\n",
    "    \n",
    "\n",
    "#     optimizer = BayesianOptimization(\n",
    "#         f=opt_function,\n",
    "#         pbounds=pbounds,\n",
    "#         verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "#         random_state=1,\n",
    "#     )\n",
    "#     optimizer.probe(\n",
    "#         params={'p1': 0.11, 'p2': 0.11},\n",
    "#         lazy=True,\n",
    "#     )\n",
    "\n",
    "#     logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "#     optimizer.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "    \n",
    "    \n",
    "#     n = 0\n",
    "#     optimizer.maximize(\n",
    "#         init_points=3,\n",
    "#         n_iter=10,\n",
    "#     )\n",
    "    print(\"=======end========\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
