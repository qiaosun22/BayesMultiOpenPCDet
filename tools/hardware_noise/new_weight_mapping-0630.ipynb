{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a4624-d57c-4eeb-a620-908704b90080",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d43d715-04df-4cea-97fc-17638ccdffdd",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-07-04T01:42:47.301454Z",
     "iopub.status.busy": "2023-07-04T01:42:47.300901Z",
     "iopub.status.idle": "2023-07-04T01:42:47.317547Z",
     "shell.execute_reply": "2023-07-04T01:42:47.317096Z",
     "shell.execute_reply.started": "2023-07-04T01:42:47.301429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2903, -0.3241,  0.0031, -0.0674],\n",
      "        [ 0.4362, -0.2060,  0.2714, -0.0670],\n",
      "        [-0.1672, -0.2732, -0.0159, -0.3084]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def mlesigma(f_name):\n",
    "    # df = pd.read_excel('I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx') #0.55\n",
    "    # df = pd.read_excel('I-V_data_30min_AAO_5min second etch_15min_Pb_ED_3h_180C_MAI_200nm_Ag_memory_6V.xlsx') #0.33\n",
    "    # df = pd.read_excel('I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V.xlsx') #0.14\n",
    "\n",
    "    # data = pd.read_excel('../hardware_noise/I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V.xlsx') #0.14\n",
    "    # data = pd.read_excel('../hardware_noise/I-V_data_30min_AAO_5min second etch_15min_Pb_ED_3h_180C_MAI_200nm_Ag_memory_6V.xlsx') #0.33\n",
    "    data = pd.read_excel(f_name, engine='openpyxl') #0.55\n",
    "\n",
    "    conductance = data.drop(['voltage'], axis=1).div(data['voltage'], axis=0)\n",
    "\n",
    "    conductance = conductance[(conductance!=np.inf).all(axis=1)]\n",
    "\n",
    "    # (conductance.div(conductance.mean(axis=1), axis=0)<0).all(axis=0)\n",
    "\n",
    "\n",
    "    from scipy.stats import norm\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    conductance_by_mean = np.array(conductance.div(conductance.mean(axis=1), axis=0)).reshape(1, -1)[0]\n",
    "    samples = np.log(conductance_by_mean)\n",
    "    samples_fine = np.delete(conductance_by_mean, np.isfinite(samples)==False)\n",
    "\n",
    "    # print(norm.fit(samples_fine))  # 返回极大似然估计\n",
    "    # print(norm.fit(samples_fine, floc=0))  # 返回极大似然估计 固定均值为 0\n",
    "    \n",
    "    return norm.fit(samples_fine)[1]\n",
    "\n",
    "\n",
    "# print(mlesigma('I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx')) #0.55\n",
    "\n",
    "\n",
    "def weights_mapping(f_name, model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Map target weight to true weight. \n",
    "    The difference between the target weight and the true weight is due to two factors:\n",
    "    1.Random heat noises\n",
    "    2.Non-monotonic characteristics of conductance-Q curves\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    X ~ logNorm(a, b)  # m, v 是对数正态分布本身的均值和方差\n",
    "    # 这说的是 X 是一个值永远为正的随机变量，只有取对数之后才是正态分布\n",
    "    即 logX ~ Norm(mu, sigma)\n",
    "\n",
    "    换算关系：\n",
    "    m = exp(mu + sigma^2/2)  # 注意到 m 是 >0 的\n",
    "    v = exp(2*mu + sigma^2) * exp(sigma^2 - 1)  \n",
    "\n",
    "    因此，一个随机变量 Y 如果服从正态分布，即 Y ~ Norm(mu, sigma)\n",
    "    就一定可以有一个 X = exp(Y), 使得 Y = logX ~ Norm(mu, sigma)\n",
    "\n",
    "    所以，一个正态分布随机变量取指数得到的变量就服从对数正态分布\n",
    "\n",
    "    具体到上面的代码，已知gaussian_kernel 服从正态分布，则 \n",
    "            torch.exp(noise_sigma*gassian_kernel.sample(noise_sigma.size())) \n",
    "    服从对数正态分布，其中我们施加的 mu, sigma 都是对应的正态分布的参数，而非对数正态分布的参数\n",
    "\n",
    "    又由于 (m, v) 和 (mu, sigma) 是一一映射，我们控制谁都一样，\n",
    "    所以，为了方便和统一，今后：\n",
    "    1）需要采样对数正态分布样本，都采取先用 mu, sigma 采样正态分布，再 exp 的方式\n",
    "    2）需要估计对数正态分布参数，都采取先对对数正态分布样本取 log，再用 norm.fit 拟合的方式\n",
    "    '''\n",
    "    \n",
    "    noise_sigma = mlesigma(f_name)\n",
    "    gassian_kernel = torch.distributions.Normal(0.0, noise_sigma)\n",
    "    with torch.no_grad():\n",
    "        for theta in model.parameters():\n",
    "            abstheta = torch.abs(theta) # 求参数的绝对值\n",
    "            normalized_theta = abstheta / (torch.max(abstheta)+1e-8) # 归一化\n",
    "\n",
    "            theta_index = normalized_theta*(required_len-1)\n",
    "            theta_index = theta_index.type(torch.LongTensor) # 求各参数对应的下标位置\n",
    "\n",
    "            noise_index = normalized_theta*100\n",
    "            noise_index = noise_index.type(torch.LongTensor)\n",
    "            noise_index[noise_index>=100]=99\n",
    "\n",
    "            theta_ratio = torch.Tensor(ratio)[theta_index] # theta = theta * (c_real-c_min) / (c_max-c_min)\n",
    "\n",
    "            # noise_sigma = torch.Tensor(np.log(1+np.square(yfit_std/yfit)))[noise_index]\n",
    "            # theta.mul_(to_device(theta_ratio * torch.exp(noise_sigma*gassian_kernel.sample(noise_sigma.size())), device))\n",
    "            # print(noise_sigma.shape)\n",
    "            theta.mul_(to_device(theta_ratio*torch.exp(gassian_kernel.sample(noise_sigma.size())), device))\n",
    "            # theta.mul_(to_device(theta_ratio*torch.exp(noise_sigma), device))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def Kalman1D(observations,damping=0):\n",
    "#     # To return the smoothed time series data\n",
    "#     observation_covariance = damping\n",
    "#     initial_value_guess = observations[0]\n",
    "#     transition_matrix = 1\n",
    "#     transition_covariance = 0.1\n",
    "#     initial_value_guess\n",
    "#     kf = KalmanFilter(\n",
    "#             initial_state_mean=initial_value_guess,\n",
    "#             initial_state_covariance=observation_covariance,\n",
    "#             observation_covariance=observation_covariance,\n",
    "#             transition_covariance=transition_covariance,\n",
    "#             transition_matrices=transition_matrix\n",
    "#         )\n",
    "#     pred_state, state_cov = kf.smooth(observations)\n",
    "#     return pred_state\n",
    "\n",
    "def LCIS(arr): # 求最长连续[递增]子序列，该[递增]序列中最多允许两次递减\n",
    "    decrease_cnt = 0\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    sub_len = 0\n",
    "    longest_start = 0\n",
    "    longest_end = 0\n",
    "    longest_len = 0\n",
    "    decrease_point_0 = -1\n",
    "    decrease_point_1 = -1\n",
    "    for i in range(1, len(arr)):\n",
    "        if arr[i] > arr[i-1]:\n",
    "            end_index += 1\n",
    "        else:\n",
    "            decrease_cnt += 1\n",
    "            if decrease_cnt == 1:\n",
    "                end_index += 1\n",
    "                decrease_point_0 = end_index\n",
    "\n",
    "            elif decrease_cnt == 2:\n",
    "                end_index += 1\n",
    "                decrease_point_1 = end_index\n",
    "                \n",
    "            else:\n",
    "                sub_len = end_index - start_index + 1\n",
    "                if longest_len < sub_len:\n",
    "                    longest_len = sub_len\n",
    "                    longest_start = start_index\n",
    "                    longest_end = end_index\n",
    "                start_index = decrease_point_0\n",
    "                decrease_point_0 = decrease_point_1\n",
    "                decrease_point_1 = i\n",
    "                end_index = i\n",
    "                decrease_cnt = 2\n",
    "\n",
    "    sub_len = end_index - start_index + 1\n",
    "    if longest_len < sub_len:\n",
    "        longest_len = sub_len\n",
    "        longest_start = start_index\n",
    "        longest_end = end_index\n",
    "\n",
    "    return longest_start, longest_end\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# def main():\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(4, 3)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        out = self.linear1(xb)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Net()\n",
    "# model = weights_mapping(f_name, 0, 1, model=model, device='cpu')\n",
    "# def weights_mapping(file, mean, std, model, device='cuda'):\n",
    "# model1 = weights_mapping(f_name, 0, 1, model=model, device='cpu')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "# model1\n",
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d783ebc-b832-4ebf-900e-c113e390728d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-07-04T01:44:02.723725Z",
     "iopub.status.busy": "2023-07-04T01:44:02.723100Z",
     "iopub.status.idle": "2023-07-04T01:44:02.736641Z",
     "shell.execute_reply": "2023-07-04T01:44:02.736075Z",
     "shell.execute_reply.started": "2023-07-04T01:44:02.723706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'required_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m weights_mapping(f_name, \u001b[43mrequired_len\u001b[49m, ratio, yfit, yfit_std, model, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'required_len' is not defined"
     ]
    }
   ],
   "source": [
    "f_name = 'I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx'\n",
    "weights_mapping(f_name, required_len=65, ratio=, yfit, yfit_std, model, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8d31fb-36b6-4d31-8bac-94160c3912d5",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T08:34:15.854069Z",
     "iopub.status.busy": "2023-06-30T08:34:15.853626Z",
     "iopub.status.idle": "2023-06-30T08:34:15.857343Z",
     "shell.execute_reply": "2023-06-30T08:34:15.856920Z",
     "shell.execute_reply.started": "2023-06-30T08:34:15.854051Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4771,  0.0182, -0.0350,  0.0472],\n",
      "        [-0.0287, -0.4223, -0.0508, -0.4034],\n",
      "        [ 0.2235, -0.2301, -0.1098,  0.2376]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e137c0-9f50-4e7b-89a7-1de25bf3ed6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T08:34:12.051652Z",
     "iopub.status.busy": "2023-06-30T08:34:12.051218Z",
     "iopub.status.idle": "2023-06-30T08:34:12.210859Z",
     "shell.execute_reply": "2023-06-30T08:34:12.210432Z",
     "shell.execute_reply.started": "2023-06-30T08:34:12.051636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = weights_mapping(f_name, 0, 1, model=model, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d02d4ee-5388-45de-ae43-f803fe7e6237",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-06-30T08:33:02.257741Z",
     "iopub.status.busy": "2023-06-30T08:33:02.257173Z",
     "iopub.status.idle": "2023-06-30T08:33:02.260855Z",
     "shell.execute_reply": "2023-06-30T08:33:02.260426Z",
     "shell.execute_reply.started": "2023-06-30T08:33:02.257722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3079,  0.4667,  0.4657,  0.2650],\n",
      "        [-0.4818, -0.4662, -0.4599,  0.2789],\n",
      "        [ 0.3211, -0.0410,  0.4333,  0.1952]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61a469b-571d-4176-9dab-94ebc4f0e48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T08:29:51.350737Z",
     "iopub.status.busy": "2023-06-30T08:29:51.350156Z",
     "iopub.status.idle": "2023-06-30T08:29:51.356124Z",
     "shell.execute_reply": "2023-06-30T08:29:51.355687Z",
     "shell.execute_reply.started": "2023-06-30T08:29:51.350718Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate(file):\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # # df = pd.read_excel('I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx') #0.55\n",
    "    # # df = pd.read_excel('I-V_data_30min_AAO_5min second etch_15min_Pb_ED_3h_180C_MAI_200nm_Ag_memory_6V.xlsx') #0.33\n",
    "    # # df = pd.read_excel('./hardware_noise/hardware_data/I-V_data_0.7um_length_200nm_diameter_NA_third_etch_10min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_1V_carbon_paste.xlsx') #0.14\n",
    "    # # df = pd.read_excel('./hardware_noise/I-V_data_25min_AAO_10min_Pb_ED_1h_180C_MAI_memory_8V_2.xlsx') #0.55    \n",
    "    # df = pd.read_excel('./hardware_noise/I-V_data_30min_AAO_5min second etch_15min_Pb_ED_3h_180C_MAI_200nm_Ag_memory_6V.xlsx') #0.33\n",
    "    # file = './hardware_noise/I-V_data_30min_AAO_5min second etch_15min_Pb_ED_3h_180C_MAI_200nm_Ag_memory_6V.xlsx'\n",
    "    # sunqiao/OpenPCDet/tools/hardware_noise/hardware_data/I-V_data_0.7um_length_200nm_diameter_NA_third_etch_10min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_1V_carbon_paste.xlsx\n",
    "    dropcolumn = []\n",
    "    for i in range(len(df.columns)):\n",
    "        if 'Unnamed' in df.columns[i]:\n",
    "            dropcolumn.append(df.columns[i])\n",
    "            \n",
    "\n",
    "    df = df.drop(columns=dropcolumn)\n",
    "\n",
    "    #calculate mean and std current for each row and remove the NAN\n",
    "    voltage = df['voltage']\n",
    "    current_mean_list = []\n",
    "    current_std_list = []\n",
    "    for i in range(len(voltage)):\n",
    "        current_row = df.iloc[[i]].to_numpy()\n",
    "        current_row = current_row[~np.isnan(current_row)]\n",
    "        \n",
    "        low_percentile = np.percentile(current_row, 25)\n",
    "        high_percentile = np.percentile(current_row, 75)\n",
    "        current_row = current_row[(current_row >=low_percentile ) & (current_row <= high_percentile)]\n",
    "        \n",
    "        current_mean = np.mean(current_row)\n",
    "        \n",
    "        \n",
    "        current_std = np.std(current_row)\n",
    "        current_mean_list.append(current_mean)\n",
    "        current_std_list.append(current_std)\n",
    "\n",
    "    current_mean_list = np.array(current_mean_list)\n",
    "    current_std_list = np.array(current_std_list)\n",
    "\n",
    "    voltage_list = df['voltage'].to_numpy()\n",
    "\n",
    "    conductance_mean = current_mean_list/(voltage_list+1e-9)\n",
    "    conductance_std  = current_std_list/(voltage_list+1e-9)\n",
    "\n",
    "    c_mean_smooth = conductance_mean[1:100] \n",
    "\n",
    "    c_std_smooth = conductance_std[1:100]\n",
    "\n",
    "\n",
    "    c_mean_smooth = Kalman1D(c_mean_smooth,damping=1)\n",
    "    c_std_smooth  = Kalman1D(c_std_smooth,damping=1)\n",
    "\n",
    "\n",
    "    return c_mean_smooth, c_std_smooth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
