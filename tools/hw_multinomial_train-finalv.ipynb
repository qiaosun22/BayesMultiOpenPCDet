{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c459afb4-38d9-4da3-a4f2-129e4d43b989",
   "metadata": {},
   "source": [
    "本代码用于测试全 Multinomial 的情形\n",
    "\n",
    "目前还有些问题，主要是加了噪声之后就全降到 0.\n",
    "\n",
    "已经排除的可能：\\\n",
    "网络本身没问题，不加噪声就没事。因此高度怀疑是因为噪声过大。\\\n",
    "并且现在的权重没有重新调，需要调一下。\n",
    "\n",
    "当前解决方案：减少 requirelen 到 45，以降低加噪声的影响。\\\n",
    "重训网络。\n",
    "\n",
    "实例：PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dccef7d-d27c-490c-847f-741a53e85e3f",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T01:47:29.997443Z",
     "iopub.status.busy": "2023-07-07T01:47:29.997290Z",
     "iopub.status.idle": "2023-07-07T01:53:23.447705Z",
     "shell.execute_reply": "2023-07-07T01:53:23.446174Z",
     "shell.execute_reply.started": "2023-07-07T01:47:29.997428Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 09:47:35,981   INFO  cfg_file         ./cfgs/kitti_models/pointpillar_bayes.yaml\n",
      "2023-07-07 09:47:35,982   INFO  batch_size       8\n",
      "2023-07-07 09:47:35,982   INFO  epochs           1\n",
      "2023-07-07 09:47:35,983   INFO  workers          32\n",
      "2023-07-07 09:47:35,983   INFO  extra_tag        default\n",
      "2023-07-07 09:47:35,983   INFO  ckpt             checkpoint_epoch_33_multinomial.pth\n",
      "2023-07-07 09:47:35,984   INFO  pretrained_model False\n",
      "2023-07-07 09:47:35,984   INFO  launcher         none\n",
      "2023-07-07 09:47:35,984   INFO  tcp_port         18888\n",
      "2023-07-07 09:47:35,985   INFO  sync_bn          False\n",
      "2023-07-07 09:47:35,985   INFO  fix_random_seed  True\n",
      "2023-07-07 09:47:35,985   INFO  ckpt_save_interval 1\n",
      "2023-07-07 09:47:35,986   INFO  local_rank       0\n",
      "2023-07-07 09:47:35,986   INFO  max_ckpt_save_num 81\n",
      "2023-07-07 09:47:35,986   INFO  merge_all_iters_to_one_epoch False\n",
      "2023-07-07 09:47:35,987   INFO  set_cfgs         None\n",
      "2023-07-07 09:47:35,987   INFO  max_waiting_mins 0\n",
      "2023-07-07 09:47:35,987   INFO  start_epoch      0\n",
      "2023-07-07 09:47:35,988   INFO  save_to_file     False\n",
      "2023-07-07 09:47:35,988   INFO  cfg.ROOT_DIR: /mnt/workspace/sunqiao/OpenPCDet\n",
      "2023-07-07 09:47:35,988   INFO  cfg.LOCAL_RANK: 0\n",
      "2023-07-07 09:47:35,989   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2023-07-07 09:47:35,989   INFO  ----------- DATA_CONFIG -----------\n",
      "2023-07-07 09:47:35,989   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2023-07-07 09:47:35,990   INFO  cfg.DATA_CONFIG.DATA_PATH: ../data/kitti\n",
      "2023-07-07 09:47:35,990   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -39.68, -3, 69.12, 39.68, 1]\n",
      "2023-07-07 09:47:35,990   INFO  ----------- DATA_SPLIT -----------\n",
      "2023-07-07 09:47:35,991   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2023-07-07 09:47:35,991   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2023-07-07 09:47:35,991   INFO  ----------- INFO_PATH -----------\n",
      "2023-07-07 09:47:35,991   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2023-07-07 09:47:35,992   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2023-07-07 09:47:35,992   INFO  cfg.DATA_CONFIG.GET_ITEM_LIST: ['points']\n",
      "2023-07-07 09:47:35,992   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2023-07-07 09:47:35,993   INFO  ----------- DATA_AUGMENTOR -----------\n",
      "2023-07-07 09:47:35,993   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2023-07-07 09:47:35,993   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2023-07-07 09:47:35,994   INFO  ----------- POINT_FEATURE_ENCODING -----------\n",
      "2023-07-07 09:47:35,994   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2023-07-07 09:47:35,994   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-07-07 09:47:35,995   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2023-07-07 09:47:35,995   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]\n",
      "2023-07-07 09:47:35,995   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml\n",
      "2023-07-07 09:47:35,996   INFO  ----------- MODEL -----------\n",
      "2023-07-07 09:47:35,996   INFO  cfg.MODEL.NAME: PointPillar\n",
      "2023-07-07 09:47:35,996   INFO  ----------- VFE -----------\n",
      "2023-07-07 09:47:35,997   INFO  cfg.MODEL.VFE.NAME: PillarVFE\n",
      "2023-07-07 09:47:35,997   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False\n",
      "2023-07-07 09:47:35,997   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True\n",
      "2023-07-07 09:47:35,997   INFO  cfg.MODEL.VFE.USE_NORM: True\n",
      "2023-07-07 09:47:35,998   INFO  cfg.MODEL.VFE.USE_DO: True\n",
      "2023-07-07 09:47:35,998   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64]\n",
      "2023-07-07 09:47:35,998   INFO  ----------- MAP_TO_BEV -----------\n",
      "2023-07-07 09:47:35,999   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter\n",
      "2023-07-07 09:47:35,999   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 64\n",
      "2023-07-07 09:47:35,999   INFO  ----------- BACKBONE_2D -----------\n",
      "2023-07-07 09:47:36,000   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone\n",
      "2023-07-07 09:47:36,000   INFO  cfg.MODEL.BACKBONE_2D.USE_NORM: True\n",
      "2023-07-07 09:47:36,000   INFO  cfg.MODEL.BACKBONE_2D.USE_DO: True\n",
      "2023-07-07 09:47:36,001   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [3, 5, 5]\n",
      "2023-07-07 09:47:36,001   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [2, 2, 2]\n",
      "2023-07-07 09:47:36,001   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [64, 128, 256]\n",
      "2023-07-07 09:47:36,001   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]\n",
      "2023-07-07 09:47:36,002   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]\n",
      "2023-07-07 09:47:36,002   INFO  ----------- DENSE_HEAD -----------\n",
      "2023-07-07 09:47:36,002   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle\n",
      "2023-07-07 09:47:36,003   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False\n",
      "2023-07-07 09:47:36,003   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True\n",
      "2023-07-07 09:47:36,003   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539\n",
      "2023-07-07 09:47:36,004   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0\n",
      "2023-07-07 09:47:36,004   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2\n",
      "2023-07-07 09:47:36,004   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Cyclist', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}]\n",
      "2023-07-07 09:47:36,005   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------\n",
      "2023-07-07 09:47:36,005   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner\n",
      "2023-07-07 09:47:36,005   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0\n",
      "2023-07-07 09:47:36,006   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512\n",
      "2023-07-07 09:47:36,006   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False\n",
      "2023-07-07 09:47:36,006   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False\n",
      "2023-07-07 09:47:36,006   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder\n",
      "2023-07-07 09:47:36,007   INFO  ----------- LOSS_CONFIG -----------\n",
      "2023-07-07 09:47:36,007   INFO  ----------- LOSS_WEIGHTS -----------\n",
      "2023-07-07 09:47:36,007   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0\n",
      "2023-07-07 09:47:36,008   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0\n",
      "2023-07-07 09:47:36,008   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2\n",
      "2023-07-07 09:47:36,008   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-07-07 09:47:36,009   INFO  ----------- POST_PROCESSING -----------\n",
      "2023-07-07 09:47:36,009   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2023-07-07 09:47:36,009   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2023-07-07 09:47:36,010   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2023-07-07 09:47:36,010   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2023-07-07 09:47:36,010   INFO  ----------- NMS_CONFIG -----------\n",
      "2023-07-07 09:47:36,011   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2023-07-07 09:47:36,011   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2023-07-07 09:47:36,011   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.01\n",
      "2023-07-07 09:47:36,012   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2023-07-07 09:47:36,012   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2023-07-07 09:47:36,012   INFO  ----------- OPTIMIZATION -----------\n",
      "2023-07-07 09:47:36,013   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4\n",
      "2023-07-07 09:47:36,013   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2023-07-07 09:47:36,013   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2023-07-07 09:47:36,014   INFO  cfg.OPTIMIZATION.LR: 0.003\n",
      "2023-07-07 09:47:36,014   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2023-07-07 09:47:36,014   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2023-07-07 09:47:36,015   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2023-07-07 09:47:36,015   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2023-07-07 09:47:36,015   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2023-07-07 09:47:36,016   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2023-07-07 09:47:36,016   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2023-07-07 09:47:36,016   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2023-07-07 09:47:36,017   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2023-07-07 09:47:36,017   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2023-07-07 09:47:36,017   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2023-07-07 09:47:36,017   INFO  cfg.TAG: pointpillar_bayes\n",
      "2023-07-07 09:47:36,018   INFO  cfg.EXP_GROUP_PATH: cfgs/kitti_models\n",
      "2023-07-07 09:47:36,040   INFO  **********************Start evaluation**********************\n",
      "2023-07-07 09:47:36,041   INFO  Loading KITTI dataset\n",
      "2023-07-07 09:47:36,137   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n",
      "=============\n",
      "0.23 0.14 0.68 0.36\n",
      "=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2023-07-07 09:47:37,558   INFO  ==> Loading parameters from checkpoint checkpoint_epoch_33_multinomial.pth to CPU\n",
      "2023-07-07 09:47:37,597   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+02ac3e1\n",
      "2023-07-07 09:47:37,761   INFO  ==> Done (loaded 127/127)\n",
      "2023-07-07 09:47:38,772   INFO  ==> Loading parameters from checkpoint checkpoint_epoch_33_multinomial.pth to CPU\n",
      "2023-07-07 09:47:38,795   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+02ac3e1\n",
      "2023-07-07 09:47:38,885   INFO  ==> Done (loaded 127/127)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.757076617433052e-06 I-V_data_1.8um_length_50nm_diameter_NA_third_etch_20min_Pb_ED_3h_180C_MAI_no_200nm_Ag_memory_6V_carbon_paste.xlsx\n",
      "file:I-V_data_1.8um_length_50nm_diameter_NA_third_etch_20min_Pb_ED_3h_180C_MAI_no_200nm_Ag_memory_6V_carbon_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 472/472 [02:55<00:00,  2.69it/s, recall_0.3=(0, 15766) / 17558]\n",
      "2023-07-07 09:50:34,300   INFO  Generate label finished(sec_per_example: 0.0465 second).\n",
      "2023-07-07 09:50:34,301   INFO  recall_roi_0.3: 0.000000\n",
      "2023-07-07 09:50:34,301   INFO  recall_rcnn_0.3: 0.897938\n",
      "2023-07-07 09:50:34,302   INFO  recall_roi_0.5: 0.000000\n",
      "2023-07-07 09:50:34,302   INFO  recall_rcnn_0.5: 0.791377\n",
      "2023-07-07 09:50:34,303   INFO  recall_roi_0.7: 0.000000\n",
      "2023-07-07 09:50:34,305   INFO  recall_rcnn_0.7: 0.447830\n",
      "2023-07-07 09:50:34,315   INFO  Average predicted number of objects(3769 samples): 59.459\n",
      "/home/pai/lib/python3.9/site-packages/numba/core/typed_passes.py:329: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.readthedocs.io/en/stable/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../pcdet/datasets/kitti/kitti_object_eval_python/eval.py\", line 122:\u001b[0m\n",
      "\u001b[1m@numba.jit(nopython=True, parallel=True)\n",
      "\u001b[1mdef d3_box_overlap_kernel(boxes, qboxes, rinc, criterion=-1):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaPerformanceWarning(msg,\n",
      "2023-07-07 09:51:09,542   INFO  ==> Loading parameters from checkpoint checkpoint_epoch_33_multinomial.pth to CPU\n",
      "2023-07-07 09:51:09,563   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+02ac3e1\n",
      "2023-07-07 09:51:09,656   INFO  ==> Done (loaded 127/127)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.8979382617610207, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.7913771500170862, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.4478300489805217, 'Car_aos/easy_R40': 91.54075753992664, 'Car_aos/moderate_R40': 79.49530829724819, 'Car_aos/hard_R40': 76.83543609483547, 'Car_3d/easy_R40': 59.544130869381625, 'Car_3d/moderate_R40': 49.82465946264248, 'Car_3d/hard_R40': 47.62370937630376, 'Car_bev/easy_R40': 84.2063148374911, 'Car_bev/moderate_R40': 75.19097971579536, 'Car_bev/hard_R40': 72.71231597102832, 'Car_image/easy_R40': 91.83272833862873, 'Car_image/moderate_R40': 80.09126978501051, 'Car_image/hard_R40': 77.60179343237259, 'Pedestrian_aos/easy_R40': 24.591771381654564, 'Pedestrian_aos/moderate_R40': 21.779820464025075, 'Pedestrian_aos/hard_R40': 20.7596337609409, 'Pedestrian_3d/easy_R40': 35.17066829286028, 'Pedestrian_3d/moderate_R40': 30.619979243960422, 'Pedestrian_3d/hard_R40': 27.716257221080426, 'Pedestrian_bev/easy_R40': 42.811296903232716, 'Pedestrian_bev/moderate_R40': 37.048808015756165, 'Pedestrian_bev/hard_R40': 33.86633267328288, 'Pedestrian_image/easy_R40': 41.55691640451373, 'Pedestrian_image/moderate_R40': 37.14192217445558, 'Pedestrian_image/hard_R40': 34.99890080864315, 'Cyclist_aos/easy_R40': 61.3978877449061, 'Cyclist_aos/moderate_R40': 46.37259863261769, 'Cyclist_aos/hard_R40': 43.39006225326987, 'Cyclist_3d/easy_R40': 53.98288621377638, 'Cyclist_3d/moderate_R40': 36.84323598750637, 'Cyclist_3d/hard_R40': 34.45437081125343, 'Cyclist_bev/easy_R40': 60.77302888181384, 'Cyclist_bev/moderate_R40': 41.56104681132362, 'Cyclist_bev/hard_R40': 39.16352222845531, 'Cyclist_image/easy_R40': 62.362791947009065, 'Cyclist_image/moderate_R40': 47.75542964175049, 'Cyclist_image/hard_R40': 44.847152716877936}\n",
      "0.002659952221105318 I-V_data_1.2um_length_200nm_diameter_NA_third_etch_15min_Pb_ED_10h_180+210C_FAI_PMMA_200nm_Ag_memory_6V_silver_paste.xlsx\n",
      "file:I-V_data_1.2um_length_200nm_diameter_NA_third_etch_15min_Pb_ED_10h_180+210C_FAI_PMMA_200nm_Ag_memory_6V_silver_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:  57%|█████▋    | 267/472 [02:12<01:19,  2.57it/s, recall_0.3=(0, 8821) / 9852]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 384\u001b[0m\n\u001b[1;32m    381\u001b[0m usability \u001b[38;5;241m=\u001b[39m file2usability[f_name]\n\u001b[1;32m    382\u001b[0m sigma \u001b[38;5;241m=\u001b[39m file2sigma[f_name]\n\u001b[0;32m--> 384\u001b[0m acc1, ret_dict \u001b[38;5;241m=\u001b[39m \u001b[43meval_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msave_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_output_dir\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m                \n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mprint\u001b[39m(ret_dict)\n\u001b[1;32m    388\u001b[0m file2ap_dict[f_name][n] \u001b[38;5;241m=\u001b[39m ret_dict\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/tools/eval_utils/eval_utils_multinomial_finalv.py:61\u001b[0m, in \u001b[0;36meval_simple\u001b[0;34m(p1, p2, p3, p4, file, usability, sigma, n, cfg, model, dataloader, logger, save_path, dist_test, save_to_file, result_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mload_data_to_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     63\u001b[0m         pred_dicts, ret_dict \u001b[38;5;241m=\u001b[39m model(batch_dict)\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/models/__init__.py:36\u001b[0m, in \u001b[0;36mload_data_to_gpu\u001b[0;34m(batch_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m     batch_dict[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(val)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     batch_dict[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "# from noise import add_noise_to_weights\n",
    "from hardware_noise.weight_mapping_finalv import weight_mapping as add_noise_to_weights\n",
    "\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models_multinomial_finalv import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model, model_save\n",
    "from eval_utils import eval_utils_multinomial_finalv as eval_utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', \\\n",
    "                        help='specify the config for training')\n",
    "    # sunqiao/OpenPCDet/tools/cfgs/kitti_models/pointpillar_bayes.yaml\n",
    "    parser.add_argument('--batch_size', type=int, default=8, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=1, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=32, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    parser.add_argument('--ckpt', type=str, \n",
    "                        default='checkpoint_epoch_33_multinomial.pth',#'./checkpoint_epoch_80_bayes.pth', \n",
    "                        help='checkpoint to start from')\n",
    "    # ./checkpoint_epoch_80.pth\n",
    "    parser.add_argument('--pretrained_model', type=str, default=False, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=81, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg\n",
    "\n",
    "class Opt():\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        \n",
    "    def opt_function(self, pp1, pp2, pp3, pp4):\n",
    "        \n",
    "        global p1\n",
    "        global p2\n",
    "        global p3\n",
    "        global p4\n",
    "        \n",
    "        p1 = pp1\n",
    "        p2 = pp2\n",
    "        p3 = pp3\n",
    "        p4 = pp4\n",
    "        \n",
    "        print(\"=============\")\n",
    "        print(p1, p2, p3, p4)\n",
    "        print(\"=============\")\n",
    "\n",
    "        global best_accu\n",
    "        \n",
    "        with_training = True  # False\n",
    "        if with_training == True:\n",
    "            # p1 = round(p1, 2)\n",
    "            # p2 = round(p2, 2)\n",
    "            # p3 = round(p3, 2)\n",
    "            # p4 = round(p4, 2)\n",
    "            \n",
    "            train_set, train_loader, train_sampler = build_dataloader(\n",
    "                dataset_cfg=cfg.DATA_CONFIG,\n",
    "                class_names=cfg.CLASS_NAMES,\n",
    "                batch_size=args.batch_size,\n",
    "                dist=dist_train, workers=args.workers,\n",
    "                logger=logger,\n",
    "                training=True,\n",
    "                merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "                total_epochs=args.epochs\n",
    "            )\n",
    "\n",
    "            model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "                                p1=p1, \n",
    "                                p2=p2, \n",
    "                                p3=p3, \n",
    "                                p4=p4, \n",
    "                                dataset=train_set)\n",
    "            # print(model.state_dict())\n",
    "\n",
    "            if args.sync_bn:\n",
    "                model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "            model.cuda()\n",
    "\n",
    "            optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "            # # load checkpoint if it is possible\n",
    "            start_epoch = it = 0\n",
    "            last_epoch = -1\n",
    "            if args.pretrained_model is True:\n",
    "                model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "\n",
    "            model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "            if dist_train:\n",
    "                model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "            logger.info(model)\n",
    "\n",
    "            lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "                optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "                last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "            )\n",
    "\n",
    "        #     # -----------------------start training---------------------------\n",
    "            logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                        % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "            train_model(\n",
    "                model,\n",
    "                optimizer,\n",
    "                train_loader,\n",
    "                model_func=model_fn_decorator(),\n",
    "                lr_scheduler=lr_scheduler,\n",
    "                optim_cfg=cfg.OPTIMIZATION,\n",
    "                start_epoch=start_epoch,\n",
    "                total_epochs=args.epochs,\n",
    "                start_iter=it,\n",
    "                rank=cfg.LOCAL_RANK,\n",
    "                tb_log=tb_log,\n",
    "                ckpt_save_dir=ckpt_dir,\n",
    "                train_sampler=train_sampler,\n",
    "                lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "                ckpt_save_interval=args.ckpt_save_interval,\n",
    "                max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "                merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "            )\n",
    "\n",
    "        test_set, test_loader, sampler = build_dataloader(\n",
    "                                        dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                        class_names=cfg.CLASS_NAMES,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                    )\n",
    "\n",
    "\n",
    "        model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, p3=0.11, p4=0.11, dataset=test_set)\n",
    "        model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "        # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "        \n",
    "        optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "        if dist_train: \n",
    "            model = model.module\n",
    "\n",
    "        # if args.pretrained_model is True:\n",
    "        #     model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "        # model.load_params_from_file(filename='./checkpoint_epoch_80.pth', logger=logger, to_cpu=dist_train)\n",
    "        model.cuda()\n",
    "        \n",
    "        global n\n",
    "        n += 1\n",
    "        \n",
    "        ckpt_pth = save_path+'multinomial_iter{}-{}-{}-{}-{}'.format(n, p1, p2, p3, p4)\n",
    "        ckpt_name = ckpt_pth+'.pth'\n",
    "\n",
    "        if cfg.LOCAL_RANK == 0:\n",
    "            model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "        logger.info('**********************End training**********************')\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        f = open(save_path+'result.txt', \"a+\")\n",
    "        f.write('----------------{}-{}-{}-{}---------------\\n'.format(p1, p2, p3, p4))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "        acc1, ret_dict = eval_utils.eval_simple(p1, p2, p3, p4, None, None, None, \n",
    "                                                n, cfg, model, test_loader, logger, \n",
    "                                                save_path, dist_test=dist_train, \n",
    "                                                save_to_file=args.save_to_file, \n",
    "                                                result_dir=eval_output_dir)\n",
    "        print(\"----------\")\n",
    "        print(acc1)\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "        logger.info('**********************End evaluation**********************')\n",
    "\n",
    "        return acc1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.cuda.set_device(0)\n",
    "    # best_accu = 0\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    if args.launcher == 'none':\n",
    "        dist_train = False\n",
    "        total_gpus = 1\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "        memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "        print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "        os.system('rm tmp')\n",
    "    else:\n",
    "        total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "            args.tcp_port, args.local_rank, backend='nccl'\n",
    "        )\n",
    "        dist_train = True\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = './save_path/multinomial/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    file = open(save_path+'result.txt','w')\n",
    "    file.write('results\\n')\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    if dist_train:\n",
    "        logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info('{:16} {}'.format(key, val))\n",
    "    log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "    tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "    \n",
    "    print(\"=============\")\n",
    "    \n",
    "    p1 = 0.23\n",
    "    p2 = 0.14\n",
    "    p3 = 0.68\n",
    "    p4 = 0.36\n",
    "    \n",
    "    print(p1, p2, p3, p4)\n",
    "    print(\"=============\")\n",
    "    \n",
    "\n",
    "    '''Bayesian Training'''\n",
    "    bayes_train = False\n",
    "    if bayes_train:\n",
    "        logger.info('----------------Start Bayes Optimization----------------')\n",
    "        for f_name in os.listdir('hardware_noise'):\n",
    "\n",
    "            opt= Opt(file)\n",
    "            opt_function = opt.opt_function\n",
    "\n",
    "            # Bounded region of parameter space\n",
    "            pbounds = {'pp1': (0.1, 0.9), 'pp2': (0.1, 0.9), 'pp3': (0.1, 0.9), 'pp4': (0.1, 0.9)}\n",
    "\n",
    "\n",
    "            optimizer_bayes = BayesianOptimization(\n",
    "                f=opt_function,\n",
    "                pbounds=pbounds,\n",
    "                verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "                random_state=1,\n",
    "            )\n",
    "            optimizer_bayes.probe(\n",
    "                params={'pp1': 0.11, 'pp2': 0.11, 'pp3': 0.11, 'pp4': 0.11},\n",
    "                lazy=True,\n",
    "            )\n",
    "\n",
    "            logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "            optimizer_bayes.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "\n",
    "            n = 0\n",
    "            optimizer_bayes.maximize(\n",
    "                init_points=3,\n",
    "                n_iter=80,\n",
    "            )\n",
    "        logger.info('----------------End Bayes Optimization----------------')\n",
    "            \n",
    "            \n",
    "    '''Test on Noises'''\n",
    "\n",
    "    \n",
    "    logger.info('**********************Start evaluation**********************')    \n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "                                    dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                    class_names=cfg.CLASS_NAMES,\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, p3=0.11, p4=0.11, dataset=test_set)\n",
    "    model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "    \n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    # ckpt_pth = save_path+'bayes_model-{}-{}-{}-{}'.format(p1, p2, p3, p4)\n",
    "    # ckpt_name = ckpt_pth+'.pth'\n",
    "    # model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    file2usability = np.load('./hardware_noise/file2usability.npy', allow_pickle=True).item()\n",
    "    file2sigma = np.load('./hardware_noise/file2sigma.npy', allow_pickle=True).item()\n",
    "    \n",
    "    # hw_data_files = sorted(os.listdir('./hardware_noise/hardware_data/'))\n",
    "    file2ap_dict = {}\n",
    "    N = 1\n",
    "    \n",
    "    for sigma, f_name in sorted(zip(file2sigma.values(), file2sigma.keys())):\n",
    "        print(sigma, f_name)\n",
    "        usability = file2usability[f_name]\n",
    "    # for f_name in sorted(hw_data_files):\n",
    "        if f_name.endswith('xlsx'):\n",
    "            file2ap_dict[f_name] = {}\n",
    "            # print(f_name)\n",
    "            for n in range(N):\n",
    "                print('file:{}, evaluate-{}'.format(f_name, n))\n",
    "                model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "                add_noise_to_weights('./hardware_noise/hardware_data/'+f_name, model, device='cuda')\n",
    "                \n",
    "                usability = file2usability[f_name]\n",
    "                sigma = file2sigma[f_name]\n",
    "                \n",
    "                acc1, ret_dict = eval_utils.eval_simple(p1, p2, p3, p4, f_name, usability, sigma, n, cfg, model, test_loader, logger, save_path=None, dist_test=dist_train,\n",
    "                                                save_to_file=args.save_to_file, result_dir=eval_output_dir\n",
    "                                            )                \n",
    "                print(ret_dict)\n",
    "                file2ap_dict[f_name][n] = ret_dict\n",
    "                \n",
    "                \n",
    "\n",
    "    logger.info('**********************End evaluation**********************')    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(\"=======end========\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f2369-934c-402c-80a5-745c8c819199",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.448390Z",
     "iopub.status.idle": "2023-07-07T01:53:23.448614Z",
     "shell.execute_reply": "2023-07-07T01:53:23.448521Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.448512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(zip(file2sigma.values(), file2sigma.keys()))[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c6615-77f4-476e-b283-60705d07a6f6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.449799Z",
     "iopub.status.idle": "2023-07-07T01:53:23.449975Z",
     "shell.execute_reply": "2023-07-07T01:53:23.449899Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.449891Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02f08a-c421-4f86-89fc-10fbc63963ad",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.451084Z",
     "iopub.status.idle": "2023-07-07T01:53:23.451259Z",
     "shell.execute_reply": "2023-07-07T01:53:23.451176Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.451169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fa9cb-c24c-4897-9f3e-8abc14e9083f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.452383Z",
     "iopub.status.idle": "2023-07-07T01:53:23.452560Z",
     "shell.execute_reply": "2023-07-07T01:53:23.452488Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.452480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python setup.py develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95292c-a1c8-4cf6-9f2e-bf3ad2f6081b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.453374Z",
     "iopub.status.idle": "2023-07-07T01:53:23.453747Z",
     "shell.execute_reply": "2023-07-07T01:53:23.453661Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.453652Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577ae2f-680a-4d4d-9911-fe35c6c97709",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T01:53:23.454139Z",
     "iopub.status.idle": "2023-07-07T01:53:23.454320Z",
     "shell.execute_reply": "2023-07-07T01:53:23.454244Z",
     "shell.execute_reply.started": "2023-07-07T01:53:23.454236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ../output/cfgs/kitti_models/bayes/default/ckpt/checkpoint_epoch_33.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
