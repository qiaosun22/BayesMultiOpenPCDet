{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebc1e65-310e-4213-933c-1687238b19a4",
   "metadata": {},
   "source": [
    "检查 gap 产生的原因\n",
    "\n",
    "Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dccef7d-d27c-490c-847f-741a53e85e3f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-23T00:13:57.122016Z",
     "iopub.status.busy": "2023-07-23T00:13:57.121570Z",
     "iopub.status.idle": "2023-07-23T00:14:03.124410Z",
     "shell.execute_reply": "2023-07-23T00:14:03.123348Z",
     "shell.execute_reply.started": "2023-07-23T00:13:57.121997Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "\n",
    "\n",
    "from hardware_noise.weight_mapping_finalv import weight_mapping as add_noise_to_weights\n",
    "# from hardware_noise.weight_mapping_finalv import weight_mapping_sigma_only as add_noise_to_weights\n",
    "from eval_utils import eval_utils_multinomial_finalv_half as eval_utils\n",
    "from pcdet.models_multinomial_half import build_network\n",
    "\n",
    "\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model, model_save\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', \\\n",
    "                        help='specify the config for training')\n",
    "    # sunqiao/OpenPCDet/tools/cfgs/kitti_models/pointpillar_bayes.yaml\n",
    "    parser.add_argument('--batch_size', type=int, default=None, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=None, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=32, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    \n",
    "    # ./checkpoint_epoch_80.pth\n",
    "    # checkpoint_epoch_33_multinomial\n",
    "    # ./checkpoint_epoch_80_bayes.pth\n",
    "    \n",
    "    parser.add_argument('--pretrained_model', type=str, default=True, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=81, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "    \n",
    "    parser.add_argument('--ckpt', type=str, default='./save_path/0722/ckpt_epoch84.pth', help='checkpoint to start from')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c95292c-a1c8-4cf6-9f2e-bf3ad2f6081b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-23T00:14:13.119241Z",
     "iopub.status.busy": "2023-07-23T00:14:13.119006Z",
     "iopub.status.idle": "2023-07-23T00:14:18.536063Z",
     "shell.execute_reply": "2023-07-23T00:14:18.535420Z",
     "shell.execute_reply.started": "2023-07-23T00:14:13.119223Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 08:14:13,198   INFO  Loading KITTI dataset\n",
      "2023-07-23 08:14:13,286   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n",
      "0.5766 0.8603 0.5753\n",
      "1.3700022894417224e-16 I-V_data_1.5um_length_5nm_diameter_NA_third_etch_8min_Pb_ED_3h_180C_MAI_no_150nm_Ag_memory_6V_carbon_paste.xlsx\n",
      "I-V_data_1.5um_length_5nm_diameter_NA_third_etch_8min_Pb_ED_3h_180C_MAI_no_150nm_Ag_memory_6V_carbon_paste.xlsx\n",
      "file:I-V_data_1.5um_length_5nm_diameter_NA_third_etch_8min_Pb_ED_3h_180C_MAI_no_150nm_Ag_memory_6V_carbon_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:   0%|          | 0/943 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 116\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, evaluate-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f_name, n))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# add_noise_to_weights('./hardware_noise/data_added0709/'+f_name, model, device='cuda')\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# acc1 = eval_utils.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m acc1, ret_dict \u001b[38;5;241m=\u001b[39m \u001b[43meval_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(ret_dict)\n\u001b[1;32m    121\u001b[0m file2ap_dict[f_name][n] \u001b[38;5;241m=\u001b[39m ret_dict \n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/tools/eval_utils/eval_utils_multinomial_finalv_half.py:127\u001b[0m, in \u001b[0;36meval_simple\u001b[0;34m(p1, p2, p3, file, usability, sigma, n, cfg, model, dataloader, logger, save_path, dist_test, save_to_file, result_dir)\u001b[0m\n\u001b[1;32m    125\u001b[0m         progress_bar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m, dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#     start_time = time.time()\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    128\u001b[0m         load_data_to_gpu(batch_dict)\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    if args.launcher == 'none':\n",
    "        dist_train = False\n",
    "        total_gpus = 1\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "        memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "        print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "        os.system('rm tmp')\n",
    "    else:\n",
    "        total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "            args.tcp_port, args.local_rank, backend='nccl'\n",
    "        )\n",
    "        dist_train = True\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = './save_path/multinomial/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    file = open(save_path+'result.txt','w')\n",
    "    file.write('results\\n')\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    # if dist_train:\n",
    "    #     logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    # for key, val in vars(args).items():\n",
    "    #     logger.info('{:16} {}'.format(key, val))\n",
    "    # log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "    \n",
    "    p1 = 0.5766#0.23\n",
    "    p2 = 0.8603#0.77\n",
    "    p3 = 0.5753#0.68\n",
    "    \t\t\n",
    "    \n",
    "    print(p1, p2, p3)\n",
    "    \n",
    "\n",
    "    '''Test on Noises'''  \n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "                                    dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                    class_names=cfg.CLASS_NAMES,\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=p1, p2=p2, p3=p3, dataset=test_set)\n",
    "    # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "    filename = args.ckpt\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    model.cuda()\n",
    "    \n",
    "    \n",
    "    # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "    # # acc1 = eval_utils.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "    # acc1, ret_dict = eval_utils.eval_simple(p1, p2, p3, f_name, usability, sigma, \n",
    "    #                 n, cfg, model, test_loader, logger, \n",
    "    #                 save_path, dist_test=False,\n",
    "    #                 save_to_file=False, result_dir=save_path)\n",
    "\n",
    "\n",
    "    \n",
    "    file2usability = np.load('./hardware_noise/file2usability.npy', allow_pickle=True).item()\n",
    "    file2sigma = np.load('./hardware_noise/file2sigma.npy', allow_pickle=True).item()\n",
    "    \n",
    "    # hw_data_files = sorted(os.listdir('./hardware_noise/hardware_data/'))\n",
    "    file2ap_dict = {}\n",
    "    N = 1\n",
    "    \n",
    "    for sigma, f_name in sorted(zip(file2sigma.values(), file2sigma.keys())):\n",
    "        print(sigma, f_name)\n",
    "        usability = file2usability[f_name]\n",
    "        if f_name.endswith('xlsx'):\n",
    "            file2ap_dict[f_name] = {}\n",
    "            print(f_name)\n",
    "            for n in range(N):\n",
    "                print('file:{}, evaluate-{}'.format(f_name, n))\n",
    "                # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "                # add_noise_to_weights('./hardware_noise/data_added0709/'+f_name, model, device='cuda')\n",
    "\n",
    "                # acc1 = eval_utils.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "                acc1, ret_dict = eval_utils.eval_simple(p1, p2, p3, f_name, usability, sigma, \n",
    "                                n, cfg, model, test_loader, logger, \n",
    "                                save_path, dist_test=False,\n",
    "                                save_to_file=False, result_dir=save_path)\n",
    "                print(ret_dict)\n",
    "                file2ap_dict[f_name][n] = ret_dict \n",
    "        break\n",
    "    print(ret_dict)\n",
    "    \n",
    "    print(acc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6cbeba-cebc-4ec7-b557-0a63653fc2d7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-23T00:17:32.855973Z",
     "iopub.status.busy": "2023-07-23T00:17:32.855605Z",
     "iopub.status.idle": "2023-07-23T00:17:32.861070Z",
     "shell.execute_reply": "2023-07-23T00:17:32.860555Z",
     "shell.execute_reply.started": "2023-07-23T00:17:32.855953Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pcdet.models_multinomial_half.dense_heads.anchor_head_single.AnchorHeadSingle"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pcdet\n",
    "pcdet.models_multinomial_half.dense_heads.anchor_head_single.AnchorHeadSingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fb6f6d-0891-48e9-9cf1-f7f6e54d0f26",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-07-23T00:17:57.005391Z",
     "iopub.status.busy": "2023-07-23T00:17:57.005005Z",
     "iopub.status.idle": "2023-07-23T00:17:57.008853Z",
     "shell.execute_reply": "2023-07-23T00:17:57.008423Z",
     "shell.execute_reply.started": "2023-07-23T00:17:57.005362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnchorHeadSingle(\n",
      "  (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "  (reg_loss_func): WeightedSmoothL1Loss()\n",
      "  (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "  (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for m in model.modules():\n",
    "    \n",
    "    if not isinstance(m, pcdet.models_multinomial_half.dense_heads.anchor_head_single.AnchorHeadSingle):\n",
    "        # m.eval()\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe3b1d8-bb0c-43ab-9c82-fab11e731802",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.604446Z",
     "iopub.status.busy": "2023-07-22T23:28:49.604225Z",
     "iopub.status.idle": "2023-07-22T23:28:49.609169Z",
     "shell.execute_reply": "2023-07-22T23:28:49.608682Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.604429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PillarVFE(\n",
      "  (pfn_layers): ModuleList(\n",
      "    (0): PFNLayer(\n",
      "      (linear): Linear(in_features=10, out_features=64, bias=False)\n",
      "      (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (do): Dropout()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "PointPillarScatter()\n",
      "BaseBEVBackbone(\n",
      "  (blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ZeroPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): Dropout2d(p=0.68, inplace=False)\n",
      "      (4): ReLU()\n",
      "      (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (7): Dropout2d(p=0.68, inplace=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (11): Dropout2d(p=0.68, inplace=False)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): Dropout2d(p=0.68, inplace=False)\n",
      "      (16): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ZeroPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): Dropout2d(p=0.68, inplace=False)\n",
      "      (4): ReLU()\n",
      "      (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (7): Dropout2d(p=0.68, inplace=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (11): Dropout2d(p=0.68, inplace=False)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): Dropout2d(p=0.68, inplace=False)\n",
      "      (16): ReLU()\n",
      "      (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (19): Dropout2d(p=0.68, inplace=False)\n",
      "      (20): ReLU()\n",
      "      (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (23): Dropout2d(p=0.68, inplace=False)\n",
      "      (24): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ZeroPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): Dropout2d(p=0.68, inplace=False)\n",
      "      (4): ReLU()\n",
      "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (7): Dropout2d(p=0.68, inplace=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (11): Dropout2d(p=0.68, inplace=False)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): Dropout2d(p=0.68, inplace=False)\n",
      "      (16): ReLU()\n",
      "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (19): Dropout2d(p=0.68, inplace=False)\n",
      "      (20): ReLU()\n",
      "      (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (23): Dropout2d(p=0.68, inplace=False)\n",
      "      (24): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deblocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Dropout2d(p=0.68, inplace=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Dropout2d(p=0.68, inplace=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Dropout2d(p=0.68, inplace=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "AnchorHeadSingle(\n",
      "  (cls_loss_func): SigmoidFocalClassificationLoss()\n",
      "  (reg_loss_func): WeightedSmoothL1Loss()\n",
      "  (dir_loss_func): WeightedCrossEntropyLoss()\n",
      "  (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in model.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f40fa83-32a4-4edf-b33c-b24434bf0752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.610685Z",
     "iopub.status.busy": "2023-07-22T23:28:49.610521Z",
     "iopub.status.idle": "2023-07-22T23:28:49.617583Z",
     "shell.execute_reply": "2023-07-22T23:28:49.616564Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.610671Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-V_data_1.5um_length_5nm_diameter_NA_third_etch_8min_Pb_ED_3h_180C_MAI_no_150nm_Ag_memory_6V_carbon_paste.xlsx': {0: {'recall/roi_0.3': 0.0,\n",
       "   'recall/rcnn_0.3': 0.0,\n",
       "   'recall/roi_0.5': 0.0,\n",
       "   'recall/rcnn_0.5': 0.0,\n",
       "   'recall/roi_0.7': 0.0,\n",
       "   'recall/rcnn_0.7': 0.0,\n",
       "   'Car_aos/easy_R40': 38.73328356097765,\n",
       "   'Car_aos/moderate_R40': 28.962580653971198,\n",
       "   'Car_aos/hard_R40': 25.30128171470711,\n",
       "   'Car_3d/easy_R40': 11.1927508397362,\n",
       "   'Car_3d/moderate_R40': 9.524271464018538,\n",
       "   'Car_3d/hard_R40': 8.75336346291666,\n",
       "   'Car_bev/easy_R40': 50.88217054169959,\n",
       "   'Car_bev/moderate_R40': 41.991459241836495,\n",
       "   'Car_bev/hard_R40': 37.19775651672036,\n",
       "   'Car_image/easy_R40': 60.580134260455296,\n",
       "   'Car_image/moderate_R40': 45.61542854733045,\n",
       "   'Car_image/hard_R40': 41.04671019625883,\n",
       "   'Pedestrian_aos/easy_R40': 7.507676442421015,\n",
       "   'Pedestrian_aos/moderate_R40': 6.448257676024667,\n",
       "   'Pedestrian_aos/hard_R40': 6.156978546708869,\n",
       "   'Pedestrian_3d/easy_R40': 8.259125979275836,\n",
       "   'Pedestrian_3d/moderate_R40': 6.995355985995076,\n",
       "   'Pedestrian_3d/hard_R40': 6.494145948346134,\n",
       "   'Pedestrian_bev/easy_R40': 14.642277172774099,\n",
       "   'Pedestrian_bev/moderate_R40': 12.850540701543922,\n",
       "   'Pedestrian_bev/hard_R40': 12.305497012196653,\n",
       "   'Pedestrian_image/easy_R40': 13.781821204697009,\n",
       "   'Pedestrian_image/moderate_R40': 11.658145412560978,\n",
       "   'Pedestrian_image/hard_R40': 11.144997435612343,\n",
       "   'Cyclist_aos/easy_R40': 0.3778209254057053,\n",
       "   'Cyclist_aos/moderate_R40': 0.17086213890396443,\n",
       "   'Cyclist_aos/hard_R40': 0.17967676848919245,\n",
       "   'Cyclist_3d/easy_R40': 1.0138026021206654,\n",
       "   'Cyclist_3d/moderate_R40': 0.3431878531083699,\n",
       "   'Cyclist_3d/hard_R40': 0.33574255398820635,\n",
       "   'Cyclist_bev/easy_R40': 1.292131634529983,\n",
       "   'Cyclist_bev/moderate_R40': 0.5801286148364059,\n",
       "   'Cyclist_bev/hard_R40': 0.512763356078067,\n",
       "   'Cyclist_image/easy_R40': 1.6059784002494224,\n",
       "   'Cyclist_image/moderate_R40': 0.7276204297067659,\n",
       "   'Cyclist_image/hard_R40': 0.6836035102667862}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287009d4-d087-4ae8-b66f-244b74f09055",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.618470Z",
     "iopub.status.busy": "2023-07-22T23:28:49.618323Z",
     "iopub.status.idle": "2023-07-22T23:28:49.622436Z",
     "shell.execute_reply": "2023-07-22T23:28:49.621945Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.618458Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointPillar(\n",
       "  (vfe): PillarVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayer(\n",
       "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (do): Dropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter()\n",
       "  (backbone_2d): BaseBEVBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (19): Dropout2d(p=0.68, inplace=False)\n",
       "        (20): ReLU()\n",
       "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (23): Dropout2d(p=0.68, inplace=False)\n",
       "        (24): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (19): Dropout2d(p=0.68, inplace=False)\n",
       "        (20): ReLU()\n",
       "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (23): Dropout2d(p=0.68, inplace=False)\n",
       "        (24): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): AnchorHeadSingle(\n",
       "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
       "    (reg_loss_func): WeightedSmoothL1Loss()\n",
       "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
       "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bc8ec6-8afa-41e3-a2b3-adfff1ead862",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.623135Z",
     "iopub.status.busy": "2023-07-22T23:28:49.622998Z",
     "iopub.status.idle": "2023-07-22T23:28:49.627397Z",
     "shell.execute_reply": "2023-07-22T23:28:49.626473Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.623124Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7fd5041554a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05187c6-bbab-4c25-a04f-183e99d8ce83",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.628001Z",
     "iopub.status.busy": "2023-07-22T23:28:49.627868Z",
     "iopub.status.idle": "2023-07-22T23:28:49.657525Z",
     "shell.execute_reply": "2023-07-22T23:28:49.656543Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.627990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointPillar(\n",
       "  (vfe): PillarVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayer(\n",
       "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (do): Dropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter()\n",
       "  (backbone_2d): BaseBEVBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "        (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (18): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (19): Dropout2d(p=0.68, inplace=False)\n",
       "        (20): ReLU()\n",
       "        (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (22): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (23): Dropout2d(p=0.68, inplace=False)\n",
       "        (24): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ZeroPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): Dropout2d(p=0.68, inplace=False)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (7): Dropout2d(p=0.68, inplace=False)\n",
       "        (8): ReLU()\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): Dropout2d(p=0.68, inplace=False)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): Dropout2d(p=0.68, inplace=False)\n",
       "        (16): ReLU()\n",
       "        (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (18): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (19): Dropout2d(p=0.68, inplace=False)\n",
       "        (20): ReLU()\n",
       "        (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (22): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (23): Dropout2d(p=0.68, inplace=False)\n",
       "        (24): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Dropout2d(p=0.68, inplace=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): AnchorHeadSingle(\n",
       "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
       "    (reg_loss_func): WeightedSmoothL1Loss()\n",
       "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
       "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_bn(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        m.eval()\n",
    "\n",
    "# model = models.resnet50(pretrained=True)\n",
    "model.cuda()\n",
    "model.train()\n",
    "model.apply(fix_bn)  # fix batchnorm\n",
    "# ————————————————\n",
    "# 版权声明：本文为CSDN博主「柠檬不喝橙汁」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "# 原文链接：https://blog.csdn.net/qq_42785704/article/details/123263635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514a1ffb-109b-4a8b-83f3-de4002a930f2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.658207Z",
     "iopub.status.busy": "2023-07-22T23:28:49.658066Z",
     "iopub.status.idle": "2023-07-22T23:28:49.661316Z",
     "shell.execute_reply": "2023-07-22T23:28:49.660797Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.658195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vfe.pfn_layers.0.linear.weight\n",
      "vfe.pfn_layers.0.norm.weight\n",
      "vfe.pfn_layers.0.norm.bias\n",
      "backbone_2d.blocks.0.1.weight\n",
      "backbone_2d.blocks.0.2.weight\n",
      "backbone_2d.blocks.0.2.bias\n",
      "backbone_2d.blocks.0.5.weight\n",
      "backbone_2d.blocks.0.6.weight\n",
      "backbone_2d.blocks.0.6.bias\n",
      "backbone_2d.blocks.0.9.weight\n",
      "backbone_2d.blocks.0.10.weight\n",
      "backbone_2d.blocks.0.10.bias\n",
      "backbone_2d.blocks.0.13.weight\n",
      "backbone_2d.blocks.0.14.weight\n",
      "backbone_2d.blocks.0.14.bias\n",
      "backbone_2d.blocks.1.1.weight\n",
      "backbone_2d.blocks.1.2.weight\n",
      "backbone_2d.blocks.1.2.bias\n",
      "backbone_2d.blocks.1.5.weight\n",
      "backbone_2d.blocks.1.6.weight\n",
      "backbone_2d.blocks.1.6.bias\n",
      "backbone_2d.blocks.1.9.weight\n",
      "backbone_2d.blocks.1.10.weight\n",
      "backbone_2d.blocks.1.10.bias\n",
      "backbone_2d.blocks.1.13.weight\n",
      "backbone_2d.blocks.1.14.weight\n",
      "backbone_2d.blocks.1.14.bias\n",
      "backbone_2d.blocks.1.17.weight\n",
      "backbone_2d.blocks.1.18.weight\n",
      "backbone_2d.blocks.1.18.bias\n",
      "backbone_2d.blocks.1.21.weight\n",
      "backbone_2d.blocks.1.22.weight\n",
      "backbone_2d.blocks.1.22.bias\n",
      "backbone_2d.blocks.2.1.weight\n",
      "backbone_2d.blocks.2.2.weight\n",
      "backbone_2d.blocks.2.2.bias\n",
      "backbone_2d.blocks.2.5.weight\n",
      "backbone_2d.blocks.2.6.weight\n",
      "backbone_2d.blocks.2.6.bias\n",
      "backbone_2d.blocks.2.9.weight\n",
      "backbone_2d.blocks.2.10.weight\n",
      "backbone_2d.blocks.2.10.bias\n",
      "backbone_2d.blocks.2.13.weight\n",
      "backbone_2d.blocks.2.14.weight\n",
      "backbone_2d.blocks.2.14.bias\n",
      "backbone_2d.blocks.2.17.weight\n",
      "backbone_2d.blocks.2.18.weight\n",
      "backbone_2d.blocks.2.18.bias\n",
      "backbone_2d.blocks.2.21.weight\n",
      "backbone_2d.blocks.2.22.weight\n",
      "backbone_2d.blocks.2.22.bias\n",
      "backbone_2d.deblocks.0.0.weight\n",
      "backbone_2d.deblocks.0.1.weight\n",
      "backbone_2d.deblocks.0.1.bias\n",
      "backbone_2d.deblocks.1.0.weight\n",
      "backbone_2d.deblocks.1.1.weight\n",
      "backbone_2d.deblocks.1.1.bias\n",
      "backbone_2d.deblocks.2.0.weight\n",
      "backbone_2d.deblocks.2.1.weight\n",
      "backbone_2d.deblocks.2.1.bias\n",
      "dense_head.conv_cls.weight\n",
      "dense_head.conv_cls.bias\n",
      "dense_head.conv_box.weight\n",
      "dense_head.conv_box.bias\n",
      "dense_head.conv_dir_cls.weight\n",
      "dense_head.conv_dir_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name,params in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba1a4d0-8782-46c7-87fe-246982e6606e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.662071Z",
     "iopub.status.busy": "2023-07-22T23:28:49.661932Z",
     "iopub.status.idle": "2023-07-22T23:28:49.665433Z",
     "shell.execute_reply": "2023-07-22T23:28:49.664916Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.662060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for m in model.modules():\n",
    "    if isinstance(m,nn.BatchNorm2d):\n",
    "        print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ffb33b-9774-457b-be70-84d1e4332657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.666963Z",
     "iopub.status.busy": "2023-07-22T23:28:49.666815Z",
     "iopub.status.idle": "2023-07-22T23:28:49.676065Z",
     "shell.execute_reply": "2023-07-22T23:28:49.675621Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.666952Z"
    }
   },
   "outputs": [],
   "source": [
    "# class Opt():\n",
    "#     def __init__(self, sigma):\n",
    "#         self.sigma = sigma\n",
    "        \n",
    "#     def opt_function(self, p1, p2):\n",
    "\n",
    "#         print(\"=============\")\n",
    "#         print(p1, p2)\n",
    "#         print(\"=============\")\n",
    "\n",
    "#         global best_accu\n",
    "\n",
    "#         # p1 = round(p1, 2)\n",
    "#         # p2 = round(p2, 2)\n",
    "\n",
    "#         # train_set, train_loader, train_sampler = build_dataloader(\n",
    "#         #     dataset_cfg=cfg.DATA_CONFIG,\n",
    "#         #     class_names=cfg.CLASS_NAMES,\n",
    "#         #     batch_size=args.batch_size,\n",
    "#         #     dist=dist_train, workers=args.workers,\n",
    "#         #     logger=logger,\n",
    "#         #     training=True,\n",
    "#         #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "#         #     total_epochs=args.epochs\n",
    "#         # )\n",
    "\n",
    "#         # model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "#         #                     p1=p1, \n",
    "#         #                     p2=p2, \n",
    "#         #                     dataset=train_set)\n",
    "#         # print(model.state_dict())\n",
    "#         # print(\"???????????\")\n",
    "\n",
    "#     #     if args.sync_bn:\n",
    "#     #         model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "#     #     model.cuda()\n",
    "\n",
    "#         # optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "#     #     # # load checkpoint if it is possible\n",
    "#     #     start_epoch = it = 0\n",
    "#     #     last_epoch = -1\n",
    "#     #     if args.pretrained_model is True:\n",
    "#     #         model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "#     #     # if args.ckpt is not None:\n",
    "#     #     #     it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "#     #     #     last_epoch = start_epoch + 1\n",
    "#     #     # else:\n",
    "#     #     #     ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "#     #     #     if len(ckpt_list) > 0:\n",
    "#     #     #         ckpt_list.sort(key=os.path.getmtime)\n",
    "#     #     #         it, start_epoch = model.load_params_with_optimizer(\n",
    "#     #     #             ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "#     #     #         )\n",
    "#     #     #         last_epoch = start_epoch + 1\n",
    "\n",
    "#     #     model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "#     #     if dist_train:\n",
    "#     #         model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "#     #     logger.info(model)\n",
    "\n",
    "#     #     lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "#     #         optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "#     #         last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "#     #     )\n",
    "\n",
    "#     # #     # -----------------------start training---------------------------\n",
    "#     #     logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "#     #                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "#         # train_model(\n",
    "#         #     model,\n",
    "#         #     optimizer,\n",
    "#         #     train_loader,\n",
    "#         #     model_func=model_fn_decorator(),\n",
    "#         #     lr_scheduler=lr_scheduler,\n",
    "#         #     optim_cfg=cfg.OPTIMIZATION,\n",
    "#         #     start_epoch=start_epoch,\n",
    "#         #     total_epochs=args.epochs,\n",
    "#         #     start_iter=it,\n",
    "#         #     rank=cfg.LOCAL_RANK,\n",
    "#         #     tb_log=tb_log,\n",
    "#         #     ckpt_save_dir=ckpt_dir,\n",
    "#         #     train_sampler=train_sampler,\n",
    "#         #     lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "#         #     ckpt_save_interval=args.ckpt_save_interval,\n",
    "#         #     max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "#         #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "#         # )\n",
    "\n",
    "#         test_set, test_loader, sampler = build_dataloader(\n",
    "#                                         dataset_cfg=cfg.DATA_CONFIG,\n",
    "#                                         class_names=cfg.CLASS_NAMES,\n",
    "#                                         batch_size=args.batch_size,\n",
    "#                                         dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "#                                     )\n",
    "\n",
    "\n",
    "#         model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, dataset=test_set)\n",
    "\n",
    "#         optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "#         if dist_train: \n",
    "#             model = model.module\n",
    "\n",
    "#         if args.pretrained_model is True:\n",
    "#             model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "#         # model.load_params_from_file(filename='./checkpoint_epoch_80.pth', logger=logger, to_cpu=dist_train)\n",
    "#         model.cuda()\n",
    "\n",
    "#         ckpt_pth = save_path+'bayes_model-{}-{}'.format(p1,p2)\n",
    "#         ckpt_name = ckpt_pth+'.pth'\n",
    "\n",
    "#         if cfg.LOCAL_RANK == 0:\n",
    "#             model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "#         logger.info('**********************End training**********************')\n",
    "\n",
    "#         time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "#         # if dist_train: \n",
    "#         #     model = model.module\n",
    "\n",
    "#         sigma = self.sigma\n",
    "#         f = open(save_path+'result.txt', \"a+\")\n",
    "#         # f.write('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "#         f.write('----------------{}-{}----------------\\n'.format(p1,p2))\n",
    "#         f.close()\n",
    "\n",
    "#         logger.info('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "#         # model.load_params_from_file(filename=ckpt_name, logger=logger, to_cpu=dist_train)\n",
    "#         # model.cuda()\n",
    "#         model = add_noise_to_weights(0, sigma, model)\n",
    "#         global n\n",
    "#         n += 1\n",
    "\n",
    "#         acc1 = eval_utils_bayes.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "#         print(\"----------\")\n",
    "#         print(acc1)\n",
    "#         print(\"----------\")\n",
    "\n",
    "\n",
    "#         logger.info('**********************End evaluation**********************')\n",
    "\n",
    "#             # best_accu = acc\n",
    "\n",
    "#         return acc1  #+acc2+acc3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "\n",
    "# #     torch.cuda.set_device(0)\n",
    "# #     # best_accu = 0\n",
    "\n",
    "# #     args, cfg = parse_config()\n",
    "# #     if args.launcher == 'none':\n",
    "# #         dist_train = False\n",
    "# #         total_gpus = 1\n",
    "# #         os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# #         os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "# #         memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "# #         print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "# #         os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "# #         os.system('rm tmp')\n",
    "# #     else:\n",
    "# #         total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "# #             args.tcp_port, args.local_rank, backend='nccl'\n",
    "# #         )\n",
    "# #         dist_train = True\n",
    "\n",
    "# #     if args.batch_size is None:\n",
    "# #         args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "# #     else:\n",
    "# #         assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "# #         args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "# #     args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "# #     if args.fix_random_seed:\n",
    "# #         common_utils.set_random_seed(666)\n",
    "\n",
    "# #     output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "# #     ckpt_dir = output_dir / 'ckpt'\n",
    "# #     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# #     ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# #     save_path = './save_path/bayes/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "# #     if not os.path.exists(save_path):\n",
    "# #         os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "# #     logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "# #     file = open(save_path+'result.txt','w')\n",
    "# #     file.write('results\\n')\n",
    "# #     file.close()\n",
    "\n",
    "# #     # head = ''\n",
    "# #     # logging.basicConfig(filename='./baseline/pointpillar/log.txt',\n",
    "# #     #                     format=head)\n",
    "# #     # logger_result = logging.getLogger()\n",
    "# #     # logger_result.setLevel(logging.INFO)\n",
    "# #     # console = logging.StreamHandler()\n",
    "# #     # logging.getLogger('').addHandler(console)\n",
    "\n",
    "# #     # log to file\n",
    "# #     logger.info('**********************Start logging**********************')\n",
    "# #     gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "# #     logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "# #     if dist_train:\n",
    "# #         logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "# #     for key, val in vars(args).items():\n",
    "# #         logger.info('{:16} {}'.format(key, val))\n",
    "# #     log_config_to_file(cfg, logger=logger)\n",
    "# #     if cfg.LOCAL_RANK == 0:\n",
    "# #         os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "# #     tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "# #     eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "# #     eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# #     args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # #     # -----------------------start training---------------------------\n",
    "# #     logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "# #                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "# #     print(ckpt_dir)\n",
    "# #     # ckpt_dir = './save_path/ckpts'\n",
    "\n",
    "# #     # train_model(\n",
    "# #     #     model,\n",
    "# #     #     optimizer,\n",
    "# #     #     train_loader,\n",
    "# #     #     model_func=model_fn_decorator(),\n",
    "# #     #     lr_scheduler=lr_scheduler,\n",
    "# #     #     optim_cfg=cfg.OPTIMIZATION,\n",
    "# #     #     start_epoch=start_epoch,\n",
    "# #     #     total_epochs=args.epochs,\n",
    "# #     #     start_iter=it,\n",
    "# #     #     rank=cfg.LOCAL_RANK,\n",
    "# #     #     tb_log=tb_log,\n",
    "# #     #     ckpt_save_dir=ckpt_dir,\n",
    "# #     #     train_sampler=train_sampler,\n",
    "# #     #     lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "# #     #     ckpt_save_interval=args.ckpt_save_interval,\n",
    "# #     #     max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "# #     #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "# #     # )\n",
    "\n",
    "# #     logger.info('----------------Bayes Optimization----------------')\n",
    "# #     for sigma in np.linspace(1e-31, 1.0, 21)[1: ]:\n",
    "\n",
    "# #         # opt_function(0.11, 0.11)\n",
    "# #         print(\"=============\")\n",
    "# #         p1 = 0.11\n",
    "# #         p2 = 0.11\n",
    "# #         print(p1, p2)\n",
    "# #         print(\"=============\")\n",
    "        \n",
    "# #         opt= Opt(sigma)\n",
    "# #         opt_function = opt.opt_function\n",
    "        \n",
    "# #         # Bounded region of parameter space\n",
    "# #         pbounds = {'p1': (0.1, 0.9), 'p2': (0.1, 0.9)}\n",
    "\n",
    "\n",
    "# #         optimizer_bayes = BayesianOptimization(\n",
    "# #             f=opt_function,\n",
    "# #             pbounds=pbounds,\n",
    "# #             verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "# #             random_state=1,\n",
    "# #         )\n",
    "# #         optimizer_bayes.probe(\n",
    "# #             params={'p1': 0.11, 'p2': 0.11},\n",
    "# #             lazy=True,\n",
    "# #         )\n",
    "\n",
    "# #         logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "# #         optimizer_bayes.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "\n",
    "\n",
    "# #         n = 0\n",
    "# #         optimizer_bayes.maximize(\n",
    "# #             init_points=3,\n",
    "# #             n_iter=10,\n",
    "# #         )\n",
    "# #     print(\"=======end========\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c6a85-7b77-488e-9f1b-2ebe3cd587c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9577ae2f-680a-4d4d-9911-fe35c6c97709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T23:28:49.676863Z",
     "iopub.status.busy": "2023-07-22T23:28:49.676720Z",
     "iopub.status.idle": "2023-07-22T23:28:49.679533Z",
     "shell.execute_reply": "2023-07-22T23:28:49.678558Z",
     "shell.execute_reply.started": "2023-07-22T23:28:49.676852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ../output/cfgs/kitti_models/bayes/default/ckpt/checkpoint_epoch_33.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f3975-23eb-48bc-a0ed-2a5abce74b7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
