{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dccef7d-d27c-490c-847f-741a53e85e3f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-20T14:05:24.594337Z",
     "iopub.status.busy": "2023-07-20T14:05:24.594179Z",
     "iopub.status.idle": "2023-07-20T14:05:24.763952Z",
     "shell.execute_reply": "2023-07-20T14:05:24.763231Z",
     "shell.execute_reply.started": "2023-07-20T14:05:24.594313Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 299\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# total_gpus = 1\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mfix_random_seed:\n\u001b[0;32m--> 299\u001b[0m     \u001b[43mcommon_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_random_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m666\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mROOT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m cfg\u001b[38;5;241m.\u001b[39mEXP_GROUP_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbayes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m args\u001b[38;5;241m.\u001b[39mextra_tag\n\u001b[1;32m    302\u001b[0m ckpt_dir \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/mnt/workspace/sunqiao/OpenPCDet/pcdet/utils/common_utils.py:123\u001b[0m, in \u001b[0;36mset_random_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    121\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m    122\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m--> 123\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m    125\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/cuda/random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    111\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 113\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/cuda/__init__.py:156\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 156\u001b[0m         \u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/torch/cuda/random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    110\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "from noise import add_noise_to_weights\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models_multinomial import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model, model_save\n",
    "from eval_utils import eval_utils_multinomial\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', \\\n",
    "                        help='specify the config for training')\n",
    "    # sunqiao/OpenPCDet/tools/cfgs/kitti_models/pointpillar_bayes.yaml\n",
    "    parser.add_argument('--batch_size', type=int, default=8, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=80, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=64, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='multinomial', help='extra tag for this experiment')\n",
    "    parser.add_argument('--ckpt', type=str, default='checkpoint_epoch_80_bayes.pth', \n",
    "                        help='checkpoint to start from')\n",
    "    \n",
    "    # ./checkpoint_epoch_80.pth\n",
    "    parser.add_argument('--pretrained_model', type=str, default=True, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=99999, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1: -1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg\n",
    "\n",
    "class Opt():\n",
    "    def __init__(self, train_set, train_loader, train_sampler, test_set, test_loader, sampler):\n",
    "        # self.sigma = sigma\n",
    "        # self.model = model\n",
    "        self.train_set = train_set\n",
    "        self.train_loader = train_loader\n",
    "        self.train_sampler = train_sampler\n",
    "        self.test_set = test_set\n",
    "        self.test_loader = test_loader\n",
    "        self.sampler = sampler\n",
    "        \n",
    "    def opt_function(self, p1, p2, p3):\n",
    "        \n",
    "        # sigma = self.sigma\n",
    "        # model = self.model\n",
    "#         train_set = self.train_set\n",
    "#         train_loader = self.train_loader\n",
    "#         train_sampler = self.train_sampler\n",
    "#         test_set = self.test_set\n",
    "#         test_loader = self.test_loader\n",
    "#         sampler = self.sampler\n",
    "        \n",
    "#         model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "#                             p1=p1, \n",
    "#                             p2=p2, \n",
    "#                             p3=p3,\n",
    "#                             dataset=train_set)\n",
    "#         model.cuda()\n",
    "        \n",
    "#         optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "#         model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "        \n",
    "        \n",
    "        global n\n",
    "        n += 1\n",
    "        \n",
    "        print(\"=============\")\n",
    "        print(p1, p2, p3)\n",
    "        print(\"=============\")\n",
    "\n",
    "        global best_accu\n",
    "\n",
    "        # p1 = round(p1, 2)\n",
    "        # p2 = round(p2, 2)\n",
    "\n",
    "#         train_set, train_loader, train_sampler = build_dataloader(\n",
    "#             dataset_cfg=cfg.DATA_CONFIG,\n",
    "#             class_names=cfg.CLASS_NAMES,\n",
    "#             batch_size=args.batch_size,\n",
    "#             dist=dist_train, workers=args.workers,\n",
    "#             logger=logger,\n",
    "#             training=True,\n",
    "#             merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "#             total_epochs=args.epochs\n",
    "#         )\n",
    "\n",
    "#         model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "#                             p1=p1, \n",
    "#                             p2=p2, \n",
    "#                             p3=p3,\n",
    "#                             dataset=train_set)\n",
    "#         model.cuda()\n",
    "        # print(model.state_dict())\n",
    "        # print(\"???????????\")\n",
    "\n",
    "        # if args.sync_bn:\n",
    "        #     model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "        \n",
    "\n",
    "        \n",
    "        # # load checkpoint if it is possible\n",
    "        start_epoch = it = 0\n",
    "        last_epoch = -1\n",
    "        # if args.pretrained_model is True:\n",
    "        #     model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "        # if args.ckpt is not None:\n",
    "            # it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "            # last_epoch = start_epoch + 1\n",
    "            \n",
    "            \n",
    "        # model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "        \n",
    "        \n",
    "        # else:\n",
    "        #     ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "        #     if len(ckpt_list) > 0:\n",
    "        #         ckpt_list.sort(key=os.path.getmtime)\n",
    "        #         it, start_epoch = model.load_params_with_optimizer(\n",
    "        #             ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "        #         )\n",
    "        #         last_epoch = start_epoch + 1\n",
    "\n",
    "        model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "        model.cuda()\n",
    "        # if dist_train:\n",
    "        #     model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "        # logger.info(model)\n",
    "\n",
    "        lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "            optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "            last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "        )\n",
    "\n",
    "        # -----------------------start training---------------------------\n",
    "        logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                    % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "        \n",
    "        output_dir = cfg.ROOT_DIR / 'tools' / 'save_path' / args.extra_tag\n",
    "        ckpt_dir = output_dir / 'ckpt'\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        # print(ckpt_dir)\n",
    "        # ckpt_dir = './save_path/ckpts'\n",
    "        print(ckpt_dir)\n",
    "\n",
    "        train_model(\n",
    "            model,\n",
    "            optimizer,\n",
    "            train_loader,\n",
    "            model_func=model_fn_decorator(),\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            optim_cfg=cfg.OPTIMIZATION,\n",
    "            start_epoch=start_epoch,\n",
    "            total_epochs=args.epochs,\n",
    "            start_iter=it,\n",
    "            rank=cfg.LOCAL_RANK,\n",
    "            tb_log=tb_log,\n",
    "            ckpt_save_dir=ckpt_dir,\n",
    "            train_sampler=train_sampler,\n",
    "            lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "            ckpt_save_interval=args.ckpt_save_interval,\n",
    "            max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "            merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.42, p2=0.23, p3=0.11, dataset=test_set)\n",
    "\n",
    "        # optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "        # if dist_train: \n",
    "        #     model = model.module\n",
    "\n",
    "        # if args.pretrained_model is True:\n",
    "        # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "        # model.load_params_from_file(filename='./checkpoint_epoch_80.pth', logger=logger, to_cpu=dist_train)\n",
    "        # model.cuda()\n",
    "\n",
    "        ckpt_pth = save_path+'bayes_model-{}-{}-{}'.format(p1, p2, p3)\n",
    "        ckpt_name = ckpt_pth+'.pth'\n",
    "\n",
    "        # if cfg.LOCAL_RANK == 0:\n",
    "        #     model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "        logger.info('**********************End training**********************')\n",
    "\n",
    "        # time.sleep(30)\n",
    "\n",
    "\n",
    "\n",
    "        # if dist_train: \n",
    "        #     model = model.module\n",
    "\n",
    "        # sigma = self.sigma\n",
    "        f = open(save_path+'result.txt', \"a+\")\n",
    "        # f.write('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "        f.write('----------------{}-{}-{}---------------\\n'.format(p1, p2, p3))\n",
    "        f.close()\n",
    "\n",
    "        # logger.info('---------------Epoch-{}-Noise-{}-evaluate----------------'.format(n, sigma))\n",
    "        # model.load_params_from_file(filename=ckpt_name, logger=logger, to_cpu=dist_train)\n",
    "        # model.cuda()\n",
    "        # model = add_noise_to_weights(0, sigma, model)\n",
    "\n",
    "\n",
    "        acc1 = eval_utils_multinomial.eval_simple(args.ckpt, p1, p2, p3, 0, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "        print(\"----------\")\n",
    "        print(acc1)\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "        logger.info('**********************End evaluation**********************')\n",
    "\n",
    "            # best_accu = acc\n",
    "\n",
    "        return acc1  #+acc2+acc3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    torch.cuda.set_device(0)            \n",
    "    # best_accu = 0\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    # if args.launcher == 'none':\n",
    "    dist_train = False\n",
    "    # total_gpus = 1\n",
    "    # os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    # os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    # memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    # print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "    # os.system('rm tmp')\n",
    "    # else:\n",
    "    #     total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "    #         args.tcp_port, args.local_rank, backend='nccl'\n",
    "    #     )\n",
    "    #     dist_train = True\n",
    "\n",
    "    # if args.batch_size is None:\n",
    "    #     args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    # else:\n",
    "    #     assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "    #     args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    # args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = './save_path/bayes/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    file = open(save_path+'result.txt','w')\n",
    "    file.write('results\\n')\n",
    "    file.close()\n",
    "\n",
    "    # head = ''\n",
    "    # logging.basicConfig(filename='./baseline/pointpillar/log.txt',\n",
    "    #                     format=head)\n",
    "    # logger_result = logging.getLogger()\n",
    "    # logger_result.setLevel(logging.INFO)\n",
    "    # console = logging.StreamHandler()\n",
    "    # logging.getLogger('').addHandler(console)\n",
    "\n",
    "    # log to file\n",
    "    logger.info('**********************Start logging**********************')\n",
    "    gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "    logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "    # if dist_train:\n",
    "    #     logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info('{:16} {}'.format(key, val))\n",
    "    log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "    tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "\n",
    "\n",
    "    train_set, train_loader, train_sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=dist_train, workers=args.workers,\n",
    "        logger=logger,\n",
    "        training=True,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "        total_epochs=args.epochs\n",
    "    )\n",
    "    \n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "                                    dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                    class_names=cfg.CLASS_NAMES,\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                )\n",
    "\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.23, p2=0.77, p3=0.68, dataset=train_set)\n",
    "    model.cuda()\n",
    "    # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "    # model.cuda()\n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "    \n",
    "    start_epoch = 0\n",
    "    it = 0\n",
    "    last_epoch = -1\n",
    "    \n",
    "    lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "    optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "    last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        model_func=model_fn_decorator(),\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        optim_cfg=cfg.OPTIMIZATION,\n",
    "        start_epoch=start_epoch,\n",
    "        total_epochs=args.epochs,\n",
    "        start_iter=it,\n",
    "        rank=cfg.LOCAL_RANK,\n",
    "        tb_log=tb_log,\n",
    "        ckpt_save_dir=ckpt_dir,\n",
    "        train_sampler=train_sampler,\n",
    "        lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "        ckpt_save_interval=args.ckpt_save_interval,\n",
    "        max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "    )\n",
    "\n",
    "    \n",
    "# #     # -----------------------start training---------------------------\n",
    "#     logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "#                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "\n",
    "#     logger.info('----------------Bayes Optimization----------------')\n",
    "#     for sigma in np.linspace(1e-31, 1.0, 21):\n",
    "\n",
    "#         # opt_function(0.11, 0.11)\n",
    "#         print(\"=============\")\n",
    "#         p1 = 0.42\n",
    "#         p2 = 0.23\n",
    "#         p3 = 0.11\n",
    "#         print(p1, p2, p3)\n",
    "#         print(\"=============\")\n",
    "        \n",
    "#         opt= Opt(sigma, train_set, train_loader, train_sampler, test_set, test_loader, sampler)\n",
    "#         opt_function = opt.opt_function\n",
    "        \n",
    "#         # Bounded region of parameter space\n",
    "#         pbounds = {'p1': (0.1, 0.9), 'p2': (0.1, 0.9), 'p3': (0.1, 0.9)}\n",
    "\n",
    "\n",
    "#         optimizer_bayes = BayesianOptimization(\n",
    "#             f=opt_function,\n",
    "#             pbounds=pbounds,\n",
    "#             verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "#             random_state=1,\n",
    "#         )\n",
    "#         optimizer_bayes.probe(\n",
    "#             params={'p1': 0.68, 'p2': 0.77, 'p3': 0.23},\n",
    "#             lazy=True,\n",
    "#         )\n",
    "\n",
    "#         logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "#         optimizer_bayes.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "\n",
    "\n",
    "#         n = 0\n",
    "#         optimizer_bayes.maximize(\n",
    "#             init_points=3,\n",
    "#             n_iter=1,\n",
    "#         )\n",
    "#     print(\"=======end========\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da2618-a281-45da-a5cd-cc7890e2fdec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:05:24.764512Z",
     "iopub.status.idle": "2023-07-20T14:05:24.764695Z",
     "shell.execute_reply": "2023-07-20T14:05:24.764613Z",
     "shell.execute_reply.started": "2023-07-20T14:05:24.764604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise_to_weights(mean, std, model):\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            m.weight.add_(torch.randn(m.weight.size()) * 0.1)\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(model)\n",
    "    gassian_kernel = torch.distributions.Normal(mean, std)\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():                  \n",
    "            param.mul_(torch.exp(gassian_kernel.sample(param.size())).cuda())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477c020-ffd5-4655-9b9a-0bc09fa55d8b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-20T14:05:24.765235Z",
     "iopub.status.idle": "2023-07-20T14:05:24.765544Z",
     "shell.execute_reply": "2023-07-20T14:05:24.765457Z",
     "shell.execute_reply.started": "2023-07-20T14:05:24.765448Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=args.batch_size,\n",
    "    dist=dist_train, workers=args.workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "    total_epochs=args.epochs\n",
    ")\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "                                dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                class_names=cfg.CLASS_NAMES,\n",
    "                                batch_size=args.batch_size,\n",
    "                                dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                            )\n",
    "\n",
    "\n",
    "start_epoch = it = 0\n",
    "last_epoch = -1\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "                    p1=p1, \n",
    "                    p2=p2, \n",
    "                    p3=p3,\n",
    "                    dataset=train_set)\n",
    "\n",
    "optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95292c-a1c8-4cf6-9f2e-bf3ad2f6081b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-20T14:05:24.766040Z",
     "iopub.status.idle": "2023-07-20T14:05:24.766415Z",
     "shell.execute_reply": "2023-07-20T14:05:24.766315Z",
     "shell.execute_reply.started": "2023-07-20T14:05:24.766306Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy.deepcopy\n",
    "import torch.nn\n",
    "# import copy\n",
    "# def cpmodel(model):\n",
    "#     model = copy.deepcopy(model)\n",
    "#     with torch.no_grad():\n",
    "#         for param in model.parameters():                  \n",
    "#             param.mul_(torch.tensor(2).cuda())\n",
    "            \n",
    "#     return model\n",
    "# model = nn.Linear(4,2).cuda()\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break\n",
    "\n",
    "model1 = add_noise_to_weights(0.0, 0.3, model)\n",
    "\n",
    "# cpmodel(model)\n",
    "\n",
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break\n",
    "    \n",
    "for i in model1.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a4cb2-5c52-40dd-847d-a166b840f758",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2023-07-20T14:05:24.766827Z",
     "iopub.status.idle": "2023-07-20T14:05:24.767177Z",
     "shell.execute_reply": "2023-07-20T14:05:24.767099Z",
     "shell.execute_reply.started": "2023-07-20T14:05:24.767090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linspace(1e-31, 1.0, 21)[6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
