{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebc1e65-310e-4213-933c-1687238b19a4",
   "metadata": {},
   "source": [
    "本代码用于从 bayes 出发试图恢复出合意的半 Multinomial 效果\n",
    "\n",
    "且控制只加sigma噪声\n",
    "\n",
    "实例：Debugging\n",
    "\n",
    "GPU：0\n",
    "\n",
    "状态：\\\n",
    "已完成：把模型改成半 Multinomial ，两种加噪声方案都已支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dccef7d-d27c-490c-847f-741a53e85e3f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T12:07:39.456153Z",
     "iopub.status.busy": "2023-07-07T12:07:39.455892Z",
     "iopub.status.idle": "2023-07-07T12:07:45.096208Z",
     "shell.execute_reply": "2023-07-07T12:07:45.094872Z",
     "shell.execute_reply.started": "2023-07-07T12:07:39.456136Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt, eval_single_ckpt\n",
    "\n",
    "\n",
    "from hardware_noise.weight_mapping_finalv import weight_mapping as add_noise_to_weights\n",
    "# from hardware_noise.weight_mapping_finalv import weight_mapping_sigma_only as add_noise_to_weights\n",
    "from eval_utils import eval_utils_multinomial_finalv_half as eval_utils\n",
    "from pcdet.models_multinomial_half import build_network\n",
    "\n",
    "\n",
    "import numba\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model, model_save\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default='./cfgs/kitti_models/pointpillar_bayes.yaml', \\\n",
    "                        help='specify the config for training')\n",
    "    # sunqiao/OpenPCDet/tools/cfgs/kitti_models/pointpillar_bayes.yaml\n",
    "    parser.add_argument('--batch_size', type=int, default=None, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=None, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=32, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    \n",
    "    parser.add_argument('--ckpt', type=str, default='./checkpoint_epoch_33_multinomial.pth', help='checkpoint to start from')\n",
    "    # ./checkpoint_epoch_80.pth\n",
    "    # checkpoint_epoch_33_multinomial\n",
    "    # ./checkpoint_epoch_80_bayes.pth\n",
    "    \n",
    "    parser.add_argument('--pretrained_model', type=str, default=True, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=True, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=81, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c95292c-a1c8-4cf6-9f2e-bf3ad2f6081b",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-07-07T12:07:45.097622Z",
     "iopub.status.busy": "2023-07-07T12:07:45.097281Z",
     "iopub.status.idle": "2023-07-07T13:34:40.610961Z",
     "shell.execute_reply": "2023-07-07T13:34:40.610411Z",
     "shell.execute_reply.started": "2023-07-07T12:07:45.097605Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 20:07:45,214   INFO  Loading KITTI dataset\n",
      "2023-07-07 20:07:45,302   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:1\n",
      "0.23 0.77 0.68\n",
      "7.757076617433052e-06 I-V_data_1.8um_length_50nm_diameter_NA_third_etch_20min_Pb_ED_3h_180C_MAI_no_200nm_Ag_memory_6V_carbon_paste.xlsx\n",
      "I-V_data_1.8um_length_50nm_diameter_NA_third_etch_20min_Pb_ED_3h_180C_MAI_no_200nm_Ag_memory_6V_carbon_paste.xlsx\n",
      "file:I-V_data_1.8um_length_50nm_diameter_NA_third_etch_20min_Pb_ED_3h_180C_MAI_no_200nm_Ag_memory_6V_carbon_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|█████████▉| 942/943 [01:34<00:00, 23.15it/s]2023-07-07 20:09:21,622   INFO  Average predicted number of objects(3769 samples): 29.582\n",
      "eval: 100%|██████████| 943/943 [02:01<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_aos/easy_R40': 96.84931445534491, 'Car_aos/moderate_R40': 89.74438398788817, 'Car_aos/hard_R40': 87.21215988845002, 'Car_3d/easy_R40': 86.05908888664419, 'Car_3d/moderate_R40': 72.89974301121624, 'Car_3d/hard_R40': 69.90501719189687, 'Car_bev/easy_R40': 93.95811072372038, 'Car_bev/moderate_R40': 86.23553920369169, 'Car_bev/hard_R40': 84.03151598012238, 'Car_image/easy_R40': 96.9097098710367, 'Car_image/moderate_R40': 90.01696408224475, 'Car_image/hard_R40': 87.60924018135569, 'Pedestrian_aos/easy_R40': 35.356461224673765, 'Pedestrian_aos/moderate_R40': 32.75830922885973, 'Pedestrian_aos/hard_R40': 30.84413345459305, 'Pedestrian_3d/easy_R40': 50.373960724051315, 'Pedestrian_3d/moderate_R40': 43.29083138567253, 'Pedestrian_3d/hard_R40': 38.667594274256054, 'Pedestrian_bev/easy_R40': 55.54796993714428, 'Pedestrian_bev/moderate_R40': 48.66790790060388, 'Pedestrian_bev/hard_R40': 44.29814713489417, 'Pedestrian_image/easy_R40': 55.99617973528803, 'Pedestrian_image/moderate_R40': 51.02264188157742, 'Pedestrian_image/hard_R40': 48.138394763892904, 'Cyclist_aos/easy_R40': 81.21310943020612, 'Cyclist_aos/moderate_R40': 67.28529577463742, 'Cyclist_aos/hard_R40': 63.59292329113732, 'Cyclist_3d/easy_R40': 74.77045132745036, 'Cyclist_3d/moderate_R40': 55.05382175790013, 'Cyclist_3d/hard_R40': 51.59213243865606, 'Cyclist_bev/easy_R40': 79.71511006966671, 'Cyclist_bev/moderate_R40': 58.678694701616116, 'Cyclist_bev/hard_R40': 55.61325691787531, 'Cyclist_image/easy_R40': 82.36884612099757, 'Cyclist_image/moderate_R40': 69.09087467861717, 'Cyclist_image/hard_R40': 65.55629693299248}\n",
      "0.002659952221105318 I-V_data_1.2um_length_200nm_diameter_NA_third_etch_15min_Pb_ED_10h_180+210C_FAI_PMMA_200nm_Ag_memory_6V_silver_paste.xlsx\n",
      "I-V_data_1.2um_length_200nm_diameter_NA_third_etch_15min_Pb_ED_10h_180+210C_FAI_PMMA_200nm_Ag_memory_6V_silver_paste.xlsx\n",
      "file:I-V_data_1.2um_length_200nm_diameter_NA_third_etch_15min_Pb_ED_10h_180+210C_FAI_PMMA_200nm_Ag_memory_6V_silver_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|█████████▉| 942/943 [01:40<00:00, 28.71it/s]2023-07-07 21:12:13,953   INFO  Average predicted number of objects(3769 samples): 0.057\n",
      "eval: 100%|██████████| 943/943 [01:45<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_aos/easy_R40': 0.0, 'Car_aos/moderate_R40': 0.0, 'Car_aos/hard_R40': 0.0, 'Car_3d/easy_R40': 0.0, 'Car_3d/moderate_R40': 0.0, 'Car_3d/hard_R40': 0.0, 'Car_bev/easy_R40': 0.0, 'Car_bev/moderate_R40': 0.0, 'Car_bev/hard_R40': 0.0, 'Car_image/easy_R40': 0.0, 'Car_image/moderate_R40': 0.0, 'Car_image/hard_R40': 0.0, 'Pedestrian_aos/easy_R40': 0.0, 'Pedestrian_aos/moderate_R40': 0.0, 'Pedestrian_aos/hard_R40': 0.0, 'Pedestrian_3d/easy_R40': 0.0, 'Pedestrian_3d/moderate_R40': 0.0, 'Pedestrian_3d/hard_R40': 0.0, 'Pedestrian_bev/easy_R40': 0.0, 'Pedestrian_bev/moderate_R40': 0.0, 'Pedestrian_bev/hard_R40': 0.0, 'Pedestrian_image/easy_R40': 0.0, 'Pedestrian_image/moderate_R40': 0.0, 'Pedestrian_image/hard_R40': 0.0, 'Cyclist_aos/easy_R40': 0.0, 'Cyclist_aos/moderate_R40': 0.0, 'Cyclist_aos/hard_R40': 0.0, 'Cyclist_3d/easy_R40': 0.0, 'Cyclist_3d/moderate_R40': 0.0, 'Cyclist_3d/hard_R40': 0.0, 'Cyclist_bev/easy_R40': 0.0, 'Cyclist_bev/moderate_R40': 0.0, 'Cyclist_bev/hard_R40': 0.0, 'Cyclist_image/easy_R40': 0.0, 'Cyclist_image/moderate_R40': 0.0, 'Cyclist_image/hard_R40': 0.0}\n",
      "0.7018921503943217 I-V_data_2.5um_length_200nm_diameter_NA_third_etch_25min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_5V_silver_paste.xlsx\n",
      "I-V_data_2.5um_length_200nm_diameter_NA_third_etch_25min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_5V_silver_paste.xlsx\n",
      "file:I-V_data_2.5um_length_200nm_diameter_NA_third_etch_25min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_5V_silver_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|█████████▉| 942/943 [01:38<00:00, 28.93it/s]2023-07-07 21:19:09,149   INFO  Average predicted number of objects(3769 samples): 0.000\n",
      "eval: 100%|██████████| 943/943 [01:43<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_3d/easy_R40': 0.0, 'Car_3d/moderate_R40': 0.0, 'Car_3d/hard_R40': 0.0, 'Car_bev/easy_R40': 0.0, 'Car_bev/moderate_R40': 0.0, 'Car_bev/hard_R40': 0.0, 'Car_image/easy_R40': 0.0, 'Car_image/moderate_R40': 0.0, 'Car_image/hard_R40': 0.0, 'Pedestrian_3d/easy_R40': 0.0, 'Pedestrian_3d/moderate_R40': 0.0, 'Pedestrian_3d/hard_R40': 0.0, 'Pedestrian_bev/easy_R40': 0.0, 'Pedestrian_bev/moderate_R40': 0.0, 'Pedestrian_bev/hard_R40': 0.0, 'Pedestrian_image/easy_R40': 0.0, 'Pedestrian_image/moderate_R40': 0.0, 'Pedestrian_image/hard_R40': 0.0, 'Cyclist_3d/easy_R40': 0.0, 'Cyclist_3d/moderate_R40': 0.0, 'Cyclist_3d/hard_R40': 0.0, 'Cyclist_bev/easy_R40': 0.0, 'Cyclist_bev/moderate_R40': 0.0, 'Cyclist_bev/hard_R40': 0.0, 'Cyclist_image/easy_R40': 0.0, 'Cyclist_image/moderate_R40': 0.0, 'Cyclist_image/hard_R40': 0.0}\n",
      "1.2174662236023046 I-V_data_2um_length_300nm_diameter_NA_third_etch_10min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_4V_carbon_paste.xlsx\n",
      "I-V_data_2um_length_300nm_diameter_NA_third_etch_10min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_4V_carbon_paste.xlsx\n",
      "file:I-V_data_2um_length_300nm_diameter_NA_third_etch_10min_Pb_ED_1h_180C_MAI_no_100nm_Ag_memory_4V_carbon_paste.xlsx, evaluate-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|█████████▉| 942/943 [01:49<00:00, 26.24it/s]2023-07-07 21:34:29,642   INFO  Average predicted number of objects(3769 samples): 18.657\n",
      "eval: 100%|██████████| 943/943 [02:00<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall/roi_0.3': 0.0, 'recall/rcnn_0.3': 0.0, 'recall/roi_0.5': 0.0, 'recall/rcnn_0.5': 0.0, 'recall/roi_0.7': 0.0, 'recall/rcnn_0.7': 0.0, 'Car_aos/easy_R40': 0.0, 'Car_aos/moderate_R40': 0.0, 'Car_aos/hard_R40': 0.0, 'Car_3d/easy_R40': 0.0, 'Car_3d/moderate_R40': 0.0, 'Car_3d/hard_R40': 0.0, 'Car_bev/easy_R40': 0.0, 'Car_bev/moderate_R40': 0.0, 'Car_bev/hard_R40': 0.0, 'Car_image/easy_R40': 0.0, 'Car_image/moderate_R40': 0.0, 'Car_image/hard_R40': 0.0, 'Pedestrian_aos/easy_R40': 0.0, 'Pedestrian_aos/moderate_R40': 0.0, 'Pedestrian_aos/hard_R40': 0.0, 'Pedestrian_3d/easy_R40': 0.0, 'Pedestrian_3d/moderate_R40': 0.0, 'Pedestrian_3d/hard_R40': 0.0, 'Pedestrian_bev/easy_R40': 0.0, 'Pedestrian_bev/moderate_R40': 0.0, 'Pedestrian_bev/hard_R40': 0.0, 'Pedestrian_image/easy_R40': 0.0, 'Pedestrian_image/moderate_R40': 0.0, 'Pedestrian_image/hard_R40': 0.0, 'Cyclist_aos/easy_R40': 0.0, 'Cyclist_aos/moderate_R40': 0.0, 'Cyclist_aos/hard_R40': 0.0, 'Cyclist_3d/easy_R40': 0.0, 'Cyclist_3d/moderate_R40': 0.0, 'Cyclist_3d/hard_R40': 0.0, 'Cyclist_bev/easy_R40': 0.0, 'Cyclist_bev/moderate_R40': 0.0, 'Cyclist_bev/hard_R40': 0.0, 'Cyclist_image/easy_R40': 0.0, 'Cyclist_image/moderate_R40': 0.0, 'Cyclist_image/hard_R40': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.cuda.set_device(0)\n",
    "    # best_accu = 0\n",
    "\n",
    "    args, cfg = parse_config()\n",
    "    if args.launcher == 'none':\n",
    "        dist_train = False\n",
    "        total_gpus = 1\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "        memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "        print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "        os.system('rm tmp')\n",
    "    else:\n",
    "        total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "            args.tcp_port, args.local_rank, backend='nccl'\n",
    "        )\n",
    "        dist_train = True\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = './save_path/multinomial/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "    logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    file = open(save_path+'result.txt','w')\n",
    "    file.write('results\\n')\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    # if dist_train:\n",
    "    #     logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    # for key, val in vars(args).items():\n",
    "    #     logger.info('{:16} {}'.format(key, val))\n",
    "    # log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "    \n",
    "    p1 = 0.23\n",
    "    p2 = 0.77\n",
    "    p3 = 0.68\n",
    "    \n",
    "    print(p1, p2, p3)\n",
    "    \n",
    "\n",
    "    '''Test on Noises'''  \n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "                                    dataset_cfg=cfg.DATA_CONFIG,\n",
    "                                    class_names=cfg.CLASS_NAMES,\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "                                )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, p3=0.11, dataset=test_set)\n",
    "    # model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "    \n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    # time.sleep(1)\n",
    "    \n",
    "    file2usability = np.load('./hardware_noise/file2usability.npy', allow_pickle=True).item()\n",
    "    file2sigma = np.load('./hardware_noise/file2sigma.npy', allow_pickle=True).item()\n",
    "    \n",
    "    # hw_data_files = sorted(os.listdir('./hardware_noise/hardware_data/'))\n",
    "    file2ap_dict = {}\n",
    "    N = 1\n",
    "    \n",
    "    for sigma, f_name in sorted(zip(file2sigma.values(), file2sigma.keys())):\n",
    "        print(sigma, f_name)\n",
    "        usability = file2usability[f_name]\n",
    "        if f_name.endswith('xlsx'):\n",
    "            file2ap_dict[f_name] = {}\n",
    "            print(f_name)\n",
    "            for n in range(N):\n",
    "                print('file:{}, evaluate-{}'.format(f_name, n))\n",
    "                model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "                add_noise_to_weights('./hardware_noise/hardware_data/'+f_name, model, device='cuda')\n",
    "\n",
    "                # acc1 = eval_utils.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "                acc1, ret_dict = eval_utils.eval_simple(p1, p2, p3, f_name, usability, sigma, \n",
    "                                n, cfg, model, test_loader, logger, \n",
    "                                save_path, dist_test=False,\n",
    "                                save_to_file=False, result_dir=save_path)\n",
    "                print(ret_dict)\n",
    "                file2ap_dict[f_name][n] = ret_dict \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3b1d8-bb0c-43ab-9c82-fab11e731802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40fa83-32a4-4edf-b33c-b24434bf0752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287009d4-d087-4ae8-b66f-244b74f09055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a1ffb-109b-4a8b-83f3-de4002a930f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ffb33b-9774-457b-be70-84d1e4332657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T13:34:40.612806Z",
     "iopub.status.busy": "2023-07-07T13:34:40.612620Z",
     "iopub.status.idle": "2023-07-07T13:34:40.622490Z",
     "shell.execute_reply": "2023-07-07T13:34:40.621563Z",
     "shell.execute_reply.started": "2023-07-07T13:34:40.612790Z"
    }
   },
   "outputs": [],
   "source": [
    "# class Opt():\n",
    "#     def __init__(self, sigma):\n",
    "#         self.sigma = sigma\n",
    "        \n",
    "#     def opt_function(self, p1, p2):\n",
    "\n",
    "#         print(\"=============\")\n",
    "#         print(p1, p2)\n",
    "#         print(\"=============\")\n",
    "\n",
    "#         global best_accu\n",
    "\n",
    "#         # p1 = round(p1, 2)\n",
    "#         # p2 = round(p2, 2)\n",
    "\n",
    "#         # train_set, train_loader, train_sampler = build_dataloader(\n",
    "#         #     dataset_cfg=cfg.DATA_CONFIG,\n",
    "#         #     class_names=cfg.CLASS_NAMES,\n",
    "#         #     batch_size=args.batch_size,\n",
    "#         #     dist=dist_train, workers=args.workers,\n",
    "#         #     logger=logger,\n",
    "#         #     training=True,\n",
    "#         #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "#         #     total_epochs=args.epochs\n",
    "#         # )\n",
    "\n",
    "#         # model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), \n",
    "#         #                     p1=p1, \n",
    "#         #                     p2=p2, \n",
    "#         #                     dataset=train_set)\n",
    "#         # print(model.state_dict())\n",
    "#         # print(\"???????????\")\n",
    "\n",
    "#     #     if args.sync_bn:\n",
    "#     #         model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "#     #     model.cuda()\n",
    "\n",
    "#         # optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "#     #     # # load checkpoint if it is possible\n",
    "#     #     start_epoch = it = 0\n",
    "#     #     last_epoch = -1\n",
    "#     #     if args.pretrained_model is True:\n",
    "#     #         model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "#     #     # if args.ckpt is not None:\n",
    "#     #     #     it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "#     #     #     last_epoch = start_epoch + 1\n",
    "#     #     # else:\n",
    "#     #     #     ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "#     #     #     if len(ckpt_list) > 0:\n",
    "#     #     #         ckpt_list.sort(key=os.path.getmtime)\n",
    "#     #     #         it, start_epoch = model.load_params_with_optimizer(\n",
    "#     #     #             ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "#     #     #         )\n",
    "#     #     #         last_epoch = start_epoch + 1\n",
    "\n",
    "#     #     model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "#     #     if dist_train:\n",
    "#     #         model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "#     #     logger.info(model)\n",
    "\n",
    "#     #     lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "#     #         optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "#     #         last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "#     #     )\n",
    "\n",
    "#     # #     # -----------------------start training---------------------------\n",
    "#     #     logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "#     #                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "#         # train_model(\n",
    "#         #     model,\n",
    "#         #     optimizer,\n",
    "#         #     train_loader,\n",
    "#         #     model_func=model_fn_decorator(),\n",
    "#         #     lr_scheduler=lr_scheduler,\n",
    "#         #     optim_cfg=cfg.OPTIMIZATION,\n",
    "#         #     start_epoch=start_epoch,\n",
    "#         #     total_epochs=args.epochs,\n",
    "#         #     start_iter=it,\n",
    "#         #     rank=cfg.LOCAL_RANK,\n",
    "#         #     tb_log=tb_log,\n",
    "#         #     ckpt_save_dir=ckpt_dir,\n",
    "#         #     train_sampler=train_sampler,\n",
    "#         #     lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "#         #     ckpt_save_interval=args.ckpt_save_interval,\n",
    "#         #     max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "#         #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "#         # )\n",
    "\n",
    "#         test_set, test_loader, sampler = build_dataloader(\n",
    "#                                         dataset_cfg=cfg.DATA_CONFIG,\n",
    "#                                         class_names=cfg.CLASS_NAMES,\n",
    "#                                         batch_size=args.batch_size,\n",
    "#                                         dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    "#                                     )\n",
    "\n",
    "\n",
    "#         model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), p1=0.11, p2=0.11, dataset=test_set)\n",
    "\n",
    "#         optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "#         if dist_train: \n",
    "#             model = model.module\n",
    "\n",
    "#         if args.pretrained_model is True:\n",
    "#             model.load_params_from_file(filename=args.ckpt, to_cpu=dist, logger=logger)\n",
    "\n",
    "#         # model.load_params_from_file(filename='./checkpoint_epoch_80.pth', logger=logger, to_cpu=dist_train)\n",
    "#         model.cuda()\n",
    "\n",
    "#         ckpt_pth = save_path+'bayes_model-{}-{}'.format(p1,p2)\n",
    "#         ckpt_name = ckpt_pth+'.pth'\n",
    "\n",
    "#         if cfg.LOCAL_RANK == 0:\n",
    "#             model_save(model, ckpt_pth, optimizer, args.epochs, args.epochs)\n",
    "\n",
    "#         logger.info('**********************End training**********************')\n",
    "\n",
    "#         time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "#         # if dist_train: \n",
    "#         #     model = model.module\n",
    "\n",
    "#         sigma = self.sigma\n",
    "#         f = open(save_path+'result.txt', \"a+\")\n",
    "#         # f.write('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "#         f.write('----------------{}-{}----------------\\n'.format(p1,p2))\n",
    "#         f.close()\n",
    "\n",
    "#         logger.info('----------------Noise-{}-evaluate----------------'.format(sigma))\n",
    "#         # model.load_params_from_file(filename=ckpt_name, logger=logger, to_cpu=dist_train)\n",
    "#         # model.cuda()\n",
    "#         model = add_noise_to_weights(0, sigma, model)\n",
    "#         global n\n",
    "#         n += 1\n",
    "\n",
    "#         acc1 = eval_utils_bayes.eval_simple(p1, p2, sigma, n, cfg, model, test_loader, logger, save_path, dist_test=dist_train, save_to_file=args.save_to_file, result_dir=eval_output_dir)\n",
    "#         print(\"----------\")\n",
    "#         print(acc1)\n",
    "#         print(\"----------\")\n",
    "\n",
    "\n",
    "#         logger.info('**********************End evaluation**********************')\n",
    "\n",
    "#             # best_accu = acc\n",
    "\n",
    "#         return acc1  #+acc2+acc3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "\n",
    "# #     torch.cuda.set_device(0)\n",
    "# #     # best_accu = 0\n",
    "\n",
    "# #     args, cfg = parse_config()\n",
    "# #     if args.launcher == 'none':\n",
    "# #         dist_train = False\n",
    "# #         total_gpus = 1\n",
    "# #         os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# #         os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "# #         memory_gpu = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "# #         print('Using GPU:' + str(np.argmax(memory_gpu)))\n",
    "# #         os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))\n",
    "# #         os.system('rm tmp')\n",
    "# #     else:\n",
    "# #         total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "# #             args.tcp_port, args.local_rank, backend='nccl'\n",
    "# #         )\n",
    "# #         dist_train = True\n",
    "\n",
    "# #     if args.batch_size is None:\n",
    "# #         args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "# #     else:\n",
    "# #         assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "# #         args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "# #     args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "# #     if args.fix_random_seed:\n",
    "# #         common_utils.set_random_seed(666)\n",
    "\n",
    "# #     output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / 'bayes' / args.extra_tag\n",
    "# #     ckpt_dir = output_dir / 'ckpt'\n",
    "# #     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# #     ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# #     save_path = './save_path/bayes/'#/bayes/pointpillar/'+time.strftime('%m%d-%H%M',time.localtime(time.time()))+'/'\n",
    "\n",
    "# #     if not os.path.exists(save_path):\n",
    "# #         os.makedirs(save_path, exist_ok=True) \n",
    "\n",
    "# #     logger = common_utils.create_logger(save_path+'log.txt', rank=cfg.LOCAL_RANK)\n",
    "\n",
    "# #     file = open(save_path+'result.txt','w')\n",
    "# #     file.write('results\\n')\n",
    "# #     file.close()\n",
    "\n",
    "# #     # head = ''\n",
    "# #     # logging.basicConfig(filename='./baseline/pointpillar/log.txt',\n",
    "# #     #                     format=head)\n",
    "# #     # logger_result = logging.getLogger()\n",
    "# #     # logger_result.setLevel(logging.INFO)\n",
    "# #     # console = logging.StreamHandler()\n",
    "# #     # logging.getLogger('').addHandler(console)\n",
    "\n",
    "# #     # log to file\n",
    "# #     logger.info('**********************Start logging**********************')\n",
    "# #     gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "# #     logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "# #     if dist_train:\n",
    "# #         logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "# #     for key, val in vars(args).items():\n",
    "# #         logger.info('{:16} {}'.format(key, val))\n",
    "# #     log_config_to_file(cfg, logger=logger)\n",
    "# #     if cfg.LOCAL_RANK == 0:\n",
    "# #         os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "# #     tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "# #     eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "# #     eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# #     args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # #     # -----------------------start training---------------------------\n",
    "# #     logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "# #                 % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "# #     print(ckpt_dir)\n",
    "# #     # ckpt_dir = './save_path/ckpts'\n",
    "\n",
    "# #     # train_model(\n",
    "# #     #     model,\n",
    "# #     #     optimizer,\n",
    "# #     #     train_loader,\n",
    "# #     #     model_func=model_fn_decorator(),\n",
    "# #     #     lr_scheduler=lr_scheduler,\n",
    "# #     #     optim_cfg=cfg.OPTIMIZATION,\n",
    "# #     #     start_epoch=start_epoch,\n",
    "# #     #     total_epochs=args.epochs,\n",
    "# #     #     start_iter=it,\n",
    "# #     #     rank=cfg.LOCAL_RANK,\n",
    "# #     #     tb_log=tb_log,\n",
    "# #     #     ckpt_save_dir=ckpt_dir,\n",
    "# #     #     train_sampler=train_sampler,\n",
    "# #     #     lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "# #     #     ckpt_save_interval=args.ckpt_save_interval,\n",
    "# #     #     max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "# #     #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "# #     # )\n",
    "\n",
    "# #     logger.info('----------------Bayes Optimization----------------')\n",
    "# #     for sigma in np.linspace(1e-31, 1.0, 21)[1: ]:\n",
    "\n",
    "# #         # opt_function(0.11, 0.11)\n",
    "# #         print(\"=============\")\n",
    "# #         p1 = 0.11\n",
    "# #         p2 = 0.11\n",
    "# #         print(p1, p2)\n",
    "# #         print(\"=============\")\n",
    "        \n",
    "# #         opt= Opt(sigma)\n",
    "# #         opt_function = opt.opt_function\n",
    "        \n",
    "# #         # Bounded region of parameter space\n",
    "# #         pbounds = {'p1': (0.1, 0.9), 'p2': (0.1, 0.9)}\n",
    "\n",
    "\n",
    "# #         optimizer_bayes = BayesianOptimization(\n",
    "# #             f=opt_function,\n",
    "# #             pbounds=pbounds,\n",
    "# #             verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "# #             random_state=1,\n",
    "# #         )\n",
    "# #         optimizer_bayes.probe(\n",
    "# #             params={'p1': 0.11, 'p2': 0.11},\n",
    "# #             lazy=True,\n",
    "# #         )\n",
    "\n",
    "# #         logger_bayes = JSONLogger(path=save_path+\"logs2.json\")\n",
    "# #         optimizer_bayes.subscribe(Events.OPTIMIZATION_STEP, logger_bayes)\n",
    "\n",
    "\n",
    "# #         n = 0\n",
    "# #         optimizer_bayes.maximize(\n",
    "# #             init_points=3,\n",
    "# #             n_iter=10,\n",
    "# #         )\n",
    "# #     print(\"=======end========\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c6a85-7b77-488e-9f1b-2ebe3cd587c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9577ae2f-680a-4d4d-9911-fe35c6c97709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T13:34:40.623997Z",
     "iopub.status.busy": "2023-07-07T13:34:40.623673Z",
     "iopub.status.idle": "2023-07-07T13:34:40.626961Z",
     "shell.execute_reply": "2023-07-07T13:34:40.625717Z",
     "shell.execute_reply.started": "2023-07-07T13:34:40.623975Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ../output/cfgs/kitti_models/bayes/default/ckpt/checkpoint_epoch_33.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f3975-23eb-48bc-a0ed-2a5abce74b7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
